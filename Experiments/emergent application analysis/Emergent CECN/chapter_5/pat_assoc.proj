// ta_Dump File v3.0 -- code v5.1.0.0
LeabraProject .projects[0] { 
  taBase_Group @.templates = [0] {
  };

  Doc_Group @.docs = [3] {
    taDoc @[0] { };
    taDoc @[1] { };
    taDoc @[2] { };
  };

  Wizard_Group @.wizards = [1] {
    LeabraWizard @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };

      LayerWizElList @.layer_cfg = [3] {
	LayerWizEl @[0] { };
	LayerWizEl @[1] { };
	LayerWizEl @[2] { };
      };
    };
  };

  SelectEdit_Group @.edits = [1] {
    SelectEdit @[0] { 
      EditMbrItem_Group @.mbrs = [4] {
	EditMbrItem @[0] { };
	EditMbrItem @[1] { };
	EditMbrItem @[2] { };
	EditMbrItem @[3] { };
	EditMbrItem_Group @.gp[0] = [3] { 
	  EditMbrItem @[0] { };
	  EditMbrItem @[1] { };
	  EditMbrItem @[2] { };
	};
	EditMbrItem_Group @.gp[1] = [1] { 
	  EditMbrItem @[0] { };
	};
	EditMbrItem_Group @.gp[2] = [7] { 
	  EditMbrItem @[0] { };
	  EditMbrItem @[1] { };
	  EditMbrItem @[2] { };
	  EditMbrItem @[3] { };
	  EditMbrItem @[4] { };
	  EditMbrItem @[5] { };
	  EditMbrItem @[6] { };
	};
      };

      EditMthItem_Group @.mths = [8] {
	EditMthItem @[0] { };
	EditMthItem @[1] { };
	EditMthItem @[2] { };
	EditMthItem @[3] { };
	EditMthItem @[4] { };
	EditMthItem @[5] { };
	EditMthItem @[6] { };
	EditMthItem @[7] { };
      };
    };
  };

  DataTable_Group @.data = [0] {
    DataTable_Group @.gp[0] = [3] { 
      DataTable @[0] { 
	DataTableCols @.data = [3] {
	  String_Data @[0] { };
	  float_Data @[1] { };
	  float_Data @[2] { };
	};
      };
      DataTable @[1] { 
	DataTableCols @.data = [3] {
	  String_Data @[0] { };
	  float_Data @[1] { };
	  float_Data @[2] { };
	};
      };
      DataTable @[2] { 
	DataTableCols @.data = [3] {
	  String_Data @[0] { };
	  float_Data @[1] { };
	  float_Data @[2] { };
	};
      };
    };
    DataTable_Group @.gp[1] = [2] { 
      DataTable @[0] { 
	DataTableCols @.data = [4] {
	  String_Data @[0] { };
	  float_Data @[1] { };
	  float_Data @[2] { };
	  float_Data @[3] { };
	};
      };
      DataTable @[1] { 
	DataTableCols @.data = [8] {
	  int_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  float_Data @[2] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[3] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[4] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[5] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[6] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[7] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
    };
    DataTable_Group @.gp[2] { 
    };
  };

  taBase_Group @.data_proc = [4] {
    taDataProc @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taDataAnal @[1] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taDataGen @[2] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taImageProc @[3] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
  };

  Program_Group @.programs = [2] {
    Program @[0] { 
      ProgObjList @.objs = [0] {
      };

      ProgType_List @.types = [2] {
	DynEnumType @[0] { 
	  DynEnumItem_List @.enums = [3] {
	    DynEnumItem @[0] { };
	    DynEnumItem @[1] { };
	    DynEnumItem @[2] { };
	  };
	};
	DynEnumType @[1] { 
	  DynEnumItem_List @.enums = [2] {
	    DynEnumItem @[0] { };
	    DynEnumItem @[1] { };
	  };
	};
      };

      ProgVar_List @.args = [0] {
      };

      ProgVar_List @.vars = [10] {
	ProgVar @[0] { };
	ProgVar @[1] { };
	ProgVar @[2] { };
	ProgVar @[3] { };
	ProgVar @[4] { };
	ProgVar @[5] { };
	ProgVar @[6] { };
	ProgVar @[7] { };
	ProgVar @[8] { };
	ProgVar @[9] { };
      };

      Function_List @.functions = [0] {
      };

      ProgEl_List @.load_code = [0] {
      };

      ProgEl_List @.init_code = [0] {
      };

      ProgEl_List @.prog_code = [9] {
	MethodCall @[0] { 
	  ProgArg_List @.meth_args = [2] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	  };
	};
	MemberAssign @[1] { };
	MemberAssign @[2] { };
	MethodCall @[3] { 
	  ProgArg_List @.meth_args = [2] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	  };
	};
	MethodCall @[4] { 
	  ProgArg_List @.meth_args = [2] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	  };
	};
	MethodCall @[5] { 
	  ProgArg_List @.meth_args = [2] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	  };
	};
	MethodCall @[6] { 
	  ProgArg_List @.meth_args = [0] {
	  };
	};
	MethodCall @[7] { 
	  ProgArg_List @.meth_args = [0] {
	  };
	};
	ProgramCall @[8] { 
	  ProgArg_List @.prog_args = [3] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	    ProgArg @[2] { };
	  };
	};
      };
    };
    Program @[1] { 
      ProgObjList @.objs = [0] {
      };

      ProgType_List @.types = [1] {
	DynEnumType @[0] { 
	  DynEnumItem_List @.enums = [2] {
	    DynEnumItem @[0] { };
	    DynEnumItem @[1] { };
	  };
	};
      };

      ProgVar_List @.args = [3] {
	ProgVar @[0] { };
	ProgVar @[1] { };
	ProgVar @[2] { };
      };

      ProgVar_List @.vars = [2] {
	ProgVar @[0] { };
	ProgVar @[1] { };
      };

      Function_List @.functions = [0] {
      };

      ProgEl_List @.load_code = [0] {
      };

      ProgEl_List @.init_code = [0] {
      };

      ProgEl_List @.prog_code = [4] {
	AssignExpr @[0] { };
	Switch @[1] { 
	  ProgEl_List @.cases = [2] {
	    CaseBlock @[0] { 
	      ProgEl_List @.prog_code = [3] {
		MemberAssign @[0] { };
		MemberAssign @[1] { };
		MemberAssign @[2] { };
	      };
	    };
	    CaseBlock @[1] { 
	      ProgEl_List @.prog_code = [3] {
		MemberAssign @[0] { };
		MemberAssign @[1] { };
		MemberAssign @[2] { };
	      };
	    };
	  };
	};
	MethodCall @[2] { 
	  ProgArg_List @.meth_args = [1] {
	    ProgArg @[0] { };
	  };
	};
	MethodCall @[3] { 
	  ProgArg_List @.meth_args = [0] {
	  };
	};
      };
    };
    Program_Group @.gp[0] = [9] { 
      Program @[0] { 
	ProgObjList @.objs = [1] {
	  RndSeed @[0] { };
	};

	ProgType_List @.types = [2] {
	  DynEnumType @[0] { 
	    DynEnumItem_List @.enums = [2] {
	      DynEnumItem @[0] { };
	      DynEnumItem @[1] { };
	    };
	  };
	  DynEnumType @[1] { 
	    DynEnumItem_List @.enums = [3] {
	      DynEnumItem @[0] { };
	      DynEnumItem @[1] { };
	      DynEnumItem @[2] { };
	    };
	  };
	};

	ProgVar_List @.args = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	ProgVar_List @.vars = [10] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	  ProgVar @[6] { };
	  ProgVar @[7] { };
	  ProgVar @[8] { };
	  ProgVar @[9] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [7] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  AssignExpr @[2] { };
	  IfElse @[3] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  IfGuiPrompt @[4] { 
	    ProgEl_List @.yes_code = [2] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	      PrintExpr @[1] { };
	    };
	  };
	  AssignExpr @[5] { };
	  MemberMethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};

	ProgEl_List @.prog_code = [8] {
	  Switch @[0] { 
	    ProgEl_List @.cases = [3] {
	      CaseBlock @[0] { 
		ProgEl_List @.prog_code = [1] {
		  AssignExpr @[0] { };
		};
	      };
	      CaseBlock @[1] { 
		ProgEl_List @.prog_code = [1] {
		  AssignExpr @[0] { };
		};
	      };
	      CaseBlock @[2] { 
		ProgEl_List @.prog_code = [1] {
		  AssignExpr @[0] { };
		};
	      };
	    };
	  };
	  AssignExpr @[1] { };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MemberAssign @[3] { };
	  IfElse @[4] { 
	    ProgEl_List @.true_code = [2] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	      PrintExpr @[1] { };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  AssignExpr @[5] { };
	  WhileLoop @[6] { 
	    ProgEl_List @.loop_code = [5] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      ProgramCall @[1] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[2] { };
	      IfElse @[3] { 
		ProgEl_List @.true_code = [2] {
		  VarIncr @[0] { };
		  IfBreak @[1] { };
		};

		ProgEl_List @.false_code = [1] {
		  AssignExpr @[0] { };
		};
	      };
	      IfBreak @[4] { };
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[1] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [5] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	};

	ProgEl_List @.prog_code = [9] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetDataLoop @[4] { 
	    ProgEl_List @.loop_code = [1] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	    };
	  };
	  IfElse @[5] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[8] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};
      };
      Program @[2] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [7] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  WhileLoop @[2] { 
	    ProgEl_List @.loop_code = [3] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      MethodCall @[2] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  If @[4] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  ProgramCall @[5] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  NetUpdateView @[6] { };
	};
      };
      Program @[3] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [4] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [11] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[3] { 
	    ProgArg_List @.prog_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[5] { 
	    ProgEl_List @.true_code = [1] {
	      AssignExpr @[0] { };
	    };

	    ProgEl_List @.false_code = [1] {
	      AssignExpr @[0] { };
	    };
	  };
	  WhileLoop @[6] { 
	    ProgEl_List @.loop_code = [4] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [1] {
		  ProgArg @[0] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      IfContinue @[2] { };
	      IfBreak @[3] { };
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[8] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  IfElse @[9] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  NetUpdateView @[10] { };
	};
      };
      Program @[4] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetUpdateView @[1] { };
	};
      };
      Program @[5] { 
	ProgObjList @.objs = [1] {
	  LayerWriter @[0] { 
	    LayerDataEl_List @.layer_data = [3] {
	      LayerWriterEl @[0] { };
	      LayerWriterEl @[1] { };
	      LayerWriterEl @[2] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[6] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [3] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [3] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [4] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
      Program @[7] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [8] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	      NetMonItem @[5] { };
	      NetMonItem @[6] { };
	      NetMonItem @[7] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [4] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [6] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  AssignExpr @[2] { };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[8] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [6] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [6] {
	  IfReturn @[0] { };
	  MiscCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MiscCall @[2] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  AssignExpr @[3] { };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
    };
    Program_Group @.gp[1] = [7] { 
      Program @[0] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [5] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	};

	ProgEl_List @.prog_code = [11] {
	  NetCounterInit @[0] { };
	  MemberAssign @[1] { };
	  AssignExpr @[2] { };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetDataLoop @[5] { 
	    ProgEl_List @.loop_code = [2] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      IfElse @[1] { 
		ProgEl_List @.true_code = [1] {
		  MethodCall @[0] { 
		    ProgArg_List @.meth_args = [0] {
		    };
		  };
		};

		ProgEl_List @.false_code = [0] {
		};
	      };
	    };
	  };
	  IfElse @[6] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[8] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[9] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MemberAssign @[10] { };
	};
      };
      Program @[1] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [6] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  WhileLoop @[2] { 
	    ProgEl_List @.loop_code = [3] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      MethodCall @[2] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[4] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  NetUpdateView @[5] { };
	};
      };
      Program @[2] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [10] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[2] { 
	    ProgArg_List @.prog_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[4] { 
	    ProgEl_List @.true_code = [1] {
	      AssignExpr @[0] { };
	    };

	    ProgEl_List @.false_code = [1] {
	      AssignExpr @[0] { };
	    };
	  };
	  WhileLoop @[5] { 
	    ProgEl_List @.loop_code = [4] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [1] {
		  ProgArg @[0] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      IfContinue @[2] { };
	      IfBreak @[3] { };
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[7] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  IfElse @[8] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  NetUpdateView @[9] { };
	};
      };
      Program @[3] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetUpdateView @[1] { };
	};
      };
      Program @[4] { 
	ProgObjList @.objs = [1] {
	  LayerWriter @[0] { 
	    LayerDataEl_List @.layer_data = [3] {
	      LayerWriterEl @[0] { };
	      LayerWriterEl @[1] { };
	      LayerWriterEl @[2] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[5] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [3] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [3] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [4] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
      Program @[6] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [8] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	      NetMonItem @[5] { };
	      NetMonItem @[6] { };
	      NetMonItem @[7] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [4] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [6] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  AssignExpr @[2] { };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
    };
  };

  DataViewer_List @.viewers = [1] {
    MainWindowViewer @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
	UserDataItem @[1] { };
	UserDataItem @[2] { };
	UserDataItem @[3] { };
	UserDataItem @[4] { };
	UserDataItem @[5] { };
   };

      ToolBar_List @.toolbars = [1] {
	ToolBar @[0] { 
     UserDataItem_List @*(.user_data_) {
	    UserDataItem @[0] { };
     };
};
      };

      FrameViewer_List @.frames = [3] {
	tabBrowseViewer @[0] { };
	PanelViewer @[1] { };
	T3DataViewer @[2] { 
	  T3DataViewFrame_List @.frames = [6] {
	    T3DataViewFrame @[0] { 
	      T3DataView_List @.children = [1] {
		NetView @[0] { 
		  ScaleRange_List @.scale_ranges = [10] {
		    ScaleRange @[0] { };
		    ScaleRange @[1] { };
		    ScaleRange @[2] { };
		    ScaleRange @[3] { };
		    ScaleRange @[4] { };
		    ScaleRange @[5] { };
		    ScaleRange @[6] { };
		    ScaleRange @[7] { };
		    ScaleRange @[8] { };
		    ScaleRange @[9] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[1] { 
	      T3DataView_List @.children = [1] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [3] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[2] { 
	      T3DataView_List @.children = [1] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [3] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[3] { 
	      T3DataView_List @.children = [1] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [3] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[4] { 
	      T3DataView_List @.children = [1] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [4] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		    GridColView @[3] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[5] { 
	      T3DataView_List @.children = [1] {
		GraphTableView @[0] { 
		  T3DataView_List @.children = [8] {
		    GraphColView @[0] { };
		    GraphColView @[1] { };
		    GraphColView @[2] { };
		    GraphColView @[3] { };
		    GraphColView @[4] { };
		    GraphColView @[5] { };
		    GraphColView @[6] { };
		    GraphColView @[7] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	  };
	};
      };

      DockViewer_List @.docks = [1] {
	ToolBoxDockViewer @[0] { 
     UserDataItem_List @*(.user_data_) {
	    UserDataItem @[0] { };
	    UserDataItem @[1] { };
	    UserDataItem @[2] { };
	    UserDataItem @[3] { };
	    UserDataItem @[4] { };
	    UserDataItem @[5] { };
     };
};
      };
    };
  };

  Network_Group @.networks = [1] {
    LeabraNetwork @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
	UserDataItem @[1] { };
	UserDataItem @[2] { };
	UserDataItem @[3] { };
	UserDataItem @[4] { };
	UserDataItem @[5] { };
	UserDataItem @[6] { };
	UserDataItem @[7] { };
	UserDataItem @[8] { };
	UserDataItem @[9] { };
	UserDataItem @[10] { };
	UserDataItem @[11] { };
	UserDataItem @[12] { };
	UserDataItem @[13] { };
	UserDataItem @[14] { };
	UserDataItem @[15] { };
	UserDataItem @[16] { };
	UserDataItem @[17] { };
	UserDataItem @[18] { };
   };

      BaseSpec_Group @.specs = [5] {
	LeabraUnitSpec @[0] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.noise_sched = [0] {
	  };
	};
	LeabraConSpec @[1] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.lrate_sched = [0] {
	  };
	};
	LeabraLayerSpec @[2] { 
	  BaseSpec_Group @.children = [1] {
	    LeabraLayerSpec @[0] { 
	      BaseSpec_Group @.children = [0] {
	      };
	    };
	  };
	};
	LeabraBiasSpec @[3] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.lrate_sched = [0] {
	  };
	};
	FullPrjnSpec @[4] { 
	  BaseSpec_Group @.children = [0] {
	  };
	};
      };

      Layer_Group @.layers = [2] {
	LeabraLayer @[0] { 
	  Projection_Group @.projections = [0] {
	  };

	  Unit_Group @.units = [4] {
	  };
	};
	LeabraLayer @[1] { 
	  Projection_Group @.projections = [1] {
	    LeabraPrjn @[0] { };
	  };

	  Unit_Group @.units = [2] {
	  };
	};
      };

      NetViewObj_Group @.view_objs = [0] {
      };
    };
  };
};
LeabraProject .projects[0] {
 name="Project_0";
 desc="


";
 tags=;
 version {
  major=0;
  minor=0;
  step=0;
 };
 wiki_url {
  sync=0;
  wiki=;
  url=;
 };
 templates {
  name=;
  el_typ=taBase;
  el_def=0;
 };
 docs {
  name=;
  el_typ=taDoc;
  el_def=0;
  taDoc @[0] {
   name="ChangeLog";
   desc=;
   auto_open=0;
   web_doc=0;
   wiki=;
   url="local";
   full_url="local";
   text_size=1;
   text="<html>
<head>ChangeLog</head>
<body>
<h1>ChangeLog</h1>
<ul>

<li>Wed Jan 16 20:47:30 2008 thazy <code>pat_assoc.proj</code><br>

<li>Wed Jan 16 20:39:57 2008 thazy <code>pat_assoc.proj</code><br>

<li>Wed Jan 16 20:39:34 2008 thazy <code>pat_assoc.proj</code><br>
</ul>
</body>
</html>
";
   html_text="<html>
<head>ChangeLog</head>
<body>
<h1>ChangeLog</h1>
<ul>
<P>
<li>Wed Jan 16 20:47:30 2008 thazy <code>pat_assoc.proj</code><br>
<P>
<li>Wed Jan 16 20:39:57 2008 thazy <code>pat_assoc.proj</code><br>
<P>
<li>Wed Jan 16 20:39:34 2008 thazy <code>pat_assoc.proj</code><br>
</ul>
</body>
</html>
";
  };
  taDoc @[1] {
   name="ProjectDocs";
   desc=;
   auto_open=1;
   web_doc=0;
   wiki=;
   url="local";
   full_url="local";
   text_size=1;
   text="<html>
<head></head>
<body>
= Pattern Associator =

* GENERAL USAGE NOTE: To start, it is usually a good idea to do <code>Object/Edit Dialog</code> in the menu just above this text, which will open this documentation in a separate window that you can more easily come back to.  Alternatively, you can just always return to this document by clicking on the <code>ProjectDocs</code> tab at the top of the middle panel.

== Exploration of Hebbian Task Learning (Section 5.2 in Text) ==

This exploration is based on a very simple form of task learning, where a set of 4 input units project to 2 output units.  The \"task\" is specified in terms of the relationships between patterns of activation over the input units, and the corresponding desired or '''target''' values of the output units.  This type of network is often called a '''pattern associator''' because the objective is to associate patterns of activity on the input with those on the output.

You should see the network in the <code>PatAssocNet</code> tab in the far right 3d view frame. Note that there are 2 output units receiving inputs from 4 input units through a set of feedforward weights (see also Figure 5.1 in the text).   

* Click the [[.T3Tab.EasyEnv]] tab at the top of 3D view panel (far right) to view the events in the environment. 

As you can see, the input-output relationships to be learned in this \"task\" are simply that the leftmost two input units should make the left output unit active, while the rightmost units should make the right output unit active.  This can be thought of as categorizing the first two inputs as \"left\" with the left output unit, and the next two as \"right\" with the right output unit. ''NOTE: Figure 5.2 in the text is configured differently than'' [[.T3Tab.EasyEnv]], ''but they are the same patterns. This is true for figures 5.3 and 5.7 as well.''

This is a relatively easy task to learn because the left output unit just has to develop strong weights to the leftmost input units and ignore the ones to the right, while the right output unit does the opposite.  Note that we are using kWTA inhibition within the output layer, with a ''k'' parameter of 1.

The network is trained on this task by simply clamping both the input and output units to their corresponding values from the events in the environment, and performing CPCA Hebbian learning on the resulting activations.  

* First, press the [[.T3Tab.PatAssocNet]] tab to reactivate it, then press the master [[.PanelTab.ControlPanel]] tab in the middle panel. Now press the <code>Init</code> button there (bottom), then <code>Step</code> 4 times while you watch the network. ''NOTE: For this exploration, you should always answer \"Yes\" to \"Initialize Network Weights?\" after <code>Init</code>.''

You should see all 4 events from the environment presented in a random order.  

* Now press <code>TestStep</code> 4 times. 

You will see the activations in the output units are different this time. This is because it was the testing phase, which is run after every epoch of training.  During this testing phase, all 4 events are presented to the network,  except this time the output units are not clamped to the correct answer, but are instead updated solely according to their current weights from the input units (which are clamped as before).  Thus, the testing phase records the current ''actual'' performance of the network on this task, when it is not being \"coached\" (that is why it's a test).

* Now click on the [[.T3Tab.TrialOutputGrid]] tab in the far right 3D view panel (followed by the <code>Refresh</code> button in the top right of the middle [[.PanelTab.TrialOutputGrid]] panel if the data is not displayed).

The results of the test run you just ran are displayed. Each row represents one of the four events, with the input pattern and the actual output activations shown on the right. The <code>sse</code> column reports the '''summed squared error''' (SSE), which is simply the summed difference between the actual output activation during testing (''o_k'') and the ''target'' value (''t_k'') that was clamped during training: 

* SSE = \\sum_k (t_k - o_k)^2 

where the sum is over the 2 output units.  We are actually computing the ''thresholded'' SSE, where absolute differences of less than 0.5 are treated as zero, so the unit just has to get the activation on the correct side of 0.5 to get zero error.  We thus treat the units as representing underlying binary quantities (i.e., whether the pattern that the unit detects is present or not), with the graded activation value expressing something like the likelihood of the underlying binary hypothesis being true.  All of our tasks specify binary input/output patterns.

With only a single training epoch, the output unit is likely making some errors.  

* Click on the [[.T3Tab.TrialOutputGrid]] tab in the far right panel if its not already active and then the master [[.PanelTab.ControlPanel]] tab in the middle panel.  Press the <code>Init</code> and <code>Run</code> buttons while you watch the grid in the right frame.

You will see the grid view update after each trial, <!-- epoch, --> showing the pattern of outputs and the individual SSE (<code>sse</code>) errors.  

* Next, click on the [[.T3Tab.EpochOutputGraph]] tab in the far right panel (and the <code>Refresh</code> button in the middle frame if necessary). 

Now you will see a summary plot across epochs of the sum of the thresholded SSE measure across all the events in the epoch.  This shows what is often referred to as the '''learning curve''' for the network, and it should have rapidly gone to zero, indicating that the network has learned the task.  Training will stop automatically after the network has exhibited 5 correct epochs in a row (just to make sure it has really learned the problem), or it stops after 30 epochs if it fails to learn.

Let's see what the network has learned.

* Click the [[.T3Tab.PatAssocNet]] tab in the (far right) panel to display the network.  Press the <code>TestStep</code> button in the master [[.PanelTab.ControlPanel]] 4 times.

This will step through each of the training patterns and update the [[.T3Tab.TrialOutputGrid]].  Click on it and hit <code>Refresh</code> as before to display the results. You should see that the network has learned this easy task, turning on the left output for the first two patterns, and the right one for the next two.  Now, let's take a look at the weights for the output unit to see exactly how this happened.

* Click on the [[.T3Tab.PatAssocNet]] tab in the right frame and then on the <code>r.wt</code> button along the top left margin. (You can also select the r.wt value in the middle panel that corresponds to the PatAssocNet --- you may have to scroll down --- it is near the bottom of the list of values.) Now click on the red arrow (\"Select\") tool in the right panel and select the left output unit in the network. 

You should see that, as expected, the weights from the left 2 units are strong (near 1), and those from the right 2 units are weak (near 0).  The complementary pattern should hold for the right output unit.

<hr>

'''Question 5.1''' <em>Explain why this pattern of strong and weak weights resulted from the CPCA Hebbian learning algorithm.</em>

<hr>

=== The Hard Task ===

Now, let's try a more difficult task.  

* Set <code>env_type</code> on the master [[.PanelTab.ControlPanel]] tab to <code>HARD</code>, and <code>Apply</code>.  Click the [[.T3Tab.HardEnv]] tab at the top of the far right panel to view the events in the <code>HARD</code> environment. 

In this harder environment (note: figure 5.3 in text is in a different format), there is overlap among the input patterns for cases where the left output should be on, and where it should be off (and the right output on). This overlap makes the task hard because the unit has to somehow figure out what the most distinguishing or ''task relevant'' input units are, and set its weights accordingly.

This task reveals a problem with Hebbian learning.  It is only concerned with the correlation (conditional probability) between the output and input units, so it cannot learn to be sensitive to which inputs are more task relevant than others (unless this happens to be the same as the input-output correlations, as in the easy task).  This hard task has a complicated pattern of overlap among the different input patterns.  For the two cases where the left output should be on, the middle two input units are very strongly correlated with the output activity (conditional probability P(x_i|y_j) = 1), while the outside two inputs are only half-correlated (P(x_i|y_j) = .5).  The two cases where the left output should be off (and the right one on) overlap considerably with those where it should be on, with the last event containing both of the highly correlated inputs.  Thus, if the network just pays attention to correlations, it will tend to respond incorrectly to this last case.

Let's see what happens when we run the network on this task.

* After making sure you are viewing the <code>r.wt</code> receiving weights of the left output unit in the [[.PanelTab.PatAssocNet]] tab in the middle panel, press the <code>Init</code> (\"Yes\" to \"Initialize Network Weights?\") and then <code>Run</code> buttons in the master [[.PanelTab.ControlPanel]], which runs the network after a new set of  random starting weights. 

You should see from these weights that the network has learned that the middle two units are highly correlated with the left output unit, as we expected.  

NOTE: Repeat the Init->Run sequence a couple of times to allow the TestStep (below) to load the HARD events. 

* Return to viewing the <code>act</code> variable ([[.PanelTab.PatAssocNet]]) and then do <code>TestStep</code> 4 times (master [[.PanelTab.ControlPanel]]).

You should see that the network is not getting all the right answers.  ''(Hint: You can also look at the'' [[.T3Tab.TrialOutputGrid]] ''to see all events at once.)'' Different runs will produce slightly different results, but the first two events should generally turn the left output unit on (correctly), the third event should (correctly) turn on the right unit after at least some of the runs, but the fourth unit should pretty much always (incorrectly) turn on the left unit because of the strength of the weights from the middle two input units to the left output unit.

The weights to the right output unit (<code>r.wt</code> in the [[.T3Tab.PatAssocNet]] tab of the middle panel show that it has strongly represented its correlation with the second input unit, which explains the pattern of output responses.  This weight to the right output unit can have a net stronger effect than those to the left output unit from the two middle inputs because of the different overall activity levels in the different input patterns --- this difference in alpha affects the renormalization correction for the CPCA Hebbian learning rule as described earlier in the text (note that even if this renormalization is set to a constant across the different events, the network still fails to learn). For the fourth event, however, the \"double dose\" of the strong weights from the two middle units favors the left unit leading to a consistent error.

* Do several more <code>Run</code>s on this <code>HARD</code> task. You can try increasing the <code>max_epochs</code> parameter to 50, or even 100, in the master [[.PanelTab.ControlPanel]] if you wish.

<hr>

'''Question 5.2 (a)''' <em>Does the network ever solve the task? '''(b)''' Report the final  <code>sse</code> at the end of training for each run.</em>

<hr>

* Experiment with the parameters that control the contrast enhancement of the CPCA Hebbian learning rule (<code>wt_sig.gain</code> and <code>wt_sig.off</code>), to see if these are playing an important role in the network's behavior.

You should see that changes to these parameters do not lead to any substantial improvements.  Hebbian learning does not seem to be able to solve tasks where the correlations do not provide the appropriate weight values.  It seems unlikely that there will generally be a coincidence between correlational structure and the task solution. Thus, we must conclude that Hebbian learning is of limited use for task learning.  In contrast, we will see in the next section that an algorithm specifically designed for task learning can learn this task without much difficulty.

* To continue on to the next simulation, you can leave this project open because we will use it again.  Or, if you wish to stop now, and come back to it later, quit by selecting <code>File->CloseProject</code> in the main project window and then <code>File->Quit</code> in the <code>.viewers[0](root)</code> window.

== Exploration of Delta Rule Task Learning (Section 5.5 in Text) ==

* Reset the parameters to their default values using the <code>Defaults</code> button in the master [[.PanelTab.ControlPanel]] (\"Yes\" to \"Initialize Network Weights\").

* Select <code>DELTA</code> instead of <code>HEBB</code> for the <code>learn_rule value</code> in the master [[.PanelTab.ControlPanel]] and click <code>Apply</code> and then, while watching the '''Learning Parameters''' fields, click <code>SetLearnRule</code>.

This will switch weight updating from the default CPCA Hebbian rule explored previously to the delta rule.  The effects of this switch can be seen in the <code>Learning Parameters</code> group, which shows the learning rate for the weights (<code>lrate</code>, always .01) and for the bias weights (<code>bias_lrate</code>, which is 0 for Hebbian learning because it has no way of training the bias weights, and is equal to <code>lrate</code> for delta rule), and the proportion of Hebbian learning (<code>hebb</code>, 1 or 0 --- we will see in the next chapter that intermediate values of this parameter can be used as well). '''IMPORTANT: Note that it is pressing the <code>SetLearnRule</code> button that actually changes the <code>Learning Parameters</code> values.'''

Before training the network, we will explore how the minus-plus activation phases work in the simulator.   

* Make sure that you are monitoring ''activations'' in the network by selecting the <code>act</code> button along the top left margin, or in the [[.T3Tab.PatAssocNet]] middle panel where it should be highlighted once chosen. Also make sure the <code>Display!</code> checkbox in checked. Next, set <code>step_prog</code> to <code>LeabraSettle</code> instead of <code>LeabraTrial</code> in the master [[.PanelTab.ControlPanel]].

This will increase the resolution of the stepping so that each press of the <code>Step</code> button will perform only the settling (iterative activation updating) process associated with one phase of processing at a time. 

* Next hit the <code>Step</code> button.

You will see in the network the actual activation produced in response to the input pattern (also known as the ''expectation'' or ''response,'' or ''minus phase'' activation).

* Now, hit <code>Step</code> again.

You will see the target (also known as the ''outcome,'' or ''instruction,'' or ''plus phase'') activation.  Learning occurs after this second, plus phase of activation.  You can recognize targets, like all external inputs, because their activations are exactly .95 or 0 -- note that we are clamping activations to .95 (not 1.0) because units cannot easily produce activations above .95 with typical net input values due to the saturating nonlinearity of the rate code activation function.  You can also switch to viewing the <code>targ</code> value (2 above <code>act</code> in the [[.PanelTab.PatAssocNet]] tab in the middle panel), which will show you the target inputs prior to the activation clamping.  In addition, the minus phase activation is always viewable as <code>act_m</code> and the plus phase as <code>act_p</code>.

Now, let's monitor the weights.

* Click on <code>r.wt</code> to monitor receiving weights.  Then click on the Red Arrow tool in the top right corner of the [[.T3Tab.PatAssocNet]] and select the left output unit. Click <code>Init</code> and <code>Run</code> in the master [[.PanelTab.ControlPanel]] to complete the training on this [[.T3Tab.EasyEnv]] task.

The network has no trouble learning this task -- you can click on the [[.T3Tab.EpochOutputGraph]] tab (with <code>Refresh</code> if necessary) to confirm.  However, if you perform multiple <code>Run</code> 's, you should be able to notice that the final weight values are quite variable relative to the Hebbian case (you can always switch the <code>LearnRule</code> back to <code>HEBB</code> in the master control panel to compare between the two learning algorithms). In particular, you might note that there is a much less clear cut differentiation between the first two units vs. the last two in the <code>DELTA</code> rule case.

This variability in the weights reflects a critical weakness of error-driven learning -- it's ''lazy''. Basically, once the output unit is performing the task correctly, learning effectively stops, with whatever weight values that happened to do the trick.  In contrast, Hebbian learning keeps adapting the weights to reflect the conditional probabilities, which, in this task, results in roughly the same final weight values regardless of what the initial random weights were.  We will return to this issue later in Chapteer 6, when we discuss the benefits of using a combination of Hebbian and error-driven learning.

Now for the real test.

* Set <code>env_type</code> to <code>HARD</code> in the master [[.PanelTab.ControlPanel]] and also change the <code>max_epoch</code> parameter to 50.  Then, press <code>Init</code> and <code>Run</code>. Click on the [[.T3Tab.EpochOutputGraph]] tab in the far right frame to watch the learning curve.

You should see that the network learns this task without much difficulty (although it sometimes needs > 30 epochs).  Thus, because the delta rule performs learning as a function of how well the network is actually doing, it can adapt the weights specifically to solve the task.

<hr>

'''Question 5.3 (a)''' <em>Compare and contrast in a qualitative manner the nature of the weights learned by the delta rule on this <code>HARD</code> task with those learned by the Hebbian rule (e.g., note where the largest weights tend to be) -- be sure to do multiple runs to get a general sense of what tends to be learned. '''(b)''' Using your answer to the first part, explain why the delta rule weights solve the problem, but the Hebbian ones do not (don't forget to include the bias weights <code>bias.wt</code> in your analysis of the delta rule case).</em>

<hr>

After this experience, you may think that the delta rule is all powerful, but we can temper this enthusiasm and motivate the next section.  

* Set <code>env_type</code> to <code>IMPOSSIBLE</code>.  Then, click on the [[.T3Tab.ImpossibleEnv]] tab in the far right panel. (Note that figure 5.7 in the text has a different layout.)

Notice that each input unit in this environment is active equally often when the output is active as when it is inactive. That is, there is complete overlap among the patterns that activate the different output units. These kinds of problems are called ''ambiguous cue'' problems, or ''nonlinear discrimination'' problems (Sutherland & Rudy, 1989; O'Reilly & Rudy, 2000). This kind of problem might prove difficult, because every input unit will end up being equivocal about what the output should do.  Nevertheless, the input patterns are not all the same -- people could learn to solve this task fairly trivially by just paying attention to the overall patterns of activation.  Let's see if the network can do this.

* Press <code>Init</code> and <code>Run</code> on the master [[.PanelTab.ControlPanel]]. Activate the [[.T3Tab.EpochOutputGraph]] tab again to watch the learning curve.

Do it again.  And again.  Any luck? If you wish, you can increase the max_epochs to 100, or even 150, if you wish -- and see if it learns.

Because the delta rule cannot learn what appears to be a relatively simple task, we conclude that something more powerful is necessary. Unfortunately, that is not the conclusion that Minsky & Papert (1969) reached in their highly influential book, ''Perceptrons''.  Instead, they concluded that neural networks were hopelessly inadequate because they could not solve problems like the one we just explored. (Specifically, they focused on the exclusive-or (XOR) task)!  This conclusion played a large role in the waning of the early interest in neural network models of the 1960s.  Interestingly, we will see that only a few more applications of the chain rule are necessary to remedy the problem, but this fact took a while to be appreciated by most people (roughly fifteen years, in fact).

* To continue on to the next simulation, close this project first by selecting <code>File->Close Project</code>. It's probably better to not save upon closing so you can sure the exercises will work when reopened. Or, if you wish to stop now, quit by then selecting <code>File->Quit</code> in the <code>.viewers[0](root) window.

</body>
</html>
";
   html_text="<html><head></head><body>
<h1> Pattern Associator </h1>
<p>
</p><ul><li> GENERAL USAGE NOTE: To start, it is usually a good idea to do <code>Object/Edit Dialog</code> in the menu just above this text, which will open this documentation in a separate window that you can more easily come back to.  Alternatively, you can just always return to this document by clicking on the <code>ProjectDocs</code> tab at the top of the middle panel.
</li></ul>
<h2> Exploration of Hebbian Task Learning (Section 5.2 in Text) </h2>
<p>
This exploration is based on a very simple form of task learning, where a set of 4 input units project to 2 output units.  The \"task\" is specified in terms of the relationships between patterns of activation over the input units, and the corresponding desired or  <b>target</b>  values of the output units.  This type of network is often called a  <b>pattern associator</b>  because the objective is to associate patterns of activity on the input with those on the output.
</p><p>
You should see the network in the <code>PatAssocNet</code> tab in the far right 3d view frame. Note that there are 2 output units receiving inputs from 4 input units through a set of feedforward weights (see also Figure 5.1 in the text).   
</p><p>
</p><ul><li> Click the <a href=\"ta:.T3Tab.EasyEnv\">EasyEnv</a> tab at the top of 3D view panel (far right) to view the events in the environment. 
</li></ul>
As you can see, the input-output relationships to be learned in this \"task\" are simply that the leftmost two input units should make the left output unit active, while the rightmost units should make the right output unit active.  This can be thought of as categorizing the first two inputs as \"left\" with the left output unit, and the next two as \"right\" with the right output unit.  <i>NOTE: Figure 5.2 in the text is configured differently than</i>  <a href=\"ta:.T3Tab.EasyEnv\">EasyEnv</a>,  <i>but they are the same patterns. This is true for figures 5.3 and 5.7 as well.</i> 
<p>
This is a relatively easy task to learn because the left output unit just has to develop strong weights to the leftmost input units and ignore the ones to the right, while the right output unit does the opposite.  Note that we are using kWTA inhibition within the output layer, with a  <i>k</i>  parameter of 1.
</p><p>
The network is trained on this task by simply clamping both the input and output units to their corresponding values from the events in the environment, and performing CPCA Hebbian learning on the resulting activations.  
</p><p>
</p><ul><li> First, press the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> tab to reactivate it, then press the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> tab in the middle panel. Now press the <code>Init</code> button there (bottom), then <code>Step</code> 4 times while you watch the network.  <i>NOTE: For this exploration, you should always answer \"Yes\" to \"Initialize Network Weights?\" after <code>Init</code>.</i> 
</li></ul>
You should see all 4 events from the environment presented in a random order.  
<p>
</p><ul><li> Now press <code>TestStep</code> 4 times. 
</li></ul>
You will see the activations in the output units are different this time. This is because it was the testing phase, which is run after every epoch of training.  During this testing phase, all 4 events are presented to the network,  except this time the output units are not clamped to the correct answer, but are instead updated solely according to their current weights from the input units (which are clamped as before).  Thus, the testing phase records the current  <i>actual</i>  performance of the network on this task, when it is not being \"coached\" (that is why it's a test).
<p>
</p><ul><li> Now click on the <a href=\"ta:.T3Tab.TrialOutputGrid\">TrialOutputGrid</a> tab in the far right 3D view panel (followed by the <code>Refresh</code> button in the top right of the middle <a href=\"ta:.PanelTab.TrialOutputGrid\">TrialOutputGrid</a> panel if the data is not displayed).
</li></ul>
The results of the test run you just ran are displayed. Each row represents one of the four events, with the input pattern and the actual output activations shown on the right. The <code>sse</code> column reports the  <b>summed squared error</b>  (SSE), which is simply the summed difference between the actual output activation during testing ( <i>o_k</i> ) and the  <i>target</i>  value ( <i>t_k</i> ) that was clamped during training: 
<p>
</p><ul><li> SSE = \\sum_k (t_k - o_k)^2 
</li></ul>
where the sum is over the 2 output units.  We are actually computing the  <i>thresholded</i>  SSE, where absolute differences of less than 0.5 are treated as zero, so the unit just has to get the activation on the correct side of 0.5 to get zero error.  We thus treat the units as representing underlying binary quantities (i.e., whether the pattern that the unit detects is present or not), with the graded activation value expressing something like the likelihood of the underlying binary hypothesis being true.  All of our tasks specify binary input/output patterns.
<p>
With only a single training epoch, the output unit is likely making some errors.  
</p><p>
</p><ul><li> Click on the <a href=\"ta:.T3Tab.TrialOutputGrid\">TrialOutputGrid</a> tab in the far right panel if its not already active and then the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> tab in the middle panel.  Press the <code>Init</code> and <code>Run</code> buttons while you watch the grid in the right frame.
</li></ul>
You will see the grid view update after each trial, <!-- epoch, --> showing the pattern of outputs and the individual SSE (<code>sse</code>) errors.  
<p>
</p><ul><li> Next, click on the <a href=\"ta:.T3Tab.EpochOutputGraph\">EpochOutputGraph</a> tab in the far right panel (and the <code>Refresh</code> button in the middle frame if necessary). 
</li></ul>
Now you will see a summary plot across epochs of the sum of the thresholded SSE measure across all the events in the epoch.  This shows what is often referred to as the  <b>learning curve</b>  for the network, and it should have rapidly gone to zero, indicating that the network has learned the task.  Training will stop automatically after the network has exhibited 5 correct epochs in a row (just to make sure it has really learned the problem), or it stops after 30 epochs if it fails to learn.
<p>
Let's see what the network has learned.
</p><p>
</p><ul><li> Click the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> tab in the (far right) panel to display the network.  Press the <code>TestStep</code> button in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> 4 times.
</li></ul>
This will step through each of the training patterns and update the <a href=\"ta:.T3Tab.TrialOutputGrid\">TrialOutputGrid</a>.  Click on it and hit <code>Refresh</code> as before to display the results. You should see that the network has learned this easy task, turning on the left output for the first two patterns, and the right one for the next two.  Now, let's take a look at the weights for the output unit to see exactly how this happened.
<p>
</p><ul><li> Click on the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> tab in the right frame and then on the <code>r.wt</code> button along the top left margin. (You can also select the r.wt value in the middle panel that corresponds to the PatAssocNet --- you may have to scroll down --- it is near the bottom of the list of values.) Now click on the red arrow (\"Select\") tool in the right panel and select the left output unit in the network. 
</li></ul>
You should see that, as expected, the weights from the left 2 units are strong (near 1), and those from the right 2 units are weak (near 0).  The complementary pattern should hold for the right output unit.
<p>
</p><hr>
<p>
 <b>Question 5.1</b>  <em>Explain why this pattern of strong and weak weights resulted from the CPCA Hebbian learning algorithm.</em>
</p><p>
</p><hr>
<p>
</p><h3> The Hard Task </h3>
<p>
Now, let's try a more difficult task.  
</p><p>
</p><ul><li> Set <code>env_type</code> on the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> tab to <code>HARD</code>, and <code>Apply</code>.  Click the <a href=\"ta:.T3Tab.HardEnv\">HardEnv</a> tab at the top of the far right panel to view the events in the <code>HARD</code> environment. 
</li></ul>
In this harder environment (note: figure 5.3 in text is in a different format), there is overlap among the input patterns for cases where the left output should be on, and where it should be off (and the right output on). This overlap makes the task hard because the unit has to somehow figure out what the most distinguishing or  <i>task relevant</i>  input units are, and set its weights accordingly.
<p>
This task reveals a problem with Hebbian learning.  It is only concerned with the correlation (conditional probability) between the output and input units, so it cannot learn to be sensitive to which inputs are more task relevant than others (unless this happens to be the same as the input-output correlations, as in the easy task).  This hard task has a complicated pattern of overlap among the different input patterns.  For the two cases where the left output should be on, the middle two input units are very strongly correlated with the output activity (conditional probability P(x_i|y_j) = 1), while the outside two inputs are only half-correlated (P(x_i|y_j) = .5).  The two cases where the left output should be off (and the right one on) overlap considerably with those where it should be on, with the last event containing both of the highly correlated inputs.  Thus, if the network just pays attention to correlations, it will tend to respond incorrectly to this last case.
</p><p>
Let's see what happens when we run the network on this task.
</p><p>
</p><ul><li> After making sure you are viewing the <code>r.wt</code> receiving weights of the left output unit in the <a href=\"ta:.PanelTab.PatAssocNet\">PatAssocNet</a> tab in the middle panel, press the <code>Init</code> (\"Yes\" to \"Initialize Network Weights?\") and then <code>Run</code> buttons in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a>, which runs the network after a new set of  random starting weights. 
</li></ul>
You should see from these weights that the network has learned that the middle two units are highly correlated with the left output unit, as we expected.  
<p>
NOTE: Repeat the Init-&gt;Run sequence a couple of times to allow the TestStep (below) to load the HARD events. 
</p><p>
</p><ul><li> Return to viewing the <code>act</code> variable (<a href=\"ta:.PanelTab.PatAssocNet\">PatAssocNet</a>) and then do <code>TestStep</code> 4 times (master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a>).
</li></ul>
You should see that the network is not getting all the right answers.   <i>(Hint: You can also look at the</i>  <a href=\"ta:.T3Tab.TrialOutputGrid\">TrialOutputGrid</a>  <i>to see all events at once.)</i>  Different runs will produce slightly different results, but the first two events should generally turn the left output unit on (correctly), the third event should (correctly) turn on the right unit after at least some of the runs, but the fourth unit should pretty much always (incorrectly) turn on the left unit because of the strength of the weights from the middle two input units to the left output unit.
<p>
The weights to the right output unit (<code>r.wt</code> in the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> tab of the middle panel show that it has strongly represented its correlation with the second input unit, which explains the pattern of output responses.  This weight to the right output unit can have a net stronger effect than those to the left output unit from the two middle inputs because of the different overall activity levels in the different input patterns --- this difference in alpha affects the renormalization correction for the CPCA Hebbian learning rule as described earlier in the text (note that even if this renormalization is set to a constant across the different events, the network still fails to learn). For the fourth event, however, the \"double dose\" of the strong weights from the two middle units favors the left unit leading to a consistent error.
</p><p>
</p><ul><li> Do several more <code>Run</code>s on this <code>HARD</code> task. You can try increasing the <code>max_epochs</code> parameter to 50, or even 100, in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> if you wish.
</li></ul>
<hr>
<p>
 <b>Question 5.2 (a)</b>  <em>Does the network ever solve the task?  <b>(b)</b>  Report the final  <code>sse</code> at the end of training for each run.</em>
</p><p>
</p><hr>
<p>
</p><ul><li> Experiment with the parameters that control the contrast enhancement of the CPCA Hebbian learning rule (<code>wt_sig.gain</code> and <code>wt_sig.off</code>), to see if these are playing an important role in the network's behavior.
</li></ul>
You should see that changes to these parameters do not lead to any substantial improvements.  Hebbian learning does not seem to be able to solve tasks where the correlations do not provide the appropriate weight values.  It seems unlikely that there will generally be a coincidence between correlational structure and the task solution. Thus, we must conclude that Hebbian learning is of limited use for task learning.  In contrast, we will see in the next section that an algorithm specifically designed for task learning can learn this task without much difficulty.
<p>
</p><ul><li> To continue on to the next simulation, you can leave this project open because we will use it again.  Or, if you wish to stop now, and come back to it later, quit by selecting <code>File-&gt;CloseProject</code> in the main project window and then <code>File-&gt;Quit</code> in the <code>.viewers[0](root)</code> window.
</li></ul>
<h2> Exploration of Delta Rule Task Learning (Section 5.5 in Text) </h2>
<p>
</p><ul><li> Reset the parameters to their default values using the <code>Defaults</code> button in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> (\"Yes\" to \"Initialize Network Weights\").
</li></ul>
<ul><li> Select <code>DELTA</code> instead of <code>HEBB</code> for the <code>learn_rule value</code> in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> and click <code>Apply</code> and then, while watching the  <b>Learning Parameters</b>  fields, click <code>SetLearnRule</code>.
</li></ul>
This will switch weight updating from the default CPCA Hebbian rule explored previously to the delta rule.  The effects of this switch can be seen in the <code>Learning Parameters</code> group, which shows the learning rate for the weights (<code>lrate</code>, always .01) and for the bias weights (<code>bias_lrate</code>, which is 0 for Hebbian learning because it has no way of training the bias weights, and is equal to <code>lrate</code> for delta rule), and the proportion of Hebbian learning (<code>hebb</code>, 1 or 0 --- we will see in the next chapter that intermediate values of this parameter can be used as well).  <b>IMPORTANT: Note that it is pressing the <code>SetLearnRule</code> button that actually changes the <code>Learning Parameters</code> values.</b> 
<p>
Before training the network, we will explore how the minus-plus activation phases work in the simulator.   
</p><p>
</p><ul><li> Make sure that you are monitoring  <i>activations</i>  in the network by selecting the <code>act</code> button along the top left margin, or in the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> middle panel where it should be highlighted once chosen. Also make sure the <code>Display!</code> checkbox in checked. Next, set <code>step_prog</code> to <code>LeabraSettle</code> instead of <code>LeabraTrial</code> in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a>.
</li></ul>
This will increase the resolution of the stepping so that each press of the <code>Step</code> button will perform only the settling (iterative activation updating) process associated with one phase of processing at a time. 
<p>
</p><ul><li> Next hit the <code>Step</code> button.
</li></ul>
You will see in the network the actual activation produced in response to the input pattern (also known as the  <i>expectation</i>  or  <i>response,</i>  or  <i>minus phase</i>  activation).
<p>
</p><ul><li> Now, hit <code>Step</code> again.
</li></ul>
You will see the target (also known as the  <i>outcome,</i>  or  <i>instruction,</i>  or  <i>plus phase</i> ) activation.  Learning occurs after this second, plus phase of activation.  You can recognize targets, like all external inputs, because their activations are exactly .95 or 0 -- note that we are clamping activations to .95 (not 1.0) because units cannot easily produce activations above .95 with typical net input values due to the saturating nonlinearity of the rate code activation function.  You can also switch to viewing the <code>targ</code> value (2 above <code>act</code> in the <a href=\"ta:.PanelTab.PatAssocNet\">PatAssocNet</a> tab in the middle panel), which will show you the target inputs prior to the activation clamping.  In addition, the minus phase activation is always viewable as <code>act_m</code> and the plus phase as <code>act_p</code>.
<p>
Now, let's monitor the weights.
</p><p>
</p><ul><li> Click on <code>r.wt</code> to monitor receiving weights.  Then click on the Red Arrow tool in the top right corner of the <a href=\"ta:.T3Tab.PatAssocNet\">PatAssocNet</a> and select the left output unit. Click <code>Init</code> and <code>Run</code> in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> to complete the training on this <a href=\"ta:.T3Tab.EasyEnv\">EasyEnv</a> task.
</li></ul>
The network has no trouble learning this task -- you can click on the <a href=\"ta:.T3Tab.EpochOutputGraph\">EpochOutputGraph</a> tab (with <code>Refresh</code> if necessary) to confirm.  However, if you perform multiple <code>Run</code> 's, you should be able to notice that the final weight values are quite variable relative to the Hebbian case (you can always switch the <code>LearnRule</code> back to <code>HEBB</code> in the master control panel to compare between the two learning algorithms). In particular, you might note that there is a much less clear cut differentiation between the first two units vs. the last two in the <code>DELTA</code> rule case.
<p>
This variability in the weights reflects a critical weakness of error-driven learning -- it's  <i>lazy</i> . Basically, once the output unit is performing the task correctly, learning effectively stops, with whatever weight values that happened to do the trick.  In contrast, Hebbian learning keeps adapting the weights to reflect the conditional probabilities, which, in this task, results in roughly the same final weight values regardless of what the initial random weights were.  We will return to this issue later in Chapteer 6, when we discuss the benefits of using a combination of Hebbian and error-driven learning.
</p><p>
Now for the real test.
</p><p>
</p><ul><li> Set <code>env_type</code> to <code>HARD</code> in the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a> and also change the <code>max_epoch</code> parameter to 50.  Then, press <code>Init</code> and <code>Run</code>. Click on the <a href=\"ta:.T3Tab.EpochOutputGraph\">EpochOutputGraph</a> tab in the far right frame to watch the learning curve.
</li></ul>
You should see that the network learns this task without much difficulty (although it sometimes needs &gt; 30 epochs).  Thus, because the delta rule performs learning as a function of how well the network is actually doing, it can adapt the weights specifically to solve the task.
<p>
</p><hr>
<p>
 <b>Question 5.3 (a)</b>  <em>Compare and contrast in a qualitative manner the nature of the weights learned by the delta rule on this <code>HARD</code> task with those learned by the Hebbian rule (e.g., note where the largest weights tend to be) -- be sure to do multiple runs to get a general sense of what tends to be learned.  <b>(b)</b>  Using your answer to the first part, explain why the delta rule weights solve the problem, but the Hebbian ones do not (don't forget to include the bias weights <code>bias.wt</code> in your analysis of the delta rule case).</em>
</p><p>
</p><hr>
<p>
After this experience, you may think that the delta rule is all powerful, but we can temper this enthusiasm and motivate the next section.  
</p><p>
</p><ul><li> Set <code>env_type</code> to <code>IMPOSSIBLE</code>.  Then, click on the <a href=\"ta:.T3Tab.ImpossibleEnv\">ImpossibleEnv</a> tab in the far right panel. (Note that figure 5.7 in the text has a different layout.)
</li></ul>
Notice that each input unit in this environment is active equally often when the output is active as when it is inactive. That is, there is complete overlap among the patterns that activate the different output units. These kinds of problems are called  <i>ambiguous cue</i>  problems, or  <i>nonlinear discrimination</i>  problems (Sutherland &amp; Rudy, 1989; O'Reilly &amp; Rudy, 2000). This kind of problem might prove difficult, because every input unit will end up being equivocal about what the output should do.  Nevertheless, the input patterns are not all the same -- people could learn to solve this task fairly trivially by just paying attention to the overall patterns of activation.  Let's see if the network can do this.
<p>
</p><ul><li> Press <code>Init</code> and <code>Run</code> on the master <a href=\"ta:.PanelTab.ControlPanel\">ControlPanel</a>. Activate the <a href=\"ta:.T3Tab.EpochOutputGraph\">EpochOutputGraph</a> tab again to watch the learning curve.
</li></ul>
Do it again.  And again.  Any luck? If you wish, you can increase the max_epochs to 100, or even 150, if you wish -- and see if it learns.
<p>
Because the delta rule cannot learn what appears to be a relatively simple task, we conclude that something more powerful is necessary. Unfortunately, that is not the conclusion that Minsky &amp; Papert (1969) reached in their highly influential book,  <i>Perceptrons</i> .  Instead, they concluded that neural networks were hopelessly inadequate because they could not solve problems like the one we just explored. (Specifically, they focused on the exclusive-or (XOR) task)!  This conclusion played a large role in the waning of the early interest in neural network models of the 1960s.  Interestingly, we will see that only a few more applications of the chain rule are necessary to remedy the problem, but this fact took a while to be appreciated by most people (roughly fifteen years, in fact).
</p><p>
</p><ul><li> To continue on to the next simulation, close this project first by selecting <code>File-&gt;Close Project</code>. It's probably better to not save upon closing so you can sure the exercises will work when reopened. Or, if you wish to stop now, quit by then selecting <code>File-&gt;Quit</code> in the <code>.viewers[0](root) window.
</code></li></ul><code>


</code></body></html>";
  };
  taDoc @[2] {
   name="WikiDoc";
   desc=;
   auto_open=0;
   web_doc=1;
   wiki="CCN";
   url="CECN1_Pattern_Associator";
   full_url="http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Pattern_Associator";
   text_size=1;
   text="<html>
<head></head>
<body>
== Enter Title Here ==
</body>
</html>
";
   html_text="<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\" dir=\"ltr\"><head>
		<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">
		<meta http-equiv=\"Content-Style-Type\" content=\"text/css\">
		<meta name=\"generator\" content=\"MediaWiki 1.16alpha-wmf\">
		<meta name=\"keywords\" content=\"CECN1 Pattern Associator,CECN1 Projects,Emergent,pat assoc screenshots,.T3Tab.EasyEnv,.T3Tab.PatAssocNet,.PanelTab.ControlPanel,.T3Tab.TrialOutputGrid,.PanelTab.TrialOutputGrid,.T3Tab.EpochOutputGraph,.T3Tab.HardEnv\">
		<link rel=\"shortcut icon\" href=\"/emergent/favicon.ico\">
		<link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/CompCogNeuro/opensearch_desc.php\" title=\"Computational Cognitive Neuroscience Wiki (en)\">
		<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Computational Cognitive Neuroscience Wiki RSS Feed\" href=\"/CompCogNeuro/index.php?title=Special:RecentChanges&amp;feed=rss\">
		<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Computational Cognitive Neuroscience Wiki Atom Feed\" href=\"/CompCogNeuro/index.php?title=Special:RecentChanges&amp;feed=atom\">
		<title>CECN1 Pattern Associator - Computational Cognitive Neuroscience Wiki</title>
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/common/shared.css?233z\" type=\"text/css\" media=\"screen\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/common/commonPrint.css?233z\" type=\"text/css\" media=\"print\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/main.css?233z\" type=\"text/css\" media=\"screen\">
		<!--[if lt IE 5.5000]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE50Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 5.5000]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE55Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 6]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE60Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 7]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE70Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\" media=\"print\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=-&amp;action=raw&amp;maxage=18000&amp;gen=css\" type=\"text/css\">
		<!--[if lt IE 7]><script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/IEFixes.js?233z\"></script>
		<meta http-equiv=\"imagetoolbar\" content=\"no\" /><![endif]-->

		<script type=\"text/javascript\">/*<![CDATA[*/
		var skin = \"monobook\";
		var stylepath = \"/CompCogNeuro/skins\";
		var wgArticlePath = \"/CompCogNeuro/index.php/$1\";
		var wgScriptPath = \"/CompCogNeuro\";
		var wgScript = \"/CompCogNeuro/index.php\";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = \"http://grey.colorado.edu\";
		var wgCanonicalNamespace = \"\";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = \"CECN1_Pattern_Associator\";
		var wgTitle = \"CECN1 Pattern Associator\";
		var wgAction = \"view\";
		var wgArticleId = \"70\";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = \"en\";
		var wgContentLanguage = \"en\";
		var wgBreakFrames = false;
		var wgCurRevisionId = 313;
		var wgVersion = \"1.16alpha-wmf\";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = [\"\", \"\"];
		var wgDigitTransformTable = [\"\", \"\"];
		var wgMainPageTitle = \"Main Page\";
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		var wgFCKEditorDir = \"extensions/FCKeditor/fckeditor/\";
		var wgFCKEditorExtDir = \"extensions/FCKeditor\";
		var wgFCKEditorToolbarSet = \"Wiki\";
		var wgFCKEditorHeight = \"0\";
		/*]]>*/</script>

		<script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/wikibits.js?233z\"><!-- wikibits js --></script><style type=\"text/css\">@import \"/CompCogNeuro/skins/monobook/KHTMLFixes.css\";</style>
		<!-- Head Scripts -->
		<script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/ajax.js?233z\"></script>
		<script type=\"text/javascript\" src=\"/CompCogNeuro/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook\"><!-- site js --></script>
	<style type=\"text/css\">@import \"/CompCogNeuro/extensions/Collection/collection/Gadget-navpop.css?2\";</style></head><body class=\"mediawiki ltr ns-0 ns-subject page-CECN1_Pattern_Associator skin-monobook\">
	<div id=\"globalWrapper\">
		<div id=\"column-content\">
	<div id=\"content\">
		<a name=\"top\" id=\"top\"></a>
				<h1 id=\"firstHeading\" class=\"firstHeading\">CECN1 Pattern Associator</h1>
		<div id=\"bodyContent\">
			<h3 id=\"siteSub\">From Computational Cognitive Neuroscience Wiki</h3>
			<div id=\"contentSub\"></div>
									<div id=\"jump-to-nav\">Jump to: <a href=\"#column-one\">navigation</a>, <a href=\"#searchInput\">search</a></div>			<!-- start content -->
			<table id=\"toc\" class=\"toc\" summary=\"Contents\"><tbody><tr><td><div id=\"toctitle\"><h2>Contents</h2> <span class=\"toctoggle\">[<a id=\"togglelink\" class=\"internal\" href=\"javascript:toggleToc()\">hide</a>]</span></div>
<ul>
<li class=\"toclevel-1\"><a href=\"#Pattern_Associator_.28Task_Learning.29\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Pattern Associator (Task Learning)</span></a></li>
<li class=\"toclevel-1\"><a href=\"#Project_Documentation\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Project Documentation</span></a>
<ul>
<li class=\"toclevel-2\"><a href=\"#Exploration_of_Hebbian_Task_Learning_.28Section_5.2_in_Text.29\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Exploration of Hebbian Task Learning (Section 5.2 in Text)</span></a>
<ul>
<li class=\"toclevel-3\"><a href=\"#The_Hard_Task\"><span class=\"tocnumber\">2.1.1</span> <span class=\"toctext\">The Hard Task</span></a></li>
</ul>
</li>
<li class=\"toclevel-2\"><a href=\"#Exploration_of_Delta_Rule_Task_Learning_.28Section_5.5_in_Text.29\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Exploration of Delta Rule Task Learning (Section 5.5 in Text)</span></a></li>
</ul>
</li>
</ul>
</td></tr></tbody></table><script type=\"text/javascript\"> if (window.showTocToggle) { var tocShowText = \"show\"; var tocHideText = \"hide\"; showTocToggle(); } </script>
<a name=\"Pattern_Associator_.28Task_Learning.29\" id=\"Pattern_Associator_.28Task_Learning.29\"></a><h1> <span class=\"mw-headline\"> Pattern Associator (Task Learning) </span></h1>
<ul><li> The project file: <a href=\"/mediawiki/sites/CompCogNeuro/images/e/eb/pat_assoc.proj\" class=\"internal\" title=\"pat assoc.proj\">pat_assoc.proj</a> (click and Save As to download, then open in <a href=\"/CompCogNeuro/index.php/Emergent\" title=\"Emergent\">Emergent</a>)
</li><li> <a href=\"/CompCogNeuro/index.php/pat_assoc_screenshots\" title=\"pat assoc screenshots\">pat_assoc screenshots</a> -- for incorporation in PowerPoint slides, etc.
</li></ul>
<p>Back to <a href=\"/CompCogNeuro/index.php/CECN1_Projects\" title=\"CECN1 Projects\">CECN1 Projects</a>
</p>
<a name=\"Project_Documentation\" id=\"Project_Documentation\"></a><h1> <span class=\"mw-headline\"> Project Documentation </span></h1>
<p>(note: this is a literal copy from the simulation documentation -- it contains links that will not work within the wiki)
</p>
<ul><li> GENERAL USAGE NOTE: To start, it is usually a good idea to do <code>Object/Edit Dialog</code> in the menu just above this text, which will open this documentation in a separate window that you can more easily come back to.  Alternatively, you can just always return to this document by clicking on the <code>ProjectDocs</code> tab at the top of the middle panel.
</li></ul>
<a name=\"Exploration_of_Hebbian_Task_Learning_.28Section_5.2_in_Text.29\" id=\"Exploration_of_Hebbian_Task_Learning_.28Section_5.2_in_Text.29\"></a><h2> <span class=\"mw-headline\"> Exploration of Hebbian Task Learning (Section 5.2 in Text) </span></h2>
<p>This exploration is based on a very simple form of task learning, where a set of 4 input units project to 2 output units.  The \"task\" is specified in terms of the relationships between patterns of activation over the input units, and the corresponding desired or <b>target</b> values of the output units.  This type of network is often called a <b>pattern associator</b> because the objective is to associate patterns of activity on the input with those on the output.
</p><p>You should see the network in the <code>PatAssocNet</code> tab in the far right 3d view frame. Note that there are 2 output units receiving inputs from 4 input units through a set of feedforward weights (see also Figure 5.1 in the text).   
</p>
<ul><li> Click the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EasyEnv&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EasyEnv (page does not exist)\">.T3Tab.EasyEnv</a> tab at the top of 3D view panel (far right) to view the events in the environment. 
</li></ul>
<p>As you can see, the input-output relationships to be learned in this \"task\" are simply that the leftmost two input units should make the left output unit active, while the rightmost units should make the right output unit active.  This can be thought of as categorizing the first two inputs as \"left\" with the left output unit, and the next two as \"right\" with the right output unit. <i>NOTE: Figure 5.2 in the text is configured differently than</i> <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EasyEnv&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EasyEnv (page does not exist)\">.T3Tab.EasyEnv</a>, <i>but they are the same patterns. This is true for figures 5.3 and 5.7 as well.</i>
</p><p>This is a relatively easy task to learn because the left output unit just has to develop strong weights to the leftmost input units and ignore the ones to the right, while the right output unit does the opposite.  Note that we are using kWTA inhibition within the output layer, with a <i>k</i> parameter of 1.
</p><p>The network is trained on this task by simply clamping both the input and output units to their corresponding values from the events in the environment, and performing CPCA Hebbian learning on the resulting activations.  
</p>
<ul><li> First, press the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> tab to reactivate it, then press the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> tab in the middle panel. Now press the <code>Init</code> button there (bottom), then <code>Step</code> 4 times while you watch the network. <i>NOTE: For this exploration, you should always answer \"Yes\" to \"Initialize Network Weights?\" after <code>Init</code>.</i>
</li></ul>
<p>You should see all 4 events from the environment presented in a random order.  
</p>
<ul><li> Now press <code>TestStep</code> 4 times. 
</li></ul>
<p>You will see the activations in the output units are different this time. This is because it was the testing phase, which is run after every epoch of training.  During this testing phase, all 4 events are presented to the network,  except this time the output units are not clamped to the correct answer, but are instead updated solely according to their current weights from the input units (which are clamped as before).  Thus, the testing phase records the current <i>actual</i> performance of the network on this task, when it is not being \"coached\" (that is why it's a test).
</p>
<ul><li> Now click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.TrialOutputGrid&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.TrialOutputGrid (page does not exist)\">.T3Tab.TrialOutputGrid</a> tab in the far right 3D view panel (followed by the <code>Refresh</code> button in the top right of the middle <a href=\"/CompCogNeuro/index.php?title=.PanelTab.TrialOutputGrid&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.TrialOutputGrid (page does not exist)\">.PanelTab.TrialOutputGrid</a> panel if the data is not displayed).
</li></ul>
<p>The results of the test run you just ran are displayed. Each row represents one of the four events, with the input pattern and the actual output activations shown on the right. The <code>sse</code> column reports the <b>summed squared error</b> (SSE), which is simply the summed difference between the actual output activation during testing (<i>o_k</i>) and the <i>target</i> value (<i>t_k</i>) that was clamped during training: 
</p>
<ul><li> SSE = \\sum_k (t_k - o_k)^2 
</li></ul>
<p>where the sum is over the 2 output units.  We are actually computing the <i>thresholded</i> SSE, where absolute differences of less than 0.5 are treated as zero, so the unit just has to get the activation on the correct side of 0.5 to get zero error.  We thus treat the units as representing underlying binary quantities (i.e., whether the pattern that the unit detects is present or not), with the graded activation value expressing something like the likelihood of the underlying binary hypothesis being true.  All of our tasks specify binary input/output patterns.
</p><p>With only a single training epoch, the output unit is likely making some errors.  
</p><p><br>
</p>
<ul><li> Click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.TrialOutputGrid&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.TrialOutputGrid (page does not exist)\">.T3Tab.TrialOutputGrid</a> tab in the far right panel if its not already active and then the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> tab in the middle panel.  Press the <code>Init</code> and <code>Run</code> buttons while you watch the grid in the right frame.
</li></ul>
<p>You will see the grid view update after each trial,  showing the pattern of outputs and the individual SSE (<code>sse</code>) errors.  
</p>
<ul><li> Next, click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EpochOutputGraph&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EpochOutputGraph (page does not exist)\">.T3Tab.EpochOutputGraph</a> tab in the far right panel (and the <code>Refresh</code> button in the middle frame if necessary). 
</li></ul>
<p>Now you will see a summary plot across epochs of the sum of the thresholded SSE measure across all the events in the epoch.  This shows what is often referred to as the <b>learning curve</b> for the network, and it should have rapidly gone to zero, indicating that the network has learned the task.  Training will stop automatically after the network has exhibited 5 correct epochs in a row (just to make sure it has really learned the problem), or it stops after 30 epochs if it fails to learn.
</p><p>Let's see what the network has learned.
</p>
<ul><li> Click the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> tab in the (far right) panel to display the network.  Press the <code>TestStep</code> button in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> 4 times.
</li></ul>
<p>This will step through each of the training patterns and update the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.TrialOutputGrid&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.TrialOutputGrid (page does not exist)\">.T3Tab.TrialOutputGrid</a>.  Click on it and hit <code>Refresh</code> as before to display the results. You should see that the network has learned this easy task, turning on the left output for the first two patterns, and the right one for the next two.  Now, let's take a look at the weights for the output unit to see exactly how this happened.
</p>
<ul><li> Click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> tab in the right frame and then on the <code>r.wt</code> value of the middle panel that also gets displayed. (You may have to scroll down --- it is near the bottom of the list of values.) Now click on the red arrow (\"Select\") tool in the right panel and select the left output unit in the network. 
</li></ul>
<p>You should see that, as expected, the weights from the left 2 units are strong (near 1), and those from the right 2 units are weak (near 0).  The complementary pattern should hold for the right output unit.
</p>
<hr>
<p><b>Question 5.1</b> <em>Explain why this pattern of strong and weak weights resulted from the CPCA Hebbian learning algorithm.</em>
</p>
<hr>
<a name=\"The_Hard_Task\" id=\"The_Hard_Task\"></a><h3> <span class=\"mw-headline\"> The Hard Task </span></h3>
<p>Now, let's try a more difficult task.  
</p>
<ul><li> Set <code>env_type</code> on the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> tab to <code>HARD</code>, and <code>Apply</code>.  Click the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.HardEnv&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.HardEnv (page does not exist)\">.T3Tab.HardEnv</a> tab at the top of the far right panel to view the events in the <code>HARD</code> environment. 
</li></ul>
<p>In this harder environment (note: figure 5.3 in text is in a different format), there is overlap among the input patterns for cases where the left output should be on, and where it should be off (and the right output on). This overlap makes the task hard because the unit has to somehow figure out what the most distinguishing or <i>task relevant</i> input units are, and set its weights accordingly.
</p><p>This task reveals a problem with Hebbian learning.  It is only concerned with the correlation (conditional probability) between the output and input units, so it cannot learn to be sensitive to which inputs are more task relevant than others (unless this happens to be the same as the input-output correlations, as in the easy task).  This hard task has a complicated pattern of overlap among the different input patterns.  For the two cases where the left output should be on, the middle two input units are very strongly correlated with the output activity (conditional probability P(x_i|y_j) = 1), while the outside two inputs are only half-correlated (P(x_i|y_j) = .5).  The two cases where the left output should be off (and the right one on) overlap considerably with those where it should be on, with the last event containing both of the highly correlated inputs.  Thus, if the network just pays attention to correlations, it will tend to respond incorrectly to this last case.
</p><p>Let's see what happens when we run the network on this task.
</p>
<ul><li> After making sure you are viewing the <code>r.wt</code> receiving weights of the left output unit in the <a href=\"/CompCogNeuro/index.php?title=.PanelTab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.PatAssocNet (page does not exist)\">.PanelTab.PatAssocNet</a> tab in the middle panel, press the <code>Init</code> (\"Yes\" to \"Initialize Network Weights?\") and then <code>Run</code> buttons in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a>, which runs the network after a new set of  random starting weights. 
</li></ul>
<p>You should see from these weights that the network has learned that the middle two units are highly correlated with the left output unit, as we expected.  
</p>
<ul><li> Return to viewing the <code>act</code> variable (<a href=\"/CompCogNeuro/index.php?title=.PanelTab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.PatAssocNet (page does not exist)\">.PanelTab.PatAssocNet</a>) and then do <code>TestStep</code> 4 times (master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a>).
</li></ul>
<p>You should see that the network is not getting the right answers.  <i>(Hint: You can also look at the</i> <a href=\"/CompCogNeuro/index.php?title=.T3Tab.TrialOutputGrid&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.TrialOutputGrid (page does not exist)\">.T3Tab.TrialOutputGrid</a> <i>to see all events at once.)</i> Different runs will produce slightly different results, but the first two events should generally turn the left output unit on (correctly), the third event should tend to (correctly) turn on the right unit, but the fourth unit should tend to (incorrectly) turn on the left unit because of the strength of the weights from the middle two input units to the left output unit.
</p><p>The weights to the right output unit (<code>r.wt</code> in the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> tab of the middle panel show that it has strongly represented its correlation with the second input unit, which explains the pattern of output responses.  This weight to the right output unit can have a net stronger effect than those to the left output unit from the two middle inputs because of the different overall activity levels in the different input patterns --- this difference in alpha affects the renormalization correction for the CPCA Hebbian learning rule as described earlier in the text (note that even if this renormalization is set to a constant across the different events, the network still fails to learn). For the fourth event, however, the \"double dose\" of the strong weights from the two middle units favors the left unit leading to a consistent error.
</p>
<ul><li> Do several more <code>Run</code>s on this <code>HARD</code> task. You can try increasing the <code>max_epochs</code> parameter to 50, or even 100, in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> if you wish.
</li></ul>
<hr>
<p><b>Question 5.2 (a)</b> <em>Does the network ever solve the task? <b>(b)</b> Report the final  <code>sse</code> at the end of training for each run.</em>
</p>
<hr>
<ul><li> Experiment with the parameters that control the contrast enhancement of the CPCA Hebbian learning rule (<code>wt_sig.gain</code> and <code>wt_sig.off</code>), to see if these are playing an important role in the network's behavior.
</li></ul>
<p>You should see that changes to these parameters do not lead to any substantial improvements.  Hebbian learning does not seem to be able to solve tasks where the correlations do not provide the appropriate weight values.  It seems unlikely that there will generally be a coincidence between correlational structure and the task solution. Thus, we must conclude that Hebbian learning is of limited use for task learning.  In contrast, we will see in the next section that an algorithm specifically designed for task learning can learn this task without much difficulty.
</p>
<ul><li> To continue on to the next simulation, you can leave this project open because we will use it again.  Or, if you wish to stop now, and come back to it later, quit by selecting <code>File-&gt;CloseProject</code> in the main project window and then <code>File-&gt;Quit</code> in the <code>.viewers[0](root)</code> window.
</li></ul>
<a name=\"Exploration_of_Delta_Rule_Task_Learning_.28Section_5.5_in_Text.29\" id=\"Exploration_of_Delta_Rule_Task_Learning_.28Section_5.5_in_Text.29\"></a><h2> <span class=\"mw-headline\"> Exploration of Delta Rule Task Learning (Section 5.5 in Text) </span></h2>
<ul><li> Reset the parameters to their default values using the <code>Defaults</code> button in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> (\"Yes\" to \"Initialize Network Weights\").
</li></ul>
<ul><li> Select <code>DELTA</code> instead of <code>HEBB</code> for the <code>learn_rule value</code> in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> and click <code>Apply</code> and then, while watching the <b>Learning Parameters</b> fields, click <code>SetLearnRule</code>.
</li></ul>
<p>This will switch weight updating from the default CPCA Hebbian rule explored previously to the delta rule.  The effects of this switch can be seen in the <code>Learning Parameters</code> group, which shows the learning rate for the weights (<code>lrate</code>, always .01) and for the bias weights (<code>bias_lrate</code>, which is 0 for Hebbian learning because it has no way of training the bias weights, and is equal to <code>lrate</code> for delta rule), and the proportion of Hebbian learning (<code>hebb</code>, 1 or 0 --- we will see in the next chapter that intermediate values of this parameter can be used as well). <b>IMPORTANT: Note that it is <code>SetLearnRule</code> that actually changes the <code>Learning Parameters</code> values.</b>
</p><p>Before training the network, we will explore how the minus-plus activation phases work in the simulator.   
</p>
<ul><li> Make sure that you are monitoring <i>activations</i> in the network by selecting <code>act</code> in the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> middle panel if it is not already highlighted. Also make sure the <code>Display!</code> checkbox in checked. Next, set <code>step_prog</code> to <code>LeabraSettle</code> instead of <code>LeabraTrial</code> in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a>.
</li></ul>
<p>This will increase the resolution of the stepping so that each press of the <code>Step</code> button will perform only the settling (iterative activation updating) process associated with one phase of processing at a time. 
</p>
<ul><li> Next hit the <code>Step</code> button.
</li></ul>
<p>You will see in the network the actual activation produced in response to the input pattern (also known as the <i>expectation</i> or <i>response,</i> or <i>minus phase</i> activation).
</p>
<ul><li> Now, hit <code>Step</code> again.
</li></ul>
<p>You will see the target (also known as the <i>outcome,</i> or <i>instruction,</i> or <i>plus phase</i>) activation.  Learning occurs after this second, plus phase of activation.  You can recognize targets, like all external inputs, because their activations are exactly .95 or 0 -- note that we are clamping activations to .95 (not 1.0) because units cannot easily produce activations above .95 with typical net input values due to the saturating nonlinearity of the rate code activation function.  You can also switch to viewing the <code>targ</code> value (2 above <code>act</code> in the <a href=\"/CompCogNeuro/index.php?title=.PanelTab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.PatAssocNet (page does not exist)\">.PanelTab.PatAssocNet</a> tab in the middle panel), which will show you the target inputs prior to the activation clamping.  In addition, the minus phase activation is always viewable as <code>act_m</code> and the plus phase as <code>act_p</code>.
</p><p>Now, let's monitor the weights.
</p>
<ul><li> Click on <code>r.wt</code> to monitor receiving weights. (Remember that you may have to scroll down the list of values since it's near the end.) Then click on the Red Arrow tool in the top right corner of the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.PatAssocNet&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.PatAssocNet (page does not exist)\">.T3Tab.PatAssocNet</a> and select the left output unit. Click <code>Init</code> and <code>Run</code> in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> to complete the training on this <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EasyEnv&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EasyEnv (page does not exist)\">.T3Tab.EasyEnv</a> task.
</li></ul>
<p>The network has no trouble learning this task -- you can click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EpochOutputGraph&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EpochOutputGraph (page does not exist)\">.T3Tab.EpochOutputGraph</a> tab (with <code>Refresh</code> if necessary) to confirm.  However, if you perform multiple <code>Run</code> 's, you should be able to notice that the final weight values are quite variable relative to the Hebbian case (you can always switch the <code>LearnRule</code> back to <code>HEBB</code> in the master control panel to compare between the two learning algorithms). In particular, you might note that there is a much less clear cut differentiation between the first two units vs. the last two in the <code>DELTA</code> rule case.
</p><p>This variability in the weights reflects a critical weakness of error-driven learning -- it's <i>lazy</i>. Basically, once the output unit is performing the task correctly, learning effectively stops, with whatever weight values that happened to do the trick.  In contrast, Hebbian learning keeps adapting the weights to reflect the conditional probabilities, which, in this task, results in roughly the same final weight values regardless of what the initial random weights were.  We will return to this issue later in Chapteer 6, when we discuss the benefits of using a combination of Hebbian and error-driven learning.
</p><p>Now for the real test.
</p>
<ul><li> Set <code>env_type</code> to <code>HARD</code> in the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a> and also change the <code>max_epoch</code> parameter to 50.  Then, press <code>Init</code> and <code>Run</code>. Click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EpochOutputGraph&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EpochOutputGraph (page does not exist)\">.T3Tab.EpochOutputGraph</a> tab in the far right frame to watch the learning curve.
</li></ul>
<p>You should see that the network learns this task without much difficulty (although it sometimes needs &gt; 30 epochs).  Thus, because the delta rule performs learning as a function of how well the network is actually doing, it can adapt the weights specifically to solve the task.
</p>
<hr>
<p><b>Question 5.3 (a)</b> <em>Compare and contrast in a qualitative manner the nature of the weights learned by the delta rule on this <code>HARD</code> task with those learned by the Hebbian rule (e.g., note where the largest weights tend to be) -- be sure to do multiple runs to get a general sense of what tends to be learned. <b>(b)</b> Using your answer to the first part, explain why the delta rule weights solve the problem, but the Hebbian ones do not (don't forget to include the bias weights <code>bias.wt</code> in your analysis of the delta rule case).</em>
</p>
<hr>
<p>After this experience, you may think that the delta rule is all powerful, but we can temper this enthusiasm and motivate the next section.  
</p>
<ul><li> Set <code>env_type</code> to <code>IMPOSSIBLE</code>.  Then, click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.ImpossibleEnv&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.ImpossibleEnv (page does not exist)\">.T3Tab.ImpossibleEnv</a> tab in the far right panel. (Note that figure 5.7 in the text has a different layout.)
</li></ul>
<p>Notice that each input unit in this environment is active equally often when the output is active as when it is inactive. That is, there is complete overlap among the patterns that activate the different output units. These kinds of problems are called <i>ambiguous cue</i> problems, or <i>nonlinear discrimination</i> problems (Sutherland &amp; Rudy, 1989; O'Reilly &amp; Rudy, 2000). This kind of problem might prove difficult, because every input unit will end up being equivocal about what the output should do.  Nevertheless, the input patterns are not all the same -- people could learn to solve this task fairly trivially by just paying attention to the overall patterns of activation.  Let's see if the network can do this.
</p>
<ul><li> Press <code>Init</code> and <code>Run</code> on the master <a href=\"/CompCogNeuro/index.php?title=.PanelTab.ControlPanel&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.ControlPanel (page does not exist)\">.PanelTab.ControlPanel</a>. Activate the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.EpochOutputGraph&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.EpochOutputGraph (page does not exist)\">.T3Tab.EpochOutputGraph</a> tab again to watch the learning curve.
</li></ul>
<p>Do it again.  And again.  Any luck? If you wish, you can increase the max_epochs to 100, or even 150, if you wish -- and see if it learns.
</p><p>Because the delta rule cannot learn what appears to be a relatively simple task, we conclude that something more powerful is necessary. Unfortunately, that is not the conclusion that Minsky &amp; Papert (1969) reached in their highly influential book, <i>Perceptrons</i>.  Instead, they concluded that neural networks were hopelessly inadequate because they could not solve problems like the one we just explored (specifically, they focused on the exclusive-or (XOR) task)!  This conclusion played a large role in the waning of the early interest in neural network models of the 1960s.  Interestingly, we will see that only a few more applications of the chain rule are necessary to remedy the problem, but this fact took a while to be appreciated by most people (roughly fifteen years, in fact).
</p>
<ul><li> To continue on to the next simulation, close this project first by selecting <code>File-&gt;Close Project</code>. It's probably better to not save upon closing so you can sure the exercises will work when reopened. Or, if you wish to stop now, quit by then selecting <code>File-&gt;Quit</code> in the <code>.viewers[0](root) window.</code>
</li></ul>

<!-- 
NewPP limit report
Preprocessor node count: 6/1000000
Post-expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key compcogneuro:pcache:idhash:70-0!1!0!!en!2!edit=0 and timestamp 20090903144913 -->
<div class=\"printfooter\">
Retrieved from \"<a href=\"http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Pattern_Associator\">http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Pattern_Associator</a>\"</div>
						<!-- end content -->
						<div class=\"visualClear\"></div>
		</div>
	</div>
		</div>
		<div id=\"column-one\">
	<div id=\"p-cactions\" class=\"portlet\">
		<h5>Views</h5>
		<div class=\"pBody\">
			<ul lang=\"en\" xml:lang=\"en\">
	
				 <li id=\"ca-nstab-main\" class=\"selected\"><a href=\"/CompCogNeuro/index.php/CECN1_Pattern_Associator\" title=\"View the content page [ctrl-alt-c]\" accesskey=\"c\">Page</a></li>
				 <li id=\"ca-talk\" class=\"new\"><a href=\"/CompCogNeuro/index.php?title=Talk:CECN1_Pattern_Associator&amp;action=edit&amp;redlink=1\" title=\"Discussion about the content page [ctrl-alt-t]\" accesskey=\"t\">Discussion</a></li>
				 <li id=\"ca-viewsource\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Pattern_Associator&amp;action=edit\" title=\"This page is protected.
You can view its source [ctrl-alt-e]\" accesskey=\"e\">View source</a></li>
				 <li id=\"ca-history\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Pattern_Associator&amp;action=history\" title=\"Past revisions of this page [ctrl-alt-h]\" accesskey=\"h\">History</a></li>			</ul>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-personal\">
		<h5>Personal tools</h5>
		<div class=\"pBody\">
			<ul lang=\"en\" xml:lang=\"en\">
				<li id=\"pt-login\"><a href=\"/CompCogNeuro/index.php?title=Special:UserLogin&amp;returnto=CECN1_Pattern_Associator\" title=\"You are encouraged to log in; however, it is not mandatory [ctrl-alt-o]\" accesskey=\"o\">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-logo\">
		<a style=\"background-image: url(/mediawiki/sites//CompCogNeuro/logo.png);\" href=\"/CompCogNeuro/index.php/Main_Page\" title=\"Visit the main page [ctrl-alt-z]\" accesskey=\"z\"></a>
	</div>
	<script type=\"text/javascript\"> if (window.isMSIE55) fixalpha(); </script>
	<div class=\"generated-sidebar portlet\" id=\"p-navigation\">
		<h5 lang=\"en\" xml:lang=\"en\">Navigation</h5>
		<div class=\"pBody\">
			<ul>
				<li id=\"n-mainpage-description\"><a href=\"/CompCogNeuro/index.php/Main_Page\">Main Page</a></li>
				<li id=\"n-portal\"><a href=\"/CompCogNeuro/index.php/Project:Community_Portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li>
				<li id=\"n-currentevents\"><a href=\"/CompCogNeuro/index.php/Project:Current_events\" title=\"Find background information on current events\">Current events</a></li>
				<li id=\"n-recentchanges\"><a href=\"/CompCogNeuro/index.php/Special:RecentChanges\" title=\"The list of recent changes in the wiki [ctrl-alt-r]\" accesskey=\"r\">Recent changes</a></li>
				<li id=\"n-randompage\"><a href=\"/CompCogNeuro/index.php/Special:Random\" title=\"Load a random page [ctrl-alt-x]\" accesskey=\"x\">Random page</a></li>
				<li id=\"n-help\"><a href=\"/CompCogNeuro/index.php/Help:Contents\" title=\"The place to find out\">Help</a></li>
			</ul>
		</div>
	</div>
	<div id=\"p-search\" class=\"portlet\">
		<h5 lang=\"en\" xml:lang=\"en\"><label for=\"searchInput\">Search</label></h5>
		<div id=\"searchBody\" class=\"pBody\">
			<form action=\"/CompCogNeuro/index.php\" id=\"searchform\"><div>
				<input type=\"hidden\" name=\"title\" value=\"Special:Search\">
				<input id=\"searchInput\" name=\"search\" type=\"text\" title=\"Search Computational Cognitive Neuroscience Wiki [ctrl-alt-f]\" accesskey=\"f\" value=\"\">
				<input type=\"submit\" name=\"go\" class=\"searchButton\" id=\"searchGoButton\" value=\"Go\" title=\"Go to a page with this exact name if exists\">&nbsp;
				<input type=\"submit\" name=\"fulltext\" class=\"searchButton\" id=\"mw-searchButton\" value=\"Search\" title=\"Search the pages for this text\">
			</div></form>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-tb\">
		<h5 lang=\"en\" xml:lang=\"en\">Toolbox</h5>
		<div class=\"pBody\">
			<ul>
				<li id=\"t-whatlinkshere\"><a href=\"/CompCogNeuro/index.php/Special:WhatLinksHere/CECN1_Pattern_Associator\" title=\"List of all wiki pages that link here [ctrl-alt-j]\" accesskey=\"j\">What links here</a></li>
				<li id=\"t-recentchangeslinked\"><a href=\"/CompCogNeuro/index.php/Special:RecentChangesLinked/CECN1_Pattern_Associator\" title=\"Recent changes in pages linked from this page [ctrl-alt-k]\" accesskey=\"k\">Related changes</a></li>
<li id=\"t-upload\"><a href=\"/CompCogNeuro/index.php/Special:Upload\" title=\"Upload files [ctrl-alt-u]\" accesskey=\"u\">Upload file</a></li>
<li id=\"t-specialpages\"><a href=\"/CompCogNeuro/index.php/Special:SpecialPages\" title=\"List of all special pages [ctrl-alt-q]\" accesskey=\"q\">Special pages</a></li>
				<li id=\"t-print\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Pattern_Associator&amp;printable=yes\" rel=\"alternate\" title=\"Printable version of this page [ctrl-alt-p]\" accesskey=\"p\">Printable version</a></li>				<li id=\"t-permalink\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Pattern_Associator&amp;oldid=313\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-download-as-pdf\"><a href=\"/CompCogNeuro/index.php?title=Special:Book/render_article/&amp;arttitle=CECN1+Pattern+Associator&amp;oldid=313&amp;writer=rl\" rel=\"nofollow\">PDF version</a></li>			</ul>
		</div>
	</div>
	<div class=\"generated-sidebar portlet\" id=\"p-coll-create_a_book\">
		<h5 lang=\"en\" xml:lang=\"en\">Create a book</h5>
		<div class=\"pBody\">
<ul id=\"collectionPortletList\"><li id=\"coll-add_page\"><a href=\"/CompCogNeuro/index.php?title=Special:Book/add_article/&amp;arttitle=CECN1+Pattern+Associator&amp;oldid=0\" title=\"Add the current wiki page to your book\" onclick=\"collectionCall('AddArticle', ['removepage', wgNamespaceNumber, wgTitle, 0]); return false;\" rel=\"nofollow\">Add page to book</a></li><li id=\"coll-help_collections\"><a href=\"/CompCogNeuro/index.php/Help:Books\" title=\"Show help about the book tool\">Books help</a></li></ul><script type=\"text/javascript\">/*<![CDATA[*/
		var wgCollectionAddRemoveSate = \"addpage\";
		/*]]>*/</script>
<script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/portlet.js?2\"></script><script type=\"text/javascript\">/*<![CDATA[*/
		var wgCollectionNavPopupJSURL = \"/CompCogNeuro/extensions/Collection/collection/Gadget-popups.js?2\";
		var wgCollectionNavPopupCSSURL = \"/CompCogNeuro/extensions/Collection/collection/Gadget-navpop.css?2\";
		var wgCollectionAddPageText = \"Add linked wiki page to your book\";
		var wgCollectionAddCategoryText = \"Add wiki pages in linked category to your book\";
		var wgCollectionRemovePageText = \"Remove linked wiki page from your book\";
		var wgCollectionPopupHelpText = \"To deactivate this feature click \\\"Clear book\\\" in the \\\"Create a book\\\" box\";
		var wgCollectionArticleNamespaces = [0, 1, 2, 3, 4, 5, 8, 9, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111];
		/*]]>*/</script>
<script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/json2.js?2\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/popupcheck.js?2\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/popup.js\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/Gadget-popups.js?2\"></script>		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class=\"visualClear\"></div>
			<div id=\"footer\">
				<div id=\"f-poweredbyico\"><a href=\"http://www.mediawiki.org/\"><img src=\"/CompCogNeuro/skins/common/images/poweredby_mediawiki_88x31.png\" alt=\"Powered by MediaWiki\"></a></div>
			<ul id=\"f-list\">
					<li id=\"lastmod\"> This page was last modified on 18 April 2008, at 22:02.</li>
					<li id=\"viewcount\">This page has been accessed 1,452 times.</li>
					<li id=\"privacy\"><a href=\"/CompCogNeuro/index.php/Project:Privacy_policy\" title=\"Project:Privacy policy\">Privacy policy</a></li>
					<li id=\"about\"><a href=\"/CompCogNeuro/index.php/Project:About\" title=\"Project:About\">About Computational Cognitive Neuroscience Wiki</a></li>
					<li id=\"disclaimer\"><a href=\"/CompCogNeuro/index.php/Project:General_disclaimer\" title=\"Project:General disclaimer\">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type=\"text/javascript\">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served in 0.219 secs. -->
</body></html>";
  };
 };
 wizards {
  name=;
  el_typ=LeabraWizard;
  el_def=0;
  LeabraWizard @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="LeabraWizard_1";
   auto_open=0;
   n_layers=3;
   layer_cfg {
    name=;
    el_typ=LayerWizEl;
    el_def=0;
    LayerWizEl @[0] {
     name="Input";
     n_units=25;
     io_type=INPUT;
    };
    LayerWizEl @[1] {
     name="Hidden";
     n_units=25;
     io_type=HIDDEN;
    };
    LayerWizEl @[2] {
     name="Output";
     n_units=25;
     io_type=OUTPUT;
    };
   };
   connectivity=BIDIRECTIONAL;
   default_net_type=LeabraNetwork;
  };
 };
 edits {
  name=;
  el_typ=SelectEdit;
  el_def=0;
  SelectEdit @[0] {
   name="ControlPanel";
   auto_edit=1;
   desc="master control panel";
   mbrs {
    name=;
    el_typ=EditMbrItem;
    el_def=0;
    EditMbrItem @[0] {
     label="env_type";
     desc=" current value, which for normal mutually-exclusive options is index into list of enums (-1 = not set), and for bits is the bit values";
     cust_desc=0;
     base=.projects[0].programs.gp[0][0].vars[7].dyn_enum_val$$;
     mbr=DynEnum::value;
     is_numeric=1;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1;
     };
    };
    EditMbrItem @[1] {
     label="learn_rule";
     desc=" current value, which for normal mutually-exclusive options is index into list of enums (-1 = not set), and for bits is the bit values";
     cust_desc=0;
     base=.projects[0].programs[1].args[2].dyn_enum_val$$;
     mbr=DynEnum::value;
     is_numeric=1;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[2] {
     label="max_epochs";
     desc=" integer value (also for enum types)";
     cust_desc=0;
     base=.projects[0].programs.gp[0][0].vars[0]$$;
     mbr=ProgVar::int_val;
     is_numeric=1;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[3] {
     label="cycle update view";
     desc=" boolean value";
     cust_desc=0;
     base=.projects[0].programs.gp[0][4].vars[0]$$;
     mbr=ProgVar::bool_val;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem_Group @.gp[0] {
     name="Learning Parameters";
     el_typ=EditMbrItem;
     el_def=0;
     EditMbrItem @[0] {
      label="lrate";
      desc="[Default: 0.01;0.02]  [0.01 for std Leabra, .02 for CtLeabra] learning rate -- how fast do the weights change per experience";
      cust_desc=0;
      base=.projects[0].networks[0].specs[1]$$;
      mbr=LeabraConSpec::lrate;
      is_numeric=1;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[1] {
      label="bias_ lrate";
      desc="[Default: 0.01;0.02]  [0.01 for std Leabra, .02 for CtLeabra] learning rate -- how fast do the weights change per experience";
      cust_desc=0;
      base=.projects[0].networks[0].specs[3]$$;
      mbr=LeabraConSpec::lrate;
      is_numeric=1;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[2] {
      label="lmix";
      desc=" mixture of hebbian & err-driven learning (note: no hebbian for CTLEABRA_XCAL)<br>  hebb:  [Default: .001] amount of hebbian learning (should be relatively small, can be effective at .0001)<br>  err:  [Default: .999] amount of error driven learning, automatically computed to be 1-hebb<br>  err sb: [Default: true]  apply exponential soft-bounding to the error learning component (applied in dWt)";
      cust_desc=0;
      base=$.projects[0].networks[0].specs[1]$;
      mbr=LeabraConSpec::lmix;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
    };
    EditMbrItem_Group @.gp[1] {
     name="CPCA Hebb Contrast Enhancement";
     el_typ=EditMbrItem;
     el_def=0;
     EditMbrItem @[0] {
      label="wt sig";
      desc=" sigmoidal weight function for contrast enhancement: high gain makes weights more binary & discriminative<br>  gain: [Default: 1;6]  gain (contrast, sharpness) of the weight contrast function (1 = linear)<br>  off: [Default: 1:1.25]  offset of the function (1=centered at .5, >1=higher, <1=lower) -- 1.25 is standard for Leabra CHL, 1.2 for XCAL";
      cust_desc=0;
      base=$.projects[0].networks[0].specs[1]$;
      mbr=LeabraConSpec::wt_sig;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
    };
    EditMbrItem_Group @.gp[2] {
     name="Net Data";
     el_typ=EditMbrItem;
     el_def=0;
     EditMbrItem @[0] {
      label="PatAssocNet phase";
      desc=" type of settling phase<br>  MINUS PHASE:  minus phase<br>  PLUS PHASE:  plus phase";
      cust_desc=0;
      base=.projects[0].networks[0]$$;
      mbr=LeabraNetwork::phase;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[1] {
      label="PatAssocNet trial";
      desc=" trial counter: number of external input patterns that have been presented in the current epoch (updated by program)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::trial;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[2] {
      label="PatAssocNet trial name";
      desc=" name associated with the current trial (e.g., name of input pattern, typically set by a LayerWriter)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::trial_name;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[3] {
      label="PatAssocNet sse";
      desc=" sum squared error over the network, for the current external input pattern";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::sse;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[4] {
      label="PatAssocNet minus cycles";
      desc=" cycles to settle in the minus phase -- this is the typical settling time statistic to record";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=LeabraNetwork::minus_cycles;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[5] {
      label="PatAssocNet epoch";
      desc=" epoch counter: number of times a complete set of training patterns has been presented (updated by program)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::epoch;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[6] {
      label="PatAssocNet batch";
      desc=" batch counter: number of times network has been trained over a full sequence of epochs (updated by program)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::batch;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
    };
   };
   mths {
    name=;
    el_typ=EditMthItem;
    el_def=0;
    group_type=GT_BUTTONS;
    EditMthItem @[0] {
     label="Init";
     desc=" set the program state back to the beginning";
     cust_desc=0;
     base=.projects[0].programs.gp[0][0]$$;
     mth=Program::Init;
    };
    EditMthItem @[1] {
     label="Run";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][0]$;
     mth=Program::Run_Gui;
    };
    EditMthItem @[2] {
     label="Step";
     desc=" step the program at the level of the given program -- if NULL then step_prog default value will be used";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][0]$;
     mth=Program::Step_Gui;
    };
    EditMthItem @[3] {
     label="Stop";
     desc=" stop the current program at its next natural stopping point (i.e., cleanly stopping when appropriate chunks of computation have completed)";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][0]$;
     mth=Program::Stop;
    };
    EditMthItem @[4] {
     label="Test Init";
     desc=" set the program state back to the beginning";
     cust_desc=0;
     base=.projects[0].programs.gp[1][0]$$;
     mth=Program::Init;
    };
    EditMthItem @[5] {
     label="Test Step";
     desc=" step the program at the level of the given program -- if NULL then step_prog default value will be used";
     cust_desc=0;
     base=$.projects[0].programs.gp[1][0]$;
     mth=Program::Step_Gui;
    };
    EditMthItem @[6] {
     label="SetLearnRule";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=.projects[0].programs[1]$$;
     mth=Program::Run_Gui;
    };
    EditMthItem @[7] {
     label="Defaults";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=.projects[0].programs[0]$$;
     mth=Program::Run_Gui;
    };
   };
  };
 };
 data {
  name=;
  el_typ=DataTable;
  el_def=0;
  DataTable_Group @.gp[0] {
   name="InputData";
   el_typ=DataTable;
   el_def=0;
   DataTable @[0] {
    name="EasyEnv";
    desc=;
    data {
     name="data";
     el_typ=String_Data;
     el_def=0;
     String_Data @[0] {
      name="Name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [4] "Event_0";"Event_1";"Event_2";"Event_3";      };
     };
     float_Data @[1] {
      name="Input";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 4;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [4 1 4] 1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;      };
     };
     float_Data @[2] {
      name="Output";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 2;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [2 1 4] 1;0;1;0;0;1;0;1;      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[1] {
    name="HardEnv";
    desc=;
    data {
     name="data";
     el_typ=String_Data;
     el_def=0;
     String_Data @[0] {
      name="Name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [4] "Event_0";"Event_1";"Event_2";"Event_3";      };
     };
     float_Data @[1] {
      name="Input";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 4;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [4 1 4] 1;1;1;0;0;1;1;1;0;1;
0;1;0;1;1;0;      };
     };
     float_Data @[2] {
      name="Output";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 2;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [2 1 4] 1;0;1;0;0;1;0;1;      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[2] {
    name="ImpossibleEnv";
    desc=;
    data {
     name="data";
     el_typ=String_Data;
     el_def=0;
     String_Data @[0] {
      name="Name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [4] "Event_0";"Event_1";"Event_2";"Event_3";      };
     };
     float_Data @[1] {
      name="Input";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 4;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [4 1 4] 1;0;1;0;0;1;0;1;1;1;
0;0;0;0;1;1;      };
     };
     float_Data @[2] {
      name="Output";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 2;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [2 1 4] 1;0;1;0;0;1;0;1;      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
  };
  DataTable_Group @.gp[1] {
   name="OutputData";
   el_typ=DataTable;
   el_def=0;
   DataTable @[0] {
    name="TrialOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     String_Data @[0] {
      name="trial_name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[1] {
      name="sse";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[2] {
      name="Input_act";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 4;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [4 1 0]       };
     };
     float_Data @[3] {
      name="Output_act";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 2;1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [2 1 0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[1] {
    name="EpochOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     int_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="batch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="epoch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[2] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="avg_sse";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[3] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="cnt_err";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[4] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="avg_ext_rew";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[5] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="avg_cycles";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[6] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="epoch_time_tot";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[7] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.270935960591133;
	val_type_fixed=0;
       };
      };
      name="epoch_time_usr";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
  };
  DataTable_Group @.gp[2] {
   name="AnalysisData";
   el_typ=DataTable;
   el_def=0;
  };
 };
 data_proc {
  name=;
  el_typ=taDataProc;
  el_def=0;
  taDataProc @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_base";
  };
  taDataAnal @[1] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_anal";
  };
  taDataGen @[2] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_gen";
  };
  taImageProc @[3] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="image_proc";
  };
 };
 programs {
  name=;
  el_typ=Program;
  el_def=0;
  tags=;
  desc=;
  Program @[0] {
   name="SetDefaults";
   short_nm="SDflts";
   tags=;
   desc="restores default initial parameters in the simulation";
   flags=;
   objs {
    name=;
    el_typ=taNBase;
    el_def=0;
   };
   types {
    name=;
    el_typ=ProgType;
    el_def=0;
    DynEnumType @[0] {
     name="EnvType";
     desc=;
     enums {
      name=;
      el_typ=DynEnumItem;
      el_def=0;
      DynEnumItem @[0] {
       name="EASY";
       value=0;
       desc=;
      };
      DynEnumItem @[1] {
       name="HARD";
       value=1;
       desc=;
      };
      DynEnumItem @[2] {
       name="IMPOSSIBLE";
       value=2;
       desc=;
      };
     };
     bits=0;
    };
    DynEnumType @[1] {
     name="LearnRule";
     desc=;
     enums {
      name=;
      el_typ=DynEnumItem;
      el_def=0;
      DynEnumItem @[0] {
       name="HEBB";
       value=0;
       desc=;
      };
      DynEnumItem @[1] {
       name="DELTA";
       value=1;
       desc=;
      };
     };
     bits=0;
    };
   };
   args {
    name=;
    el_typ=ProgVar;
    el_def=0;
   };
   vars {
    name=;
    el_typ=ProgVar;
    el_def=0;
    ProgVar @[0] {
     name="train";
     var_type=T_Object;
     object_type=Program;
     object_val=$.projects[0].programs.gp[0][0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[1] {
     name="env_type";
     var_type=T_DynEnum;
     dyn_enum_val {
      enum_type=.projects[0].programs[0].types[0]$$;
      value=0;
     };
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[2] {
     name="input_data";
     var_type=T_Object;
     object_type=DataTable;
     object_val=.projects[0].data.gp[0][0]$$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[3] {
     name="ControlPanel";
     var_type=T_Object;
     object_type=SelectEdit;
     object_val=.projects[0].edits[0]$$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[4] {
     name="con_spec";
     var_type=T_Object;
     object_type=LeabraConSpec;
     object_val=$.projects[0].networks[0].specs[1]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[5] {
     name="gain";
     var_type=T_Real;
     real_val=6;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc="weight sigmoid (wt_sig) gain";
     init_from=NULL;
    };
    ProgVar @[6] {
     name="off";
     var_type=T_Real;
     real_val=1.25;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc="weight sigmoid (wt_sig) offset";
     init_from=NULL;
    };
    ProgVar @[7] {
     name="network";
     var_type=T_Object;
     object_type=LeabraNetwork;
     object_val=$.projects[0].networks[0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[8] {
     name="learn_rule";
     var_type=T_DynEnum;
     dyn_enum_val {
      enum_type=.projects[0].programs[0].types[1]$$;
      value=0;
     };
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[9] {
     name="max_epoch";
     var_type=T_Int;
     int_val=30;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
   };
   functions {
    name=;
    el_typ=Function;
    el_def=0;
   };
   load_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   init_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   prog_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
    MethodCall @[0] {
     desc=;
     flags=;
     result_var=NULL;
     obj=.projects[0].programs[0].vars[0]$$;
     method=Program::SetVar;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=const_taString_ref;
       type="const taString&";
       name="var_nm";
       required=1;
       def_val="\"\"";
       expr {
	expr="\"env_type\"";
       };
      };
      ProgArg @[1] {
       arg_type=const_Variant_ref;
       type="const Variant&";
       name="value";
       required=1;
       def_val=;
       expr {
	expr="env_type";
       };
      };
     };
    };
    MemberAssign @[1] {
     desc=;
     flags=;
     obj=.projects[0].programs[0].vars[4]$$;
     path="wt_sig.gain";
     expr {
      expr="gain";
     };
     update_after=0;
    };
    MemberAssign @[2] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[4]$;
     path="wt_sig.off";
     expr {
      expr="off";
     };
     update_after=0;
    };
    MethodCall @[3] {
     desc=;
     flags=;
     result_var=NULL;
     obj=$.projects[0].programs[0].vars[0]$;
     method=Program::SetVar;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=const_taString_ref;
       type="const taString&";
       name="var_nm";
       required=1;
       def_val="\"\"";
       expr {
	expr="\"input_data\"";
       };
      };
      ProgArg @[1] {
       arg_type=const_Variant_ref;
       type="const Variant&";
       name="value";
       required=1;
       def_val=;
       expr {
	expr="input_data";
       };
      };
     };
    };
    MethodCall @[4] {
     desc=;
     flags=;
     result_var=NULL;
     obj=$.projects[0].programs[0].vars[0]$;
     method=Program::SetVar;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=const_taString_ref;
       type="const taString&";
       name="var_nm";
       required=1;
       def_val="\"\"";
       expr {
	expr="\"network\"";
       };
      };
      ProgArg @[1] {
       arg_type=const_Variant_ref;
       type="const Variant&";
       name="value";
       required=1;
       def_val=;
       expr {
	expr="network";
       };
      };
     };
    };
    MethodCall @[5] {
     desc=;
     flags=;
     result_var=NULL;
     obj=$.projects[0].programs[0].vars[0]$;
     method=Program::SetVar;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=const_taString_ref;
       type="const taString&";
       name="var_nm";
       required=1;
       def_val="\"\"";
       expr {
	expr="\"max_epoch\"";
       };
      };
      ProgArg @[1] {
       arg_type=const_Variant_ref;
       type="const Variant&";
       name="value";
       required=1;
       def_val=;
       expr {
	expr="max_epoch";
       };
      };
     };
    };
    MethodCall @[6] {
     desc=;
     flags=;
     result_var=NULL;
     obj=$.projects[0].programs[0].vars[0]$;
     method=Program::Init;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
     };
    };
    MethodCall @[7] {
     desc=;
     flags=;
     result_var=NULL;
     obj=.projects[0].programs[0].vars[3]$$;
     method=SelectEdit::UpdateAfterEdit;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
     };
    };
    ProgramCall @[8] {
     desc=;
     flags=;
     prog_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=LeabraNetwork;
       type="LeabraNetwork*";
       name="network";
       required=1;
       def_val=;
       expr {
	expr="network";
       };
      };
      ProgArg @[1] {
       arg_type=DataTable;
       type="DataTable*";
       name="input_data";
       required=1;
       def_val=;
       expr {
	expr="input_data";
       };
      };
      ProgArg @[2] {
       arg_type=DynEnum;
       type="LearnRule";
       name="learn_rule";
       required=1;
       def_val=;
       expr {
	expr="learn_rule";
       };
      };
     };
     target=$.projects[0].programs[1]$;
     targ_ld_init="*SetLearnRule*";
    };
   };
   step_prog=NULL;
   step_n=1;
  };
  Program @[1] {
   name="SetLearnRule";
   short_nm="SLrRl";
   tags=;
   desc="sets the learning mix values between HEBB and ERR";
   flags=;
   objs {
    name=;
    el_typ=taNBase;
    el_def=0;
   };
   types {
    name=;
    el_typ=DynEnumType;
    el_def=0;
    DynEnumType @[0] {
     name="LearnRule";
     desc=;
     enums {
      name=;
      el_typ=DynEnumItem;
      el_def=0;
      DynEnumItem @[0] {
       name="HEBB";
       value=0;
       desc=;
      };
      DynEnumItem @[1] {
       name="DELTA";
       value=1;
       desc=;
      };
     };
     bits=0;
    };
   };
   args {
    name=;
    el_typ=ProgVar;
    el_def=0;
    ProgVar @[0] {
     name="network";
     var_type=T_Object;
     object_type=LeabraNetwork;
     object_val=$.projects[0].networks[0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[1] {
     name="input_data";
     var_type=T_Object;
     object_type=DataTable;
     object_val=$.projects[0].data.gp[0][0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[2] {
     name="learn_rule";
     var_type=T_DynEnum;
     dyn_enum_val {
      enum_type=.projects[0].programs[1].types[0]$$;
      value=0;
     };
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
   };
   vars {
    name=;
    el_typ=ProgVar;
    el_def=0;
    ProgVar @[0] {
     name="ControlPanel";
     var_type=T_Object;
     object_type=SelectEdit;
     object_val=$.projects[0].edits[0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[1] {
     name="con_spec";
     var_type=T_Object;
     object_type=LeabraConSpec;
     object_val=$.projects[0].networks[0].specs[1]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
   };
   functions {
    name=;
    el_typ=Function;
    el_def=0;
   };
   load_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   init_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   prog_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
    AssignExpr @[0] {
     desc=;
     flags=;
     result_var=.projects[0].programs[1].vars[1]$$;
     expr {
      expr="network.specs.ConSpec";
     };
    };
    Switch @[1] {
     desc=;
     flags=;
     switch_var=.projects[0].programs[1].args[2]$$;
     cases {
      name=;
      el_typ=CaseBlock;
      el_def=0;
      CaseBlock @[0] {
       desc=;
       flags=;
       prog_code {
	name=;
	el_typ=ProgEl;
	el_def=0;
	MemberAssign @[0] {
	 desc="set Hebb to 100% ";
	 flags=;
	 obj=$.projects[0].programs[1].vars[1]$;
	 path="lmix.hebb";
	 expr {
	  expr="1";
	 };
	 update_after=1;
	};
	MemberAssign @[1] {
	 desc="bias weights learning rate needs to be 0 if Hebbian learning is used";
	 flags=;
	 obj=.projects[0].programs[1].args[0]$$;
	 path="specs.BiasSpec_0.lrate";
	 expr {
	  expr="0";
	 };
	 update_after=0;
	};
	MemberAssign @[2] {
	 desc="bias weights learning rate needs to be 0 if Hebbian learning is used";
	 flags=;
	 obj=$.projects[0].programs[1].args[0]$;
	 path="specs.ConSpec_0.lrate";
	 expr {
	  expr="0.01";
	 };
	 update_after=0;
	};
       };
       case_val {
	expr="HEBB";
       };
      };
      CaseBlock @[1] {
       desc=;
       flags=;
       prog_code {
	name=;
	el_typ=ProgEl;
	el_def=0;
	MemberAssign @[0] {
	 desc="set Hebb to 0% ";
	 flags=;
	 obj=$.projects[0].programs[1].vars[1]$;
	 path="lmix.hebb";
	 expr {
	  expr="0";
	 };
	 update_after=1;
	};
	MemberAssign @[1] {
	 desc="bias weights learning rate needs to be 0 if Hebbian learning is used";
	 flags=;
	 obj=$.projects[0].programs[1].args[0]$;
	 path="specs.BiasSpec_0.lrate";
	 expr {
	  expr="0.01";
	 };
	 update_after=0;
	};
	MemberAssign @[2] {
	 desc="bias weights learning rate needs to be 0 if Hebbian learning is used";
	 flags=;
	 obj=$.projects[0].programs[1].args[0]$;
	 path="specs.ConSpec_0.lrate";
	 expr {
	  expr="0.01";
	 };
	 update_after=0;
	};
       };
       case_val {
	expr="DELTA";
       };
      };
     };
    };
    MethodCall @[2] {
     desc=;
     flags=;
     result_var=NULL;
     obj=$.projects[0].programs[1].args[0]$;
     method=Network::UpdateAllSpecs;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=bool;
       type="bool";
       name="force";
       required=0;
       def_val="false";
       expr {
	expr=;
       };
      };
     };
    };
    MethodCall @[3] {
     desc=;
     flags=;
     result_var=NULL;
     obj=.projects[0].programs[1].vars[0]$$;
     method=SelectEdit::UpdateAfterEdit;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
     };
    };
   };
   step_prog=NULL;
   step_n=1;
  };
  Program_Group @.gp[0] {
   name="LeabraAll_Std";
   el_typ=Program;
   el_def=0;
   tags="Leabra, Std, All";
   desc="The full set of programs for training a standard Leabra network";
   Program @[0] {
    name="LeabraTrain";
    short_nm="Train";
    tags="Leabra, Std";
    desc="A complete training run of a Leabra network: iterating over epochs until the network has learned the task";
    flags=;
    objs {
     name=;
     el_typ=RndSeed;
     el_def=0;
     RndSeed @[0] {
      name="rnd_seed";
      seed{ -1765453828;1805221175;-871740336;489523138;1860919694;-1191443344;283951872;-1228673273;-1688602111;-1956626888;-1445226772;266988017;-2028845791;-1188429348;1034193572;1519941315;1828891802;-1935012808;1295506676;-1023653444;-1992732817;-149378282;970767455;796797074;-193322062;1998638574;61810277;-664194316;1183337103;-1249023965;308985379;1523760878;-1445184661;-879910514;19935683;-486933230;1820717273;883137885;-582034729;-284964405;938648592;687295097;-1782963481;1063211396;-304689856;-1435707748;35469956;-1015760317;-1401308304;1769272875;-1509451580;1194015825;-1652188220;1887267667;120076688;-1399011833;-2047488719;-2060500904;-1886745156;-810116559;-85092362;-1446899482;2060889650;-1588525730;-161916532;-921248596;1860679757;-585080257;-1845699088;354947775;-502227807;-1261535695;-832170649;-713755459;-1487913664;2017361237;-1090165136;638741831;-760144815;1178996393;2115219608;-1485468242;1776677166;1108561630;-1561561777;-2094302026;1590724442;405936702;998344910;1911764895;1258979248;1666259504;-111505743;-705327465;691696834;-1780882711;299059735;-710702476;-874491819;-187189167;-1392665922;-2097108847;-1451348635;384108810;293137242;35521771;753316897;106019440;-1810596196;-2111143229;436592531;-1979981714;-294824180;1243832412;219269667;-131695806;1240164889;743420909;171364855;1337918954;-34268881;-1671464235;-632715699;201571137;1198893601;1347895069;-319430006;284995980;-645269316;180771548;-1293576882;-1769106561;-298576427;-1156176909;1351559067;1910639177;-1918462224;1109331971;-35626156;-1441677090;-1355099304;1556516111;-1623972588;50686013;-1416247903;72365280;-1844396814;4651843;994901251;-941920828;1002622745;174003828;-2018250660;271721391;111786917;870667700;2084840608;1793301794;182041197;-509222240;-1020221969;611369661;-941688269;1177314707;-790809282;-110188874;-1965972721;-430814776;-1870544705;1954623546;1331993329;-1507094181;1701312969;-618031979;268821980;-1822790533;-1979150995;-1155976068;-444914584;-1828740630;433588540;1607516513;1316531094;-292519350;-793020283;-2128591977;-352819325;2011452987;1389432734;254820728;995822870;-930680723;1323940390;-1041870556;1834804261;1220101879;-1865636398;-299254827;-1227447756;922150421;-149093359;-1172423197;976409487;1177419574;2084249727;-1289142141;-229475149;1746231871;1505030470;-965529388;-92908379;2089172049;1567399012;-565263954;577961751;-813501462;-359600955;458055927;153907533;-62527172;-434061897;1885088993;1652659518;-558392902;1606592477;1520760493;1506500286;1848219966;2116365759;307739355;-1348932531;-403406062;521326493;1020391130;-677648660;-1549728714;-952992400;-1909257652;-1698115660;-27502147;1655183078;-186406636;-957348347;-1575643311;-1480253517;949107402;1722633384;-1526419292;2045544566;-1634040084;1571724000;-1897102144;1873425286;-2140498880;-1724788472;147575793;74291221;1781743178;-1432701031;-2071370710;1843784908;1561010918;325281065;-411509964;847244475;-1085965872;-1856474396;-643011639;1362862526;-162592664;-677603771;-2128822099;1816046875;-216844717;1792360098;-1088687518;2069627124;1250066110;1183398257;368089671;-1771184613;-1008533002;776922051;-78104566;-1274417751;-70760300;889090993;-366715148;-1544771693;318879318;-1365575920;718937405;710815541;-992018930;1883910471;-494016571;829384774;-2119460153;1441431011;739220821;-424767307;726302459;1328901429;-1007621453;-428554080;-1410898816;1050819196;1890676767;601049866;2060121639;-757631948;-575452694;-1146561755;-654879076;1766409461;-1837446785;-1095736179;-1252969304;652132944;-1676707121;-1301403359;1030682384;544148114;443895517;-1685625995;-1125781960;-1899362264;1698280409;-605385344;1809445112;-775924601;-1380450977;699972605;845648158;-279490524;-865566798;-1150870747;1330026164;-2005707845;-480441776;-897548525;-501108059;712004308;-1905253637;902041237;1681555234;387114281;-952738936;-734232013;-321188275;-113875932;-1625332798;1308892192;-1416379546;1285069782;-629371850;194948941;-930717754;-1062783201;-801457293;-175446888;-664787568;-586186903;-1238171587;-1023815353;107541825;-747664109;-1192216385;-833713919;56369467;1841213625;-841600501;-1803549028;-262198325;1450331998;-2027149070;1424267304;1220344486;591610973;61521708;-1663043112;-1911996801;1837206991;1369584069;234588116;1186532389;1937575862;532751286;-1521910190;-1094211819;1657879705;-1105051265;-553992999;1240673675;-954871044;-1837123802;1466009280;-975276878;-99761053;-467281041;-716153044;-1712409060;494266728;-79315045;-751505268;-1870106368;-111367840;1575604390;1450816123;-1747143237;191018135;-189329362;-249792419;1329056947;-831715880;1445102598;74897251;64747184;1000113426;-2089475139;462508799;2126067520;208377675;1098306878;-726017405;1556198953;503334770;141964197;-1647792443;1629910320;-918915325;-289409873;744461708;-812519955;-429310312;1413720026;1854041627;1628920823;438824900;-278036981;-522386720;-705519544;1183736401;2029624139;-979705874;-211079362;1815890383;-471179771;1911705630;-430754564;1831428445;-1343117553;-904405275;-1577187197;-2092079701;1284476532;1225970417;-337663367;-489714196;1147201558;-485432865;-1685333607;-1931620619;604362818;416785882;-1244914989;-610832569;1747340199;-1356746670;-1311415963;2015399545;1449029423;251886846;1563836431;1997587808;1155910176;-1698993695;13648748;775120762;150871809;-807352763;1102295423;408123032;-1584585765;-875739263;265275951;-881398415;-2128891423;1666493303;-127677065;-159439698;1199902508;-757525587;1290724243;50785416;-1106764905;-318201671;-8325805;1180211842;-1455811934;-633275628;1940087048;-2120082557;305390812;100075716;2072206157;-1782402314;474034239;-297614889;1994190497;658360094;-1530880299;551599059;1676871488;478848935;2147321318;1224701223;-1098608637;2003065707;124374233;-1320356699;1188751084;1718416011;-1869771651;864118567;-665676944;362920301;587497232;1916121952;-1613385642;-1393064138;1466903959;-2057550782;-609407147;-318589692;-601674534;1926223029;1170161949;1980804646;-1193765250;1130347784;-936482902;-244885301;1505825031;-1166938242;1686166029;-1579518754;-977413905;460383040;1944513125;-431620198;-661276028;-1584015253;667784342;280618840;-1987158045;27410161;-582430654;1660155091;-503186679;1332111138;-1232245248;-1883669764;2079422057;997810492;1687190241;-622699370;-487766528;-1339474841;-732306670;1131524335;-1307824607;-898371317;-487366043;-2106037636;-68062219;-1861523378;1046795325;487023443;592878850;1849689614;1089039664;803098523;1821138286;1399473683;1256933731;-758683660;-351259202;-1638769955;423113544;-845822538;114810808;-135479832;-680086776;284330153;-2089722368;-250139874;-301889082;-1715942897;-1939624328;-116841862;559701270;1792770568;-76537624;1061667347;-1330594084;737287668;-1439078493;-1568535067;-1945035388;-1036558784;421465554;-2140940226;1338011153;876740278;-1370298827;-1553382117;1043441222;796660232;-3053677;-1829114308;1758211811;1037267864;-697240217;      };
      mti=624;
     };
    };
    types {
     name=;
     el_typ=DynEnumType;
     el_def=0;
     DynEnumType @[0] {
      name="RndInitType";
      desc=;
      enums {
       name=;
       el_typ=DynEnumItem;
       el_def=0;
       DynEnumItem @[0] {
	name="OLD_SEED";
	value=0;
	desc="use stored random seed value (recreates same sequence every time)";
       };
       DynEnumItem @[1] {
	name="NEW_SEED";
	value=1;
	desc="generate new random seed (new sequence of random numbers)";
       };
      };
      bits=0;
     };
     DynEnumType @[1] {
      name="EnvType";
      desc=;
      enums {
       name=;
       el_typ=DynEnumItem;
       el_def=0;
       DynEnumItem @[0] {
	name="EASY";
	value=0;
	desc=;
       };
       DynEnumItem @[1] {
	name="HARD";
	value=1;
	desc=;
       };
       DynEnumItem @[2] {
	name="IMPOSSIBLE";
	value=2;
	desc=;
       };
      };
      bits=0;
     };
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to train";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable with training patterns";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="no_prompts";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="If train is called by other programs (e.g., Batch), they should set this to true -- otherwise it is reset to false in Init";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="max_epoch";
      var_type=T_Int;
      int_val=30;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="maximum number of epochs to run";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch";
      var_type=T_Int;
      int_val=11;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current epoch -- local copy, which is used to update network's epoch counter";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="train_mode";
      var_type=T_HardEnum;
      int_val=1;
      hard_enum_type=Network::TrainMode;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="TRAIN = update weights (learn), TEST = just record network's responses but don't learn";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="rnd_init";
      var_type=T_DynEnum;
      dyn_enum_val {
       enum_type=.projects[0].programs.gp[0][0].types[0]$$;
       value=1;
      };
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="how to initialize the random numbers when the Init button is pressed";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="err_stopcrit";
      var_type=T_Real;
      real_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="stopping criterion -- when error measure (count of trials with a non-zero error by defult)
goes <= this value, stop training (set to -1 to disable stopping criterion, and always train to max_epoch epochs)";
      init_from=NULL;
     };
     ProgVar @[5] {
      name="rnd_seed";
      var_type=T_Object;
      object_type=RndSeed;
      object_val=.projects[0].programs.gp[0][0].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="random seed that is used at start of training -- if OldSeed is called";
      init_from=NULL;
     };
     ProgVar @[6] {
      name="train_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=.projects[0].networks[0].train_time$$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="records time used to train network (object lives on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[7] {
      name="env_type";
      var_type=T_DynEnum;
      dyn_enum_val {
       enum_type=.projects[0].programs.gp[0][0].types[1]$$;
       value=0;
      };
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[8] {
      name="n_under_thr";
      var_type=T_Int;
      int_val=5;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="number of times network needs to be under stopcrit threshold to actually stop";
      init_from=NULL;
     };
     ProgVar @[9] {
      name="n_under_cnt";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current under threshold counter";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc=;
      flags=;
      result_var=.projects[0].programs.gp[0][0].args[2]$$;
      expr {
       expr="false";
      };
     };
     MethodCall @[1] {
      desc="check network to make sure it is ready to be run";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][0].args[0]$$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     AssignExpr @[2] {
      desc="get our pointer to the network training time object";
      flags=;
      result_var=.projects[0].programs.gp[0][0].vars[6]$$;
      expr {
       expr="network.train_time";
      };
     };
     IfElse @[3] {
      desc="initialize random seed (either old or new)";
      flags=;
      cond {
       expr="rnd_init == OLD_SEED";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="restore previous random seed (all runs produce same results)";
	flags=;
	result_var=NULL;
	obj=.projects[0].programs.gp[0][0].vars[5]$$;
	method=RndSeed::OldSeed;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="new random numbers each time";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][0].vars[5]$;
	method=RndSeed::NewSeed;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
     };
     IfGuiPrompt @[4] {
      desc="don't initialize weights without checking";
      flags=;
      prompt="Do you want to Initialize Network Weights";
      yes_label="Yes";
      no_label="No";
      yes_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="initialize network weights: could also load pre-set weights or something else here";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][0].args[0]$;
	method=Network::Init_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
       PrintExpr @[1] {
	desc=;
	flags=;
	expr {
	 expr="network.name << \" Weights Initialized\"";
	};
       };
      };
     };
     AssignExpr @[5] {
      desc=;
      flags=NON_STD;
      result_var=.projects[0].programs.gp[0][0].vars[9]$$;
      expr {
       expr="0";
      };
     };
     MemberMethodCall @[6] {
      desc="update in case wt_sig params changed";
      flags=NON_STD;
      obj=$.projects[0].programs.gp[0][0].args[0]$;
      path="specs.ConSpec_0";
      result_var=NULL;
      method=taList_impl::UpdateAfterEdit;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     Switch @[0] {
      desc=;
      flags=;
      switch_var=.projects[0].programs.gp[0][0].vars[7]$$;
      cases {
       name=;
       el_typ=CaseBlock;
       el_def=0;
       CaseBlock @[0] {
	desc=;
	flags=;
	prog_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 AssignExpr @[0] {
	  desc=;
	  flags=;
	  result_var=.projects[0].programs.gp[0][0].args[1]$$;
	  expr {
	   expr="\"EasyEnv\"";
	  };
	 };
	};
	case_val {
	 expr="EASY";
	};
       };
       CaseBlock @[1] {
	desc=;
	flags=;
	prog_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 AssignExpr @[0] {
	  desc=;
	  flags=;
	  result_var=$.projects[0].programs.gp[0][0].args[1]$;
	  expr {
	   expr="\"HardEnv\"";
	  };
	 };
	};
	case_val {
	 expr="HARD";
	};
       };
       CaseBlock @[2] {
	desc=;
	flags=;
	prog_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 AssignExpr @[0] {
	  desc=;
	  flags=;
	  result_var=$.projects[0].programs.gp[0][0].args[1]$;
	  expr {
	   expr="\"ImpossibleEnv\"";
	  };
	 };
	};
	case_val {
	 expr="IMPOSSIBLE";
	};
       };
      };
     };
     AssignExpr @[1] {
      desc="get our pointer to the network training time object";
      flags=;
      result_var=$.projects[0].programs.gp[0][0].vars[6]$;
      expr {
       expr="network.train_time";
      };
     };
     MethodCall @[2] {
      desc="start timer to keep track of how long it takes to run entire training run";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][0].vars[6]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MemberAssign @[3] {
      desc="set network's training mode to our local value";
      flags=;
      obj=$.projects[0].programs.gp[0][0].args[0]$;
      path="train_mode";
      expr {
       expr="train_mode";
      };
      update_after=0;
     };
     IfElse @[4] {
      desc=;
      flags=;
      cond {
       expr="no_prompts";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="initialize network weights: could also load pre-set weights or something else here";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][0].args[0]$;
	method=Network::Init_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
       PrintExpr @[1] {
	desc=;
	flags=;
	expr {
	 expr="network.name << \" Weights Initialized\"";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     AssignExpr @[5] {
      desc="grab the official network epoch counter: will be initialized if needed by now";
      flags=;
      result_var=.projects[0].programs.gp[0][0].vars[1]$$;
      expr {
       expr="network.epoch";
      };
     };
     WhileLoop @[6] {
      desc="main loop over epochs of training";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the epoch program (one epoch), passes our network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][1]$$;
	targ_ld_init="*LeabraEpoch*";
       };
       ProgramCall @[1] {
	desc=;
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=$.projects[0].programs.gp[1][0]$;
	targ_ld_init="*LeabraEpochTest*";
       };
       NetCounterIncr @[2] {
	desc="increment the epoch counter (locally and on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][0].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][0].vars[1]$;
	counter=Network::epoch;
	update_after=1;
       };
       IfElse @[3] {
	desc=;
	flags=NON_STD;
	cond {
	 expr="network.cnt_err<=err_stopcrit";
	};
	true_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 VarIncr @[0] {
	  desc=;
	  flags=;
	  var=$.projects[0].programs.gp[0][0].vars[9]$;
	  expr {
	   expr="1";
	  };
	 };
	 IfBreak @[1] {
	  desc="stop if errors go below stopping criterion for n_under_thr consecutive times (note: could use sse or avg_sse here too)";
	  flags=;
	  cond {
	   expr="n_under_cnt>n_under_thr";
	  };
	 };
	};
	false_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 AssignExpr @[0] {
	  desc="if errors above threshold this epoch, reset counter to 0 ";
	  flags=;
	  result_var=$.projects[0].programs.gp[0][0].vars[9]$;
	  expr {
	   expr="0";
	  };
	 };
	};
       };
       IfBreak @[4] {
	desc="stop if errors go below stopping criterion (note: could use sse or avg_sse here instead)";
	flags=OFF;
	cond {
	 expr="network.cnt_err <= err_stopcrit";
	};
       };
      };
      test {
       expr="epoch < max_epoch";
      };
     };
     MethodCall @[7] {
      desc="stop the timer -- time elapsed is now recorded in this object, and can be displayed or recorded to a data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][0].vars[6]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=.projects[0].programs.gp[1][1]$$;
    step_n=1;
   };
   Program @[1] {
    name="LeabraEpoch";
    short_nm="Epoch";
    tags="Leabra, Std";
    desc="iterates over all of the items in a data table and calls LeabraTrial process on them";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="table of patterns to present to the network, one row at a time";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="data_loop_order";
      var_type=T_HardEnum;
      int_val=1;
      hard_enum_type=DataLoop::Order;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="controls the order in which events (rows of the input data datatable) are presented to the network
(SEQUENTIAL, PERMUTED, RANDOM)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[1][0]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="trial-level output data -- we reset it every epoch by default, so it just contains last epoch of data";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=.projects[0].networks[0].epoch_time$$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="timer to record time required to perform one epoch of processing (object is on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="data_loop_index";
      var_type=T_Int;
      int_val=4;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="index counter for the looping over items in the input_data datatable (not always the same as trial counter, depending on distributed memory computation)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=.projects[0].programs.gp[0][1].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][1].vars[1]$$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=.projects[0].programs.gp[0][1].vars[3]$$;
      expr {
       expr="network.epoch_time";
      };
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=$.projects[0].programs.gp[0][1].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][1].vars[1]$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=$.projects[0].programs.gp[0][1].vars[3]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[2] {
      desc="start the epoch timer to record computation time per epoch";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].vars[3]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="reset trial-level monitor data every epoch, so it reflects only the most recent epoch's worth of data (turn flags OFF to accumulate trial data across entire training run)";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][1].vars[2]$$;
      method=DataTable::ResetData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetDataLoop @[4] {
      desc="iterates over the events/rows of input_data, according to data_loop_order variable";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the trial program, passing network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][2]$$;
	targ_ld_init="*LeabraTrial*";
       };
      };
      data_var=.projects[0].programs.gp[0][1].args[1]$$;
      index_var=.projects[0].programs.gp[0][1].vars[4]$$;
      order_var=.projects[0].programs.gp[0][1].vars[0]$$;
      order=PERMUTED;
      item_idx_list{ 3;2;1;0;      };
      update_after=0;
      dmem_nprocs=1;
      dmem_this_proc=0;
      grouped=0;
      group_col 9 0="Group";
      group_index_var=NULL;
      group_order_var=NULL;
      group_order=PERMUTED;
      group_idx_list{       };
     };
     IfElse @[5] {
      desc="if full batch mode, update only at end of epoch";
      flags=;
      cond {
       expr="network.wt_update == Network::BATCH";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="final update of weights based on accumulated changes";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][1].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     MethodCall @[6] {
      desc="network accumulates some core statistics over the epoch -- this finalizes that process and computes summary stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].args[0]$;
      method=LeabraNetwork::Compute_EpochStats;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[7] {
      desc="done with the computation in the epoch -- record time it took";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].vars[3]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[8] {
      desc="run program that records data from network and possibly other sources about the epoch";
      flags=OFF;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[0][7]$$;
      targ_ld_init="*LeabraEpochMonitor*";
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[2] {
    name="LeabraTrial";
    short_nm="Trial";
    tags="Leabra, Std";
    desc="Leabra processing of a single input/toutput event or external information: typically runs a minus and a plus phase, then learns (unless testing)";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on -- typically set by higher-level calling programs";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable containing training input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="phase_no";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="local phase counting variable (0 is typically minus phase, 1 is typically plus -- depends on network settings)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether to update any network view displays after trial is completed";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=.projects[0].programs.gp[0][2].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][2].vars[0]$$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=$.projects[0].programs.gp[0][2].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][2].vars[0]$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
     MethodCall @[1] {
      desc="initializes various counters at start of trial";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][2].args[0]$;
      method=LeabraNetwork::Trial_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     WhileLoop @[2] {
      desc="loop over phases of settling in the network";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the settle program (which iterates over cyles of network activation updating) for each phase";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][3]$$;
	targ_ld_init="*LeabraSettle*";
       };
       NetCounterIncr @[1] {
	desc="increment the phase number (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][2].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][2].vars[0]$;
	counter=LeabraNetwork::phase_no;
	update_after=0;
       };
       MethodCall @[2] {
	desc="increments other phase state information to prepare for the next phase of settling";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][2].args[0]$;
	method=LeabraNetwork::Trial_UpdatePhase;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      test {
       expr="phase_no < network.phase_max";
      };
     };
     MethodCall @[3] {
      desc="after the trial is over, do final computations: Compute_dWt (learn weights), compute stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][2].args[0]$;
      method=LeabraNetwork::Trial_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     If @[4] {
      desc=;
      flags=;
      cond {
       expr="network.Compute_Weights_Test(network.trial+1)";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="update the weight values based on changes computed by trial program";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][2].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
     };
     ProgramCall @[5] {
      desc="records data about the trial-level processing to a datatable for graphing/processing";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[0][6]$$;
      targ_ld_init="*LeabraTrialMonitor*";
     };
     NetUpdateView @[6] {
      desc="update the network view(s) (only if update_net_view is true)";
      flags=;
      network_var=$.projects[0].programs.gp[0][2].args[0]$;
      update_var=.projects[0].programs.gp[0][2].vars[1]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[3] {
    name="LeabraSettle";
    short_nm="Settle";
    tags="Leabra, Std";
    desc="iterates over cycles of updating until network has settled into a stable state, or output activations have exceeded a threshold";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="cycle";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current cycle of settling (local loop counter)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="min_cycles";
      var_type=T_Int;
      int_val=15;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="IMPORTANT: this value is obtained from the network min_cycles and min_cycles_phase2 -- change the value on the network object, not here in this program!
sets the minimum number of cycles to settle for, regardless of network state changes, etc";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=1;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="if true, will update network views at end of settling";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="ApplyInputs";
      var_type=T_Object;
      object_type=Program;
      object_val=.projects[0].programs.gp[0][5]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=.projects[0].programs.gp[0][3].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][3].vars[0]$$;
      counter=Network::cycle;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=$.projects[0].programs.gp[0][3].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][3].vars[0]$;
      counter=Network::cycle;
      update_after=0;
     };
     MethodCall @[1] {
      desc="resets input data, before getting new external inputs data from apply inputs call";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][3].args[0]$;
      method=Network::Init_InputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[2] {
      desc=;
      flags=NON_STD;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][3].vars[3]$$;
      method=Program::Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[3] {
      desc="apply external input activations from the input_data table to the network
this program can be extended to do arbitrary things to generate data and apply it to network layers";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
       ProgArg @[1] {
	arg_type=DataTable;
	type="DataTable*";
	name="input_data";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
      };
      target=$.projects[0].programs.gp[0][5]$;
      targ_ld_init="*ApplyInputs*";
     };
     MethodCall @[4] {
      desc="initializes various counters at start of settling";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][3].args[0]$;
      method=LeabraNetwork::Settle_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[5] {
      desc="get appropriate min_cycles value depending on which phase we're in";
      flags=;
      cond {
       expr="network.phase_no <= 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=.projects[0].programs.gp[0][3].vars[1]$$;
	expr {
	 expr="network.min_cycles";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=$.projects[0].programs.gp[0][3].vars[1]$;
	expr {
	 expr="network.min_cycles_phase2";
	};
       };
      };
     };
     WhileLoop @[6] {
      desc="the main loop over cycles of updating";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the cycle program, which computes one cycle of activations";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][4]$$;
	targ_ld_init="*LeabraCycle*";
       };
       NetCounterIncr @[1] {
	desc="increment cycle counter (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][3].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][3].vars[0]$;
	counter=Network::cycle;
	update_after=0;
       };
       IfContinue @[2] {
	desc="avoid subsequent stopping criteria if below min_cycles";
	flags=;
	cond {
	 expr="cycle < min_cycles";
	};
       };
       IfBreak @[3] {
	desc="stopping criterion for settling: based either on maximum change in activation (maxda) or on the maximum activation value in the network getting over threshold (which ever comes first).  Set either parmeter to values that are always false (e.g., trg_max_act_stopcrit = -1) to eliminate associated source of criterion for stopping settling.";
	flags=;
	cond {
	 expr="(network.maxda < network.maxda_stopcrit) ||
 (network.trg_max_act > network.trg_max_act_stopcrit)";
	};
       };
      };
      test {
       expr="cycle < network.cycle_max";
      };
     };
     MethodCall @[7] {
      desc="perform final operations at end of settling (storing final activations, etc)";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][3].args[0]$;
      method=LeabraNetwork::Settle_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[8] {
      desc="only run trial-level statistics in minus phase (otherwise network may have correct answer clamped on!).  IMPORTANT: this assumes that you've got target activation values for output layers already
presented in the minus phase -- if this is not the case (values are computed on the fly), you may want to run this instead at the start of the plus phase, after ApplyInputs";
      flags=;
      cond {
       expr="network.phase == LeabraNetwork::MINUS_PHASE";
      };
      true_code {
       name=;
       el_typ=MethodCall;
       el_def=0;
       MethodCall @[0] {
	desc="compute trial-level statistics";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][3].args[0]$;
	method=LeabraNetwork::Compute_TrialStats;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     IfElse @[9] {
      desc="this stat must be called in plus phase when reward information is avail";
      flags=;
      cond {
       expr="network.phase_no == 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="get external reward information";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][3].args[0]$;
	method=LeabraNetwork::Compute_ExtRew;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     NetUpdateView @[10] {
      desc="update network views, if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[0][3].args[0]$;
      update_var=.projects[0].programs.gp[0][3].vars[2]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[4] {
    name="LeabraCycle";
    short_nm="Cycle";
    tags="Leabra, Std";
    desc="runs one cycle of leabra processing (updating net inputs and activations)";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether network views will be updated on a cycle-by-cycle basis (slow, but often quite useful for seeing how processing is proceeding)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="this does all the standard leabra processing for one cycle of activation updating";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][4].args[0]$$;
      method=LeabraNetwork::Cycle_Run;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetUpdateView @[1] {
      desc="update network views if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[0][4].args[0]$;
      update_var=$.projects[0].programs.gp[0][4].vars[0]$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[5] {
    name="ApplyInputs";
    short_nm="AplyIn";
    tags="Network, InputData, Apply";
    desc="apply the current input data to the network as external input and target values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=LayerWriter;
     el_def=0;
     LayerWriter @[0] {
      name="LayerWriter_0";
      data=$.projects[0].data.gp[0][0]$;
      network=$.projects[0].networks[0]$;
      layer_data {
       name=;
       el_typ=LayerWriterEl;
       el_def=0;
       LayerWriterEl @[0] {
	chan_name="Input";
	net_target=LAYER;
	layer_name="Input";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=EXT;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[1] {
	chan_name="Output";
	net_target=LAYER;
	layer_name="Output";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=TARG;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[2] {
	chan_name="Name";
	net_target=TRIAL_NAME;
	layer_name="Name";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
      };
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to apply inputs to -- typically set by calling program";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="input datatable containing input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="LayerWriter_0";
      var_type=T_Object;
      object_type=LayerWriter;
      object_val=.projects[0].programs.gp[0][5].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="this is a pointer to the LayerWriter object in objs -- edit that object to determine how information is presented to the network";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][5].vars[0]$$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the layer writer -- will emit warnings and errors for missing or misconfigured items";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][5].vars[0]$;
      method=taList_impl::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][5].vars[0]$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="apply inputs to the network!  layer writer has all the key specs";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][5].vars[0]$;
      method=LayerWriter::ApplyInputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[6] {
    name="LeabraTrialMonitor";
    short_nm="TrlMon";
    tags="Leabra, Std, Monitor";
    desc="monitor trial-level data from the network (and potentially other sources) -- stores results in datatable (TrialOutputData typically) that can be used for graph/grid views and further analysis ";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="trial_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="trial_name";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial_name";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="act";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="act";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="Aggregate": op=NONE: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="SimpleMathSpec": opr=NONE: arg=0.5: lw=0: hi=1: };
	pre_proc_2 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][0]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to record data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to record trial-level data to (this program writes new data to this table!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[0][6].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the NetMonitor object in objs secton of this program that contains configuration for what to record and where to get it";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="set the network and datatable for the NetMonitor";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][6].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the network monitor -- will emit warnings and errors for misconfigurations";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="update the monitor items and data schema based on current settings of the NetMonitor object";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][6].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data from the network and other sources -- this does the main work";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[2] {
      desc="update views and other things after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[3] {
      desc="only functional for dmem projects: synchronizes trial data across processes so that all distributed memory processors have the same trial-level data, despite having run only a subset of them each";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][6].args[0]$$;
      method=Network::DMem_ShareTrialData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="n_rows";
	required=0;
	def_val="1";
	expr {
	 expr="1";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[7] {
    name="LeabraEpochMonitor";
    short_nm="EpcMon";
    tags="Leabra, Std, Monitor";
    desc="monitor epoch-level data from the network to a datatable (EpochOutputData typically) for use in graphing and viewing and further analysis";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="epoch_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="avg_sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="cnt_err";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="cnt_err";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="avg_ext_rew";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_ext_rew";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[5] {
	name="avg_cycles";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_cycles";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[6] {
	name="epoch_time_tot";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[7] {
	name="epoch_time_usr";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=.projects[0].data.gp[1][1]$$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="network to get data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="epoch_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to write the epoch data to";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[0][7].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network monitor object that contains full specs for what to record and where to get it";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the network's epoch-level timer, to record how long it took to process an epoch";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=AssignExpr;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=.projects[0].programs.gp[0][7].vars[2]$$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[1] {
      desc="set data and network on NetMonitor object";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][7].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="epoch_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="check configuration and emit errors/warnings for problems";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="update the monitor items and data schema based on current settings of NetMonitor";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][7].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data and stor it into the data table -- this does the main job here";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     AssignExpr @[2] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=$.projects[0].programs.gp[0][7].vars[2]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[3] {
      desc="set the total time to compute the epoch (epoch_time_tot -- wall clock time) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetTotSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_tot\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[4] {
      desc="set the user process time (cpu time for this process, epoch_time_usr) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetUsrSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_usr\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[5] {
      desc="update after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[8] {
    name="SaveWeights";
    short_nm="SvWts";
    tags="Network, Weights";
    desc="save network's current weight values to file using WriteWeights function, with file name based on project name + batch + epoch values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="tag";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="user-provided tag (startup script will set this!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="wts_subdir";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="user-provided subdirectory to save weights in";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="fname";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="final generated file name -- do not edit!";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="epoch_str";
      var_type=T_String;
      string_val="0036";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="string rep of epoch with leading zeros";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="batch_str";
      var_type=T_String;
      string_val="03";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="string rep of batch with leading zeros";
      init_from=NULL;
     };
     ProgVar @[5] {
      name="final_tag";
      var_type=T_String;
      string_val=".03_0036";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="batch + epoch";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     IfReturn @[0] {
      desc="do not save if not the first dmem process (only relevant for dmem = distributed memory processing)";
      flags=;
      cond {
       expr="taMisc::dmem_proc > 0";
      };
     };
     MiscCall @[1] {
      desc="get current batch counter for file name, with leading zeros to length 3";
      flags=;
      result_var=.projects[0].programs.gp[0][8].vars[4]$$;
      object_type=taMisc;
      method=taMisc::LeadingZeros;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=int;
	type="int";
	name="num";
	required=1;
	def_val=;
	expr {
	 expr="network.batch";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="len";
	required=1;
	def_val=;
	expr {
	 expr="2";
	};
       };
      };
     };
     MiscCall @[2] {
      desc="get current epoch counter with leading zeros to length 4";
      flags=;
      result_var=.projects[0].programs.gp[0][8].vars[3]$$;
      object_type=taMisc;
      method=taMisc::LeadingZeros;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=int;
	type="int";
	name="num";
	required=1;
	def_val=;
	expr {
	 expr="network.epoch";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="len";
	required=1;
	def_val=;
	expr {
	 expr="4";
	};
       };
      };
     };
     AssignExpr @[3] {
      desc="string 'tag' to identify the batch, epoch, and other user id info for the weights";
      flags=;
      result_var=.projects[0].programs.gp[0][8].vars[5]$$;
      expr {
       expr="tag + \".\" + batch_str + \"_\" + epoch_str";
      };
     };
     MethodCall @[4] {
      desc="get a file name based on the project's current file name, for saving the weights";
      flags=;
      result_var=.projects[0].programs.gp[0][8].vars[2]$$;
      obj=.projects[0].programs.gp[0][8].args[0]$$;
      method=taBase::GetFileNameFmProject;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="ext";
	required=1;
	def_val=;
	expr {
	 expr="\".wts.gz\"";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="tag";
	required=0;
	def_val="\"\"";
	expr {
	 expr="final_tag";
	};
       };
       ProgArg @[2] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="subdir";
	required=0;
	def_val="\"\"";
	expr {
	 expr="wts_subdir";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="dmem_proc_no";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[5] {
      desc="save the weights to that file name";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][8].args[0]$;
      method=Network::SaveWeights;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="fname";
	required=0;
	def_val="\"\"";
	expr {
	 expr="fname";
	};
       };
       ProgArg @[1] {
	arg_type=Network::WtSaveFormat;
	type="Network::WtSaveFormat";
	name="fmt";
	required=0;
	def_val="Network::NET_FMT";
	expr {
	 expr="Network::NET_FMT";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
  };
  Program_Group @.gp[1] {
   name="LeabraAll_Test";
   el_typ=Program;
   el_def=0;
   tags="Leabra, Std, All, Test";
   desc="The full set of programs for testing a standard Leabra network (starting with Epoch)";
   Program @[0] {
    name="LeabraEpochTest";
    short_nm="EpcTst";
    tags="Leabra, Std, Test";
    desc="sets testing flag, iterates over all of the items in a data table and calls LeabraTestTrial process on them";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="table of patterns to present to the network, one row at a time";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="data_loop_order";
      var_type=T_HardEnum;
      int_val=0;
      hard_enum_type=DataLoop::Order;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="controls the order in which events (rows of the input data datatable) are presented to the network
(SEQUENTIAL, PERMUTED, RANDOM)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="trial-level output data -- we reset it every epoch by default, so it just contains last epoch of data";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="timer to record time required to perform one epoch of processing (object is on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="data_loop_index";
      var_type=T_Int;
      int_val=4;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="index counter for the looping over items in the input_data datatable (not always the same as trial counter, depending on distributed memory computation)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=.projects[0].programs.gp[1][0].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][0].vars[1]$$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=.projects[0].programs.gp[1][0].vars[3]$$;
      expr {
       expr="network.epoch_time";
      };
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=$.projects[0].programs.gp[1][0].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][0].vars[1]$;
      counter=Network::trial;
      update_after=0;
     };
     MemberAssign @[1] {
      desc="set to testing mode";
      flags=NEW_EL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      path="train_mode";
      expr {
       expr="Network::TEST";
      };
      update_after=0;
     };
     AssignExpr @[2] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=$.projects[0].programs.gp[1][0].vars[3]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[3] {
      desc="start the epoch timer to record computation time per epoch";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].vars[3]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MethodCall @[4] {
      desc="reset trial-level monitor data every epoch, so it reflects only the most recent epoch's worth of data (turn flags OFF to accumulate trial data across entire training run)";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][0].vars[2]$$;
      method=DataTable::ResetData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetDataLoop @[5] {
      desc="iterates over the events/rows of input_data, according to data_loop_order variable";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the trial program, passing network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=$.projects[0].programs.gp[1][1]$;
	targ_ld_init="*LeabraTrial*";
       };
       IfElse @[1] {
	desc="test if it is time to update the weight values from delta weights (dWt) computed over trials";
	flags=;
	cond {
	 expr="network.Compute_Weights_Test(trial+1)";
	};
	true_code {
	 name=;
	 el_typ=MethodCall;
	 el_def=0;
	 MethodCall @[0] {
	  desc="update the weight values based on changes computed by trial program";
	  flags=;
	  result_var=NULL;
	  obj=$.projects[0].programs.gp[1][0].args[0]$;
	  method=Network::Compute_Weights;
	  meth_args {
	   name=;
	   el_typ=ProgArg;
	   el_def=0;
	  };
	 };
	};
	false_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	};
       };
      };
      data_var=.projects[0].programs.gp[1][0].args[1]$$;
      index_var=.projects[0].programs.gp[1][0].vars[4]$$;
      order_var=.projects[0].programs.gp[1][0].vars[0]$$;
      order=SEQUENTIAL;
      item_idx_list{ 0;1;2;3;      };
      update_after=0;
      dmem_nprocs=1;
      dmem_this_proc=0;
      grouped=0;
      group_col 9 0="Group";
      group_index_var=NULL;
      group_order_var=NULL;
      group_order=PERMUTED;
      group_idx_list{       };
     };
     IfElse @[6] {
      desc="if full batch mode, update only at end of epoch";
      flags=;
      cond {
       expr="network.wt_update == Network::BATCH";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="final update of weights based on accumulated changes";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][0].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     MethodCall @[7] {
      desc="network accumulates some core statistics over the epoch -- this finalizes that process and computes summary stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      method=LeabraNetwork::Compute_EpochStats;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[8] {
      desc="done with the computation in the epoch -- record time it took";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].vars[3]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[9] {
      desc="run program that records data from network and possibly other sources about the epoch";
      flags=NON_STD;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[1][6]$$;
      targ_ld_init="*LeabraEpochMonitor*";
     };
     MemberAssign @[10] {
      desc="set back to training mode";
      flags=NEW_EL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      path="train_mode";
      expr {
       expr="Network::TRAIN";
      };
      update_after=0;
     };
    };
    step_prog=$.projects[0].programs.gp[1][1]$;
    step_n=1;
   };
   Program @[1] {
    name="LeabraTrialTest";
    short_nm="TrlTst";
    tags="Leabra, Std";
    desc="Leabra processing of a single input/toutput event or external information: typically runs a minus and a plus phase, then learns (unless testing)";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on -- typically set by higher-level calling programs";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable containing training input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="phase_no";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="local phase counting variable (0 is typically minus phase, 1 is typically plus -- depends on network settings)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether to update any network view displays after trial is completed";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=.projects[0].programs.gp[1][1].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][1].vars[0]$$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=$.projects[0].programs.gp[1][1].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][1].vars[0]$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
     MethodCall @[1] {
      desc="initializes various counters at start of trial";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][1].args[0]$;
      method=LeabraNetwork::Trial_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     WhileLoop @[2] {
      desc="loop over phases of settling in the network";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the settle program (which iterates over cyles of network activation updating) for each phase";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[1][2]$$;
	targ_ld_init="*LeabraSettle*";
       };
       NetCounterIncr @[1] {
	desc="increment the phase number (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[1][1].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[1][1].vars[0]$;
	counter=LeabraNetwork::phase_no;
	update_after=0;
       };
       MethodCall @[2] {
	desc="increments other phase state information to prepare for the next phase of settling";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][1].args[0]$;
	method=LeabraNetwork::Trial_UpdatePhase;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      test {
       expr="phase_no < network.phase_max";
      };
     };
     MethodCall @[3] {
      desc="after the trial is over, do final computations: Compute_dWt (learn weights), compute stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][1].args[0]$;
      method=LeabraNetwork::Trial_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[4] {
      desc="records data about the trial-level processing to a datatable for graphing/processing";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[1][5]$$;
      targ_ld_init="*LeabraTrialMonitor*";
     };
     NetUpdateView @[5] {
      desc="update the network view(s) (only if update_net_view is true)";
      flags=;
      network_var=$.projects[0].programs.gp[1][1].args[0]$;
      update_var=.projects[0].programs.gp[1][1].vars[1]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[2] {
    name="LeabraSettleTest";
    short_nm="SttTst";
    tags="Leabra, Std";
    desc="iterates over cycles of updating until network has settled into a stable state, or output activations have exceeded a threshold";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="cycle";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current cycle of settling (local loop counter)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="min_cycles";
      var_type=T_Int;
      int_val=15;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="IMPORTANT: this value is obtained from the network min_cycles and min_cycles_phase2 -- change the value on the network object, not here in this program!
sets the minimum number of cycles to settle for, regardless of network state changes, etc";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=1;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="if true, will update network views at end of settling";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=.projects[0].programs.gp[1][2].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][2].vars[0]$$;
      counter=Network::cycle;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=$.projects[0].programs.gp[1][2].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][2].vars[0]$;
      counter=Network::cycle;
      update_after=0;
     };
     MethodCall @[1] {
      desc="resets input data, before getting new external inputs data from apply inputs call";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=Network::Init_InputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[2] {
      desc="apply external input activations from the input_data table to the network
this program can be extended to do arbitrary things to generate data and apply it to network layers";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
       ProgArg @[1] {
	arg_type=DataTable;
	type="DataTable*";
	name="input_data";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
      };
      target=.projects[0].programs.gp[1][4]$$;
      targ_ld_init="*ApplyInputs*";
     };
     MethodCall @[3] {
      desc="initializes various counters at start of settling";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=LeabraNetwork::Settle_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[4] {
      desc="get appropriate min_cycles value depending on which phase we're in";
      flags=;
      cond {
       expr="network.phase_no <= 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=.projects[0].programs.gp[1][2].vars[1]$$;
	expr {
	 expr="network.min_cycles";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=$.projects[0].programs.gp[1][2].vars[1]$;
	expr {
	 expr="network.min_cycles_phase2";
	};
       };
      };
     };
     WhileLoop @[5] {
      desc="the main loop over cycles of updating";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the cycle program, which computes one cycle of activations";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	};
	target=.projects[0].programs.gp[1][3]$$;
	targ_ld_init="*LeabraCycle*";
       };
       NetCounterIncr @[1] {
	desc="increment cycle counter (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[1][2].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[1][2].vars[0]$;
	counter=Network::cycle;
	update_after=0;
       };
       IfContinue @[2] {
	desc="avoid subsequent stopping criteria if below min_cycles";
	flags=;
	cond {
	 expr="cycle < min_cycles";
	};
       };
       IfBreak @[3] {
	desc="stopping criterion for settling: based either on maximum change in activation (maxda) or on the maximum activation value in the network getting over threshold (which ever comes first).  Set either parmeter to values that are always false (e.g., trg_max_act_stopcrit = -1) to eliminate associated source of criterion for stopping settling.";
	flags=;
	cond {
	 expr="(network.maxda < network.maxda_stopcrit) ||
 (network.trg_max_act > network.trg_max_act_stopcrit)";
	};
       };
      };
      test {
       expr="cycle < network.cycle_max";
      };
     };
     MethodCall @[6] {
      desc="perform final operations at end of settling (storing final activations, etc)";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=LeabraNetwork::Settle_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[7] {
      desc="only run trial-level statistics in minus phase (otherwise network may have correct answer clamped on!).  IMPORTANT: this assumes that you've got target activation values for output layers already
presented in the minus phase -- if this is not the case (values are computed on the fly), you may want to run this instead at the start of the plus phase, after ApplyInputs";
      flags=;
      cond {
       expr="network.phase == LeabraNetwork::MINUS_PHASE";
      };
      true_code {
       name=;
       el_typ=MethodCall;
       el_def=0;
       MethodCall @[0] {
	desc="compute trial-level statistics";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][2].args[0]$;
	method=LeabraNetwork::Compute_TrialStats;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     IfElse @[8] {
      desc="this stat must be called in plus phase when reward information is avail";
      flags=;
      cond {
       expr="network.phase_no == 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="get external reward information";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][2].args[0]$;
	method=LeabraNetwork::Compute_ExtRew;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     NetUpdateView @[9] {
      desc="update network views, if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[1][2].args[0]$;
      update_var=.projects[0].programs.gp[1][2].vars[2]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[3] {
    name="LeabraCycleTest";
    short_nm="CycTst";
    tags="Leabra, Std";
    desc="runs one cycle of leabra processing (updating net inputs and activations)";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether network views will be updated on a cycle-by-cycle basis (slow, but often quite useful for seeing how processing is proceeding)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="this does all the standard leabra processing for one cycle of activation updating";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][3].args[0]$$;
      method=LeabraNetwork::Cycle_Run;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetUpdateView @[1] {
      desc="update network views if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[1][3].args[0]$;
      update_var=.projects[0].programs.gp[1][3].vars[0]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[4] {
    name="ApplyInputsTest";
    short_nm="AplyIn";
    tags="Network, InputData, Apply";
    desc="apply the current input data to the network as external input and target values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=LayerWriter;
     el_def=0;
     LayerWriter @[0] {
      name="LayerWriter_0";
      data=$.projects[0].data.gp[0][0]$;
      network=$.projects[0].networks[0]$;
      layer_data {
       name=;
       el_typ=LayerWriterEl;
       el_def=0;
       LayerWriterEl @[0] {
	chan_name="Input";
	net_target=LAYER;
	layer_name="Input";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=EXT;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[1] {
	chan_name="Output";
	net_target=LAYER;
	layer_name="Output";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=TARG;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[2] {
	chan_name="Name";
	net_target=TRIAL_NAME;
	layer_name="Name";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
      };
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to apply inputs to -- typically set by calling program";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="input datatable containing input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="LayerWriter_0";
      var_type=T_Object;
      object_type=LayerWriter;
      object_val=.projects[0].programs.gp[1][4].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="this is a pointer to the LayerWriter object in objs -- edit that object to determine how information is presented to the network";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][4].vars[0]$$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the layer writer -- will emit warnings and errors for missing or misconfigured items";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][4].vars[0]$;
      method=taList_impl::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][4].vars[0]$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="apply inputs to the network!  layer writer has all the key specs";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][4].vars[0]$;
      method=LayerWriter::ApplyInputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[5] {
    name="LeabraTrialMonitorTest";
    short_nm="TrlMon";
    tags="Leabra, Std, Monitor";
    desc="monitor trial-level data from the network (and potentially other sources) -- stores results in datatable (TrialOutputData typically) that can be used for graph/grid views and further analysis ";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="trial_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="trial_name";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial_name";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="act";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="act";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="Aggregate": op=NONE: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="SimpleMathSpec": opr=NONE: arg=0.5: lw=0: hi=1: };
	pre_proc_2 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][0]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to record data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to record trial-level data to (this program writes new data to this table!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[1][5].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the NetMonitor object in objs secton of this program that contains configuration for what to record and where to get it";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="set the network and datatable for the NetMonitor";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the network monitor -- will emit warnings and errors for misconfigurations";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="update the monitor items and data schema based on current settings of the NetMonitor object";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data from the network and other sources -- this does the main work";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[2] {
      desc="update views and other things after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[3] {
      desc="only functional for dmem projects: synchronizes trial data across processes so that all distributed memory processors have the same trial-level data, despite having run only a subset of them each";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].args[0]$$;
      method=Network::DMem_ShareTrialData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="n_rows";
	required=0;
	def_val="1";
	expr {
	 expr="1";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[6] {
    name="LeabraEpochMonitorTest";
    short_nm="EpcMon";
    tags="Leabra, Std, Monitor";
    desc="monitor epoch-level data from the network to a datatable (EpochOutputData typically) for use in graphing and viewing and further analysis";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="epoch_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="avg_sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="cnt_err";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="cnt_err";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="avg_ext_rew";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_ext_rew";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[5] {
	name="avg_cycles";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_cycles";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[6] {
	name="epoch_time_tot";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[7] {
	name="epoch_time_usr";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][1]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to get data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="epoch_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to write the epoch data to";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[1][6].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network monitor object that contains full specs for what to record and where to get it";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the network's epoch-level timer, to record how long it took to process an epoch";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=AssignExpr;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=.projects[0].programs.gp[1][6].vars[2]$$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[1] {
      desc="set data and network on NetMonitor object";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][6].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="epoch_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="check configuration and emit errors/warnings for problems";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="update the monitor items and data schema based on current settings of NetMonitor";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][6].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data and stor it into the data table -- this does the main job here";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     AssignExpr @[2] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=$.projects[0].programs.gp[1][6].vars[2]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[3] {
      desc="set the total time to compute the epoch (epoch_time_tot -- wall clock time) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetTotSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_tot\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[4] {
      desc="set the user process time (cpu time for this process, epoch_time_usr) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetUsrSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_usr\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[5] {
      desc="update after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
  };
 };
 viewers {
  name=;
  el_typ=TopLevelViewer;
  el_def=0;
  MainWindowViewer @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="view_win_lft";
     value 6 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[1] {
     name="view_win_top";
     value 6 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[2] {
     name="view_win_wd";
     value 6 0=1;
     val_type_fixed=0;
    };
    UserDataItem @[3] {
     name="view_win_ht";
     value 6 0=0.7996109127998352;
     val_type_fixed=0;
    };
    UserDataItem @[4] {
     name="view_win_iconified";
     value 1 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[5] {
     name="view_splitter_state";
     value 9 0="AAAA/wAAAAAAAAADAAAApQAAAnAAAAM7AQAAAAYBAAAAAQ==";
     val_type_fixed=0;
    };
   };
   name="Browser3";
   m_data=.projects[0]$$;
   visible=1;
   m_is_root=0;
   m_is_viewer_xor_browser=0;
   m_is_proj_viewer=1;
   m_is_dialog=0;
   toolbars {
    name=;
    el_typ=ToolBar;
    el_def=0;
    ToolBar @[0] {
     UserDataItem_List @*(.user_data_) {
      name=;
      el_typ=UserDataItemBase;
      el_def=0;
      UserDataItem @[0] {
       name="view_win_visible";
       value 1 0=0;
       val_type_fixed=0;
      };
     };
     name="Application";
     m_data=NULL;
     visible=0;
     lft=0;
     top=0.0311284;
     o=Horizontal;
    };
   };
   frames {
    name=;
    el_typ=FrameViewer;
    el_def=0;
    tabBrowseViewer @[0] {
     name="Tree";
     m_data=NULL;
     visible=1;
     root_typ=LeabraProject;
     root_md=NULL;
     m_root=$.projects[0]$;
    };
    PanelViewer @[1] {
     name="Panels";
     m_data=NULL;
     visible=1;
    };
    T3DataViewer @[2] {
     name="T3Frames";
     m_data=NULL;
     visible=1;
     frames {
      name=;
      el_typ=T3DataViewFrame;
      el_def=0;
      T3DataViewFrame @[0] {
       name="PatAssocNet";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 NetView @[0] {
	  name=;
	  m_data=$.projects[0].networks[0]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=1: y=0: z=0: rot=0.35: }: translate={x=0: y=0: z=0: }: };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=1: y=0: z=0: rot=0.35: }: translate={x=0: y=0: z=0: }: };
	  display=1;
	  lay_mv=0;
	  net_text=1;
	  net_text_xform {scale={x=1: y=1: z=1: }: rotate={x=1: y=0: z=0: rot=1.570796: }: translate={x=1: y=0: z=-1: }: };
	  net_text_rot=-90;
	  cur_unit_vals{ act;	  };
	  unit_src_path=".layers[1].units[0]";
	  hist_idx=0;
	  hist_save=1;
	  hist_max=100;
	  hist_ff=5;
	  unit_disp_mode=UDM_BLOCK;
	  unit_text_disp=UTD_NONE;
	  max_size {x=4: y=1: z=1.5: };
	  font_sizes {
	   net_name=0.05;
	   net_vals=0.05;
	   layer=0.04;
	   layer_min=0.01;
	   layer_vals=0.03;
	   prjn=0.01;
	   unit=0.02;
	   un_nm_len=3;
	  };
	  view_params {
	   xy_square=0;
	   unit_spacing=0.05;
	   prjn_disp=L_R_F;
	   prjn_name=0;
	   prjn_width=0.002;
	   prjn_trans=0.5;
	   lay_trans=0.5;
	   unit_trans=0.6;
	   laygp_width=1;
	   show_laygp=1;
	  };
	  wt_line_disp=0;
	  wt_line_width=4;
	  wt_line_thr=0.5;
	  wt_line_swt=0;
	  wt_prjn_k_un=4;
	  wt_prjn_k_gp=1;
	  wt_prjn_lay=NULL;
	  snap_bord_disp=0;
	  snap_bord_width=4;
	  scale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=.colorspecs[0]$$<ColorScaleSpec,C_ColdHot>;
	   auto_scale=0;
	  };
	  scale_ranges {
	   name=;
	   el_typ=ScaleRange;
	   el_def=0;
	   ScaleRange @[0] {
	    name="act";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[1] {
	    name="r.wt";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[2] {
	    name="net";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[3] {
	    name="targ";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[4] {
	    name="act_m";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[5] {
	    name="act_p";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[6] {
	    name="ext";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[7] {
	    name="vcb.hyst";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[8] {
	    name="r.pdw";
	    auto_scale=1;
	    min=-0.005462845;
	    max=0.005462845;
	   };
	   ScaleRange @[9] {
	    name="s.pdw";
	    auto_scale=1;
	    min=-0;
	    max=0;
	   };
	  };
	  lay_disp_modes{ Input=0;Output=0;	  };
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=0.6801137: y=0.4857121: z=1.91429: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=2.225083;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[1] {
       name="EasyEnv";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=$.projects[0].data.gp[0][0]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="Name";
	    m_data=.projects[0].data.gp[0][0].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=16;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="Input";
	    m_data=.projects[0].data.gp[0][0].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=4;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="Output";
	    m_data=.projects[0].data.gp[0][0].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=2;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=3: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=2: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.5325: y=0.5174999: z=1.443747: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.453747;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[2] {
       name="HardEnv";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=.projects[0].data.gp[0][1]$$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="Name";
	    m_data=.projects[0].data.gp[0][1].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=16;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="Input";
	    m_data=.projects[0].data.gp[0][1].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=4;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="Output";
	    m_data=.projects[0].data.gp[0][1].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=2;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=3: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=2: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.5325: y=0.5174999: z=1.443747: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.453747;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[3] {
       name="ImpossibleEnv";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=.projects[0].data.gp[0][2]$$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="Name";
	    m_data=.projects[0].data.gp[0][2].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=16;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="Input";
	    m_data=.projects[0].data.gp[0][2].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=4;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="Output";
	    m_data=.projects[0].data.gp[0][2].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=2;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=3: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=2: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.5325: y=0.5174999: z=1.443747: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.453747;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[4] {
       name="TrialOutputGrid";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=$.projects[0].data.gp[1][0]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="trial_name";
	    m_data=.projects[0].data.gp[1][0].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=16;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="sse";
	    m_data=.projects[0].data.gp[1][0].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="Input_act";
	    m_data=.projects[0].data.gp[1][0].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=4;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[3] {
	    name="Output_act";
	    m_data=.projects[0].data.gp[1][0].data[3]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=2;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=-1: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=3: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.5325: y=0.5174999: z=1.443747: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.453747;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[5] {
       name="EpochOutputGraph";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GraphTableView @[0] {
	  name=;
	  m_data=$.projects[0].data.gp[1][1]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GraphColView;
	   el_def=0;
	   GraphColView @[0] {
	    name="batch";
	    m_data=.projects[0].data.gp[1][1].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[1] {
	    name="epoch";
	    m_data=.projects[0].data.gp[1][1].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=11: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[2] {
	    name="avg_sse";
	    m_data=.projects[0].data.gp[1][1].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=1: min=0: fix_max=0: max=1.05359: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[3] {
	    name="cnt_err";
	    m_data=.projects[0].data.gp[1][1].data[3]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[4] {
	    name="avg_ext_rew";
	    m_data=.projects[0].data.gp[1][1].data[4]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[5] {
	    name="avg_cycles";
	    m_data=.projects[0].data.gp[1][1].data[5]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[6] {
	    name="epoch_time_tot";
	    m_data=.projects[0].data.gp[1][1].data[6]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[7] {
	    name="epoch_time_usr";
	    m_data=.projects[0].data.gp[1][1].data[7]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10000;
	  view_range {min=0: max=-1: };
	  display_on=1;
	  manip_ctrl_on=1;
	  graph_type=XY;
	  plot_style=LINE;
	  negative_draw=0;
	  negative_draw_z=1;
	  line_width=2;
	  point_size=MEDIUM;
	  point_spacing=1;
	  bar_space=0.2;
	  label_spacing=-1;
	  width=1;
	  depth=1;
	  axis_font_size=0.05;
	  label_font_size=0.04;
	  x_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=X;
	   col_name="epoch";
	   fixed_range {fix_min=0: min=0: fix_max=0: max=10: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=10: };
	   range {min=0: max=10: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  z_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=Z;
	   col_name="batch";
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=-6e-19: max=6e-19: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  plot_1 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=Y;
	   col_name="avg_sse";
	   fixed_range {fix_min=1: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=6e-19: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  plot_2 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="red": r=1: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=SQUARE;
	   alt_y=0;
	  };
	  plot_3 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="blue": r=0: g=0: b=1: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=DIAMOND;
	   alt_y=0;
	  };
	  plot_4 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="green3": r=0: g=0.8039216: b=0: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=TRIANGLE;
	   alt_y=0;
	  };
	  plot_5 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="purple": r=0.627451: g=0.1254902: b=0.9411765: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=PLUS;
	   alt_y=0;
	  };
	  plot_6 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="orange": r=1: g=0.6470588: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CROSS;
	   alt_y=0;
	  };
	  plot_7 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="brown": r=0.6470588: g=0.1647059: b=0.1647059: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=STAR;
	   alt_y=0;
	  };
	  plot_8 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="chartreuse": r=0.4980392: g=1: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=MINUS;
	   alt_y=0;
	  };
	  alt_y_1=0;
	  alt_y_2=0;
	  alt_y_3=0;
	  alt_y_4=0;
	  alt_y_5=0;
	  err_1 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_2 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_3 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_4 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_5 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_6 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_7 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_8 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_spacing=1;
	  err_bar_width=0.02;
	  color_mode=VALUE_COLOR;
	  color_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=0;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  raster_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  thresh=0.5;
	  thr_line_len=0.48;
	  matrix_mode=SEP_GRAPHS;
	  mat_layout=BOT_ZERO;
	  mat_odd_vert=1;
	  two_d_font=0;
	  two_d_font_scale=350;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.429511: y=0.4449999: z=1.481323: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.991323;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
     };
    };
   };
   docks {
    name=;
    el_typ=DockViewer;
    el_def=0;
    ToolBoxDockViewer @[0] {
     UserDataItem_List @*(.user_data_) {
      name=;
      el_typ=UserDataItemBase;
      el_def=0;
      UserDataItem @[0] {
       name="view_win_lft";
       value 6 0=0;
       val_type_fixed=0;
      };
      UserDataItem @[1] {
       name="view_win_top";
       value 6 0=-0.02140077762305737;
       val_type_fixed=0;
      };
      UserDataItem @[2] {
       name="view_win_wd";
       value 6 0=0.05958230793476105;
       val_type_fixed=0;
      };
      UserDataItem @[3] {
       name="view_win_ht";
       value 6 0=0.7587548494338989;
       val_type_fixed=0;
      };
      UserDataItem @[4] {
       name="view_win_iconified";
       value 1 0=0;
       val_type_fixed=0;
      };
      UserDataItem @[5] {
       name="view_visible";
       value 1 0=0;
       val_type_fixed=0;
      };
     };
     name="Tools";
     m_data=NULL;
     visible=0;
     dock_flags=DV_MOVABLE|DV_FLOATABLE;
     dock_area=1;
    };
   };
  };
 };
 last_change_desc=;
 networks {
  name=;
  el_typ=LeabraNetwork;
  el_def=0;
  LeabraNetwork @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="norm_err";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[1] {
     name="ext_rew";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[2] {
     name="maxda";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[3] {
     name="minus_output_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[4] {
     name="minus_cycles";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[5] {
     name="ct_cycle";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[6] {
     name="phase_no";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[7] {
     name="phase";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[8] {
     name="sse";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[9] {
     name="output_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[10] {
     name="trial_name";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[11] {
     name="group_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[12] {
     name="time";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[13] {
     name="cycle";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[14] {
     name="tick";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[15] {
     name="trial";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[16] {
     name="group";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[17] {
     name="epoch";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[18] {
     name="batch";
     value 1 0=1;
     val_type_fixed=1;
    };
   };
   name="PatAssocNet";
   desc="pattern associator network";
   specs {
    name=;
    el_typ=LeabraUnitSpec;
    el_def=0;
    LeabraUnitSpec @[0] {
     name="UnitSpec_0";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=LeabraUnitSpec;
      el_def=0;
     };
     act_range {min=0: max=1: range=1: scale=1: };
     bias_con_type=LeabraCon;
     bias_spec {type=LeabraBiasSpec: spec=$.projects[0].networks[0].specs[3]$: };
     sse_tol=0.5;
     act_fun=NOISY_XX1;
     act {gelin=0: thr=0.25: gain=600: nvar=0.005: avg_dt=0.005: avg_init=0.15: i_thr=STD: };
     spike {rise=0: decay=0.05: g_gain=5: window=3: eq_gain=10: eq_dt=0.02: };
     spike_misc {
      exp_slope=0.02;
      spk_thr=1.2;
      clamp_max_p=0.11;
      clamp_type=REGULAR;
      vm_r=0.3;
      vm_dend=0.3;
      vm_dend_dt=0.16;
      vm_dend_time=6.25;
     };
     opt_thresh {send=0.1: delta=0.005: phase_dif=0: };
     maxda {val=INET_DA: inet_scale=1: lay_avg_thr=0.01: };
     clamp_range {min=0: max=0.95: range=0.95: scale=1.052632: };
     vm_range {min=0: max=1: range=1: scale=1: };
     v_m_init {name="": type=UNIFORM: mean=0.15: var=0: par=1: };
     dt {integ=1: vm=0.2: net=0.7: midpoint=0: d_vm_max=0.025: vm_eq_cyc=0: vm_eq_dt=1: integ_time=1: vm_time=5: net_time=1.428571: };
     act_avg {l_gain=3: l_dt=0.005: ml_dt=0.4: m_dt=0.1: s_dt=0.2: ss_dt=1: use_nd=0: l_time=200: ml_time=2.5: m_time=10: s_time=5: ss_time=1: };
     g_bar {e=1: l=0.1: i=1: h=0.1: a=0.5: };
     e_rev {e=1: l=0.15: i=0.15: h=1: a=0: };
     hyst {on=0: b_inc_dt=0.01: b_dec_dt=0.05: a_thr=0.5: d_thr=0.1: g_dt=0.1: init=1: trl=0: };
     acc {on=0: b_inc_dt=0.01: b_dec_dt=0.01: a_thr=0.5: d_thr=0.1: g_dt=0.1: init=1: trl=0: };
     adapt {
      on=0;
      dt=0.007;
      vm_gain=0.04;
      spike_gain=0.00805;
      interval=10;
      dt_time=142.8571;
     };
     depress {on=0: rec=0.2: asymp_act=0.5: depl=0.2105263: interval=1: max_amp=2: };
     syn_delay {
      on=0;
      delay=4;
     };
     da_mod {on=0: mod=PLUS_CONT: gain=0.1: };
     noise_type=NO_NOISE;
     noise {name="": type=GAUSSIAN: mean=0: var=0.001: par=1: };
     noise_adapt {trial_fixed=1: k_pos_noise=0: mode=FIXED_NOISE: min_pct=0.5: min_pct_c=0.5: };
     noise_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=1;
      cur_val=0;
     };
    };
    LeabraConSpec @[1] {
     name="ConSpec_0";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=LeabraConSpec;
      el_def=0;
     };
     rnd {name="": type=UNIFORM: mean=0.5: var=0.25: par=1: };
     wt_limits {type=MIN_MAX: min=0: max=1: sym=1: };
     learn_rule=LEABRA_CHL;
     inhib=0;
     wt_scale {abs=1: rel=1: sem_extra=2: old=0: };
     wt_scale_init {init=0: abs=1: rel=1: };
     lrate=0.01;
     cur_lrate=0.01;
     lrs_value=EPOCH;
     lrate_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=0;
      cur_val=0;
     };
     wt_sig {gain=6: off=1.25: };
     lmix {hebb=1: err=0: err_sb=1: };
     xcal {s_mix=0.9: m_mix=0.1: thr_l_mix=0.01: thr_m_mix=0.99: d_rev=0.1: d_gain=1: d_thr=0.0001: d_rev_ratio=9: };
     savg_cor {cor=1: thresh=0.01: norm_con_n=0: };
     rel_net_adapt {
      on=0;
      trg_fm_input=0.85;
      trg_fm_output=0.15;
      trg_lateral=0;
      trg_sum=1;
      tol_lg=0.05;
      tol_sm=0.2;
      rel_lrate=0.1;
     };
    };
    LeabraLayerSpec @[2] {
     name="InputLayer";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=LeabraLayerSpec;
      el_def=0;
      LeabraLayerSpec @[0] {
       name="OutputLayer";
       desc=;
       unique{ kwta;       };
       children {
	name=;
	el_typ=LeabraLayerSpec;
	el_def=0;
       };
       inhib_group=ENTIRE_LAYER;
       inhib {
	type=KWTA_AVG_INHIB;
	kwta_pt=0.6;
	min_i=0;
	fb_act_thr=0;
	ff_pct=0;
	fb_max_dt=0.1;
	comp_thr=0.5;
	comp_gain=2;
	gp_pt=0.2;
       };
       kwta {k_from=USE_K: k=1: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       gp_kwta {k_from=USE_PCT: k=12: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       tie_brk {on=0: k_thr=1: diff_thr=0.2: thr_gain=0.005: loser_gain=1: };
       i_netin_mod {on=0: max_mod=0.02: mod_gain=10: max_top_k=0.4: };
       adapt_i {type=NONE: tol=0.05: p_dt=0: mx_d=0.2: l=0.2: a_dt=0.005: };
       clamp {hard=1: gain=0.5: max_plus=0: plus=0.01: min_clamp=0.5: };
       decay {event=1: phase=1: phase2=0: clamp_phase2=0: };
       ct_inhib_mod {
	use_sin=0;
	burst_i=0.02;
	trough_i=0.02;
	use_fin=0;
	inhib_i=0;
       };
       abs_net_adapt {
	on=0;
	trg_net=0.5;
	tol=0.1;
	abs_lrate=0.1;
       };
      };
     };
     inhib_group=ENTIRE_LAYER;
     inhib {
      type=KWTA_AVG_INHIB;
      kwta_pt=0.6;
      min_i=0;
      fb_act_thr=0;
      ff_pct=0;
      fb_max_dt=0.1;
      comp_thr=0.5;
      comp_gain=2;
      gp_pt=0.2;
     };
     kwta {k_from=USE_K: k=2: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
     gp_kwta {k_from=USE_PCT: k=12: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
     tie_brk {on=0: k_thr=1: diff_thr=0.2: thr_gain=0.005: loser_gain=1: };
     i_netin_mod {on=0: max_mod=0.02: mod_gain=10: max_top_k=0.4: };
     adapt_i {type=NONE: tol=0.05: p_dt=0: mx_d=0.2: l=0.2: a_dt=0.005: };
     clamp {hard=1: gain=0.5: max_plus=0: plus=0.01: min_clamp=0.5: };
     decay {event=1: phase=1: phase2=0: clamp_phase2=0: };
     ct_inhib_mod {
      use_sin=0;
      burst_i=0.02;
      trough_i=0.02;
      use_fin=0;
      inhib_i=0;
     };
     abs_net_adapt {
      on=0;
      trg_net=0.5;
      tol=0.1;
      abs_lrate=0.1;
     };
    };
    LeabraBiasSpec @[3] {
     name="BiasSpec_0";
     desc=;
     unique{ rnd;wt_limits;wt_scale;wt_scale_init;     };
     children {
      name=;
      el_typ=LeabraBiasSpec;
      el_def=0;
     };
     rnd {name="": type=UNIFORM: mean=0: var=0: par=1: };
     wt_limits {type=NONE: min=-1: max=5: sym=0: };
     learn_rule=LEABRA_CHL;
     inhib=0;
     wt_scale {abs=1: rel=0.02: sem_extra=2: old=0: };
     wt_scale_init {init=0: abs=1: rel=1: };
     lrate=0;
     cur_lrate=0;
     lrs_value=EPOCH;
     lrate_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=0;
      cur_val=1;
     };
     wt_sig {gain=6: off=1.25: };
     lmix {hebb=0.01: err=0.99: err_sb=1: };
     xcal {s_mix=0.9: m_mix=0.1: thr_l_mix=0.01: thr_m_mix=0.99: d_rev=0.1: d_gain=1: d_thr=0.0001: d_rev_ratio=9: };
     savg_cor {cor=1: thresh=0.01: norm_con_n=0: };
     rel_net_adapt {
      on=0;
      trg_fm_input=0.85;
      trg_fm_output=0.15;
      trg_lateral=0;
      trg_sum=1;
      tol_lg=0.05;
      tol_sm=0.2;
      rel_lrate=0.1;
     };
     dwt_thresh=0.1;
    };
    FullPrjnSpec @[4] {
     name="FullPrjn";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=FullPrjnSpec;
      el_def=0;
     };
     self_con=0;
     init_wts=0;
     add_rnd_wts=0;
    };
   };
   layers {
    name=;
    el_typ=LeabraLayer;
    el_def=0;
    pos {x=0: y=0: z=0: };
    max_size {x=4: y=1: z=2: };
    LeabraLayer @[0] {
     name="Input";
     desc=;
     flags=;
     layer_type=INPUT;
     pos {x=0: y=0: z=0: };
     disp_scale=1;
     un_geom {x=4: y=1: n_not_xy=0: n=4: };
     unit_groups=0;
     gp_geom {x=0: y=0: n_not_xy=0: n=0: };
     gp_spc {x=0: y=0: };
     act_geom {x=4: y=1: n_not_xy=0: n=4: };
     scaled_act_geom {x=4: y=1: n_not_xy=0: n=1: };
     projections {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
     };
     send_prjns {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
	    Projection_Group @. = [0] = LeabraPrjn .projects[0].networks[0].layers[1].projections[0];
     };
     units {
      name=;
      el_typ=LeabraUnit;
      el_def=0;
      pos {x=0: y=0: z=0: };
      unique_geom=0;
      geom {x=4: y=1: n_not_xy=0: n=4: };
      units_lesioned=0;
      output_name=;
     };
     unit_spec {type=LeabraUnitSpec: spec=.projects[0].networks[0].specs[0]$$: };
     ext_flag=;
     dmem_dist=DMEM_DIST_DEFAULT;
     dist {
      fm_input=-1;
      fm_output=-1;
     };
     output_name=;
     sse=0;
     icon_value=0;
     netin {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     netin_top_k {cmpt=1: avg=0: max=0: max_i=-1: };
     i_thrs {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts_p {cmpt=1: avg=0.2375: max=0.95: max_i=3: };
     acts_m {cmpt=1: avg=0.2375: max=0.95: max_i=3: };
     phase_dif_ratio=1;
     acts_p2 {cmpt=1: avg=0: max=0: max_i=-1: };
     acts_m2 {cmpt=1: avg=0: max=0: max_i=-1: };
     kwta {k=2: pct=0.5: pct_c=0.5: adth_k=1: k_ithr=-0.1: k1_ithr=-0.1: ithr_r=0: ithr_diff=-0: tie_brk_gain=0: eff_loser_gain=1: tie_brk=0: };
     i_val {kwta=0: g_i=0: gp_g_i=0: g_i_orig=0: i_netin_mod=0: };
     un_g_i {cmpt=0: avg=0: max=-3.402823e+38: max_i=-1: };
     adapt_i {avg_avg=0.5: i_kwta_pt=0.6: g_bar_i=1: g_bar_l=0.1: };
     maxda=0;
     act_max_avg=0;
     spec {type=LeabraLayerSpec: spec=.projects[0].networks[0].specs[2]$$: };
     hard_clamped=0;
     avg_l_avg=0;
     dav=0;
     avg_netin {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_sum {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_n=0;
     norm_err=0;
     da_updt=0;
    };
    LeabraLayer @[1] {
     name="Output";
     desc=;
     flags=;
     layer_type=TARGET;
     pos {x=1: y=0: z=1: };
     disp_scale=1;
     un_geom {x=2: y=1: n_not_xy=0: n=2: };
     unit_groups=0;
     gp_geom {x=0: y=0: n_not_xy=0: n=0: };
     gp_spc {x=0: y=0: };
     act_geom {x=2: y=1: n_not_xy=0: n=2: };
     scaled_act_geom {x=2: y=1: n_not_xy=0: n=1: };
     projections {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
      LeabraPrjn @[0] {
       name="Fm_Input";
       from_type=CUSTOM;
       from=.projects[0].networks[0].layers[0]$$;
       spec {type=FullPrjnSpec: spec=.projects[0].networks[0].specs[4]$$: };
       con_type=LeabraCon;
       recvcons_type=LeabraRecvCons;
       sendcons_type=LeabraSendCons;
       con_spec {type=LeabraConSpec: spec=$.projects[0].networks[0].specs[1]$: };
       recv_idx=0;
       send_idx=0;
       recv_n=1;
       send_n=1;
       projected=1;
       direction=DIR_UNKNOWN;
       netin_avg=0;
       netin_rel=0;
       avg_netin_avg=0;
       avg_netin_avg_sum=0;
       avg_netin_rel=0;
       avg_netin_rel_sum=0;
       avg_netin_n=0;
       trg_netin_rel=-1;
      };
     };
     send_prjns {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
     };
     units {
      name=;
      el_typ=LeabraUnit;
      el_def=0;
      pos {x=0: y=0: z=0: };
      unique_geom=0;
      geom {x=2: y=1: n_not_xy=0: n=2: };
      units_lesioned=0;
      output_name=;
     };
     unit_spec {type=LeabraUnitSpec: spec=$.projects[0].networks[0].specs[0]$: };
     ext_flag=;
     dmem_dist=DMEM_DIST_DEFAULT;
     dist {
      fm_input=-1;
      fm_output=-1;
     };
     output_name=;
     sse=0;
     icon_value=0;
     netin {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     netin_top_k {cmpt=1: avg=0: max=0: max_i=-1: };
     i_thrs {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts_p {cmpt=1: avg=0.4766466: max=0.9532932: max_i=1: };
     acts_m {cmpt=1: avg=0.4766466: max=0.9532932: max_i=1: };
     phase_dif_ratio=1;
     acts_p2 {cmpt=1: avg=0: max=0: max_i=-1: };
     acts_m2 {cmpt=1: avg=0: max=0: max_i=-1: };
     kwta {k=1: pct=0.5: pct_c=0.5: adth_k=1: k_ithr=1.226186: k1_ithr=0.1854242: ithr_r=1.889017: ithr_diff=0.8487797: tie_brk_gain=0: eff_loser_gain=1: tie_brk=0: };
     i_val {kwta=0: g_i=0: gp_g_i=0: g_i_orig=0: i_netin_mod=0: };
     un_g_i {cmpt=0: avg=0: max=-3.402823e+38: max_i=-1: };
     adapt_i {avg_avg=0.5: i_kwta_pt=0.6: g_bar_i=1: g_bar_l=0.1: };
     maxda=0;
     act_max_avg=0;
     spec {type=LeabraLayerSpec: spec=.projects[0].networks[0].specs[2].children[0]$$: };
     hard_clamped=0;
     avg_l_avg=0;
     dav=0;
     avg_netin {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_sum {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_n=0;
     norm_err=0;
     da_updt=0;
    };
   };
   view_objs {
    name=;
    el_typ=NetViewObj;
    el_def=0;
   };
   flags=;
   auto_build=AUTO_BUILD;
   train_mode=TRAIN;
   wt_update=ON_LINE;
   small_batch_n=10;
   batch=0;
   epoch=0;
   group=0;
   trial=0;
   tick=0;
   cycle=0;
   time=0;
   group_name=;
   trial_name=;
   output_name=;
   sse_unit_avg=0;
   sse_sqrt=0;
   sse=0;
   sum_sse=0;
   avg_sse=0;
   cnt_err_tol=0;
   cnt_err=0;
   pct_err=0;
   pct_cor=0;
   cur_sum_sse=0;
   avg_sse_n=0;
   cur_cnt_err=0;
   train_time {name="": start={usr=843: sys=202: tot=128401349259: }: end={usr=982: sys=216: tot=128401349418: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   epoch_time {name="": start={usr=979: sys=215: tot=128401349416: }: end={usr=981: sys=215: tot=128401349417: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   trial_time {name="": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   settle_time {name="": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   cycle_time {name="": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   wt_sync_time {name="": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   misc_time {name="": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   threads {
    run_time {name="": s_used=0: n_used=0: };
    sync_time {name="": s_used=0: n_used=0: };
    total_time {name="": s_used=0: n_used=0: };
    n_wake_in_sync=0;
    run_time_pct=0;
    sync_time_pct=0;
    wake_in_sync_pct=0.006861665278624369;
    interleave=1;
    ignore_lay_sync=0;
   };
   dmem_sync_level=DMEM_SYNC_NETWORK;
   dmem_nprocs=1;
   usr1_save_fmt=FULL_NET;
   wt_save_fmt=TEXT;
   lay_layout=THREE_D;
   n_units=6;
   n_cons=8;
   max_size {x=4: y=1: z=2: };
   learn_rule=LEABRA_CHL;
   phase_order=MINUS_PLUS;
   no_plus_test=1;
   sequence_init=DO_NOTHING;
   phase=MINUS_PHASE;
   nothing_phase=0;
   phase_no=0;
   phase_max=1;
   ct_cycle=15;
   time_inc=1;
   cycle_max=60;
   mid_minus_cycle=-1;
   min_cycles=15;
   min_cycles_phase2=35;
   ct_time {
    minus=50;
    plus=20;
    inhib=1;
    n_avg_only_epcs=1;
    total_cycles=71;
    inhib_start=70;
   };
   ct_sravg {
    start=30;
    end=1;
    interval=1;
    plus_s_st=19;
    force_con=0;
   };
   ct_sin_i {
    start=30;
    duration=20;
    n_pi=2;
    burst_i=0.02;
    trough_i=0.02;
   };
   ct_fin_i {
    start=20;
    end=25;
    inhib_i=0;
   };
   sravg_vals {
    s_sum=0;
    s_nrm=0;
    m_sum=0;
    m_nrm=0;
    do_s=0;
   };
   ct_lrn_trig {
    plus_lrn_cyc=-1;
    davg_dt=0.1;
    davg_s_dt=0.05;
    davg_m_dt=0.03;
    davg_l_dt=0.0005;
    thr_min=0;
    thr_max=0.5;
    loc_max_cyc=8;
    loc_max_dec=0.01;
    lrn_delay=40;
    lrn_refract=100;
    davg_l_init=0;
    davg_max_init=0.001;
    davg_time=10;
    davg_s_time=20;
    davg_m_time=33.33334;
    davg_l_time=2000;
    lrn_delay_inc=0.025;
    lrn_refract_inc=0.01;
   };
   lrn_trig {
    davg=0;
    davg_s=0;
    davg_m=0;
    davg_smd=0;
    davg_l=0;
    davg_max=0.001;
    cyc_fm_inc=0;
    cyc_fm_dec=0;
    loc_max=0;
    lrn_max=0;
    lrn_trig=0;
    lrn=0;
    lrn_min=0;
    lrn_min_cyc=0;
    lrn_min_thr=0;
    lrn_min_sum=0;
    lrn_min_cyc_sum=0;
    lrn_min_thr_sum=0;
    lrn_plus=0;
    lrn_plus_cyc=0;
    lrn_plus_thr=0;
    lrn_plus_sum=0;
    lrn_plus_cyc_sum=0;
    lrn_plus_thr_sum=0;
    lrn_noth=0;
    lrn_noth_cyc=0;
    lrn_noth_thr=0;
    lrn_noth_sum=0;
    lrn_noth_cyc_sum=0;
    lrn_noth_thr_sum=0;
    lrn_stats_n=0;
   };
   minus_cycles=0;
   avg_cycles=0;
   avg_cycles_sum=0;
   avg_cycles_n=0;
   minus_output_name=;
   net_misc {
    cyc_syn_dep=0;
    syn_dep_int=20;
   };
   send_pct=0;
   send_pct_n=0;
   send_pct_tot=0;
   avg_send_pct=0;
   avg_send_pct_sum=0;
   avg_send_pct_n=0;
   maxda_stopcrit=0.005;
   maxda=0;
   trg_max_act_stopcrit=1;
   trg_max_act=0;
   ext_rew=0;
   ext_rew_avail=0;
   norew_val=0.5;
   avg_ext_rew=0;
   pvlv_pvi=0;
   pvlv_pvr=0;
   pvlv_lve=0;
   pvlv_lvi=0;
   pv_detected=0;
   avg_ext_rew_sum=0;
   avg_ext_rew_n=0;
   off_errs=1;
   on_errs=1;
   norm_err=0;
   avg_norm_err=1;
   avg_norm_err_sum=0;
   avg_norm_err_n=0;
  };
 };
};
