// ta_Dump File v3.0 -- code v5.1.0.0
LeabraProject .projects[0] { 
  taBase_Group @.templates = [0] {
  };

  Doc_Group @.docs = [2] {
    taDoc @[0] { };
    taDoc @[1] { };
  };

  Wizard_Group @.wizards = [1] {
    LeabraWizard @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };

      LayerWizElList @.layer_cfg = [3] {
	LayerWizEl @[0] { };
	LayerWizEl @[1] { };
	LayerWizEl @[2] { };
      };
    };
  };

  SelectEdit_Group @.edits = [1] {
    SelectEdit @[0] { 
      EditMbrItem_Group @.mbrs = [8] {
	EditMbrItem @[0] { };
	EditMbrItem @[1] { };
	EditMbrItem @[2] { };
	EditMbrItem @[3] { };
	EditMbrItem @[4] { };
	EditMbrItem @[5] { };
	EditMbrItem @[6] { };
	EditMbrItem @[7] { };
	EditMbrItem_Group @.gp[0] = [4] { 
	  EditMbrItem @[0] { };
	  EditMbrItem @[1] { };
	  EditMbrItem @[2] { };
	  EditMbrItem @[3] { };
	};
      };

      EditMthItem_Group @.mths = [8] {
	EditMthItem @[0] { };
	EditMthItem @[1] { };
	EditMthItem @[2] { };
	EditMthItem @[3] { };
	EditMthItem @[4] { };
	EditMthItem @[5] { };
	EditMthItem @[6] { };
	EditMthItem @[7] { };
      };
    };
  };

  DataTable_Group @.data = [0] {
    DataTable_Group @.gp[0] = [2] { 
      DataTable @[0] { 
	DataTableCols @.data = [2] {
	  String_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
      DataTable @[1] { 
	DataTableCols @.data = [2] {
	  String_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
    };
    DataTable_Group @.gp[1] = [5] { 
      DataTable @[0] { 
	DataTableCols @.data = [9] {
	  int_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[2] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  String_Data @[3] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  String_Data @[4] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  int_Data @[5] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  float_Data @[6] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[7] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[8] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
      DataTable @[1] { 
	DataTableCols @.data = [5] {
	  int_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  float_Data @[2] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[3] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[4] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
      DataTable @[2] { 
	DataTableCols @.data = [4] {
	  float_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[2] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[3] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
      DataTable @[3] { 
	DataTableCols @.data = [6] {
	  int_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  int_Data @[2] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  String_Data @[3] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  int_Data @[4] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
	      UserDataItem @[1] { };
      };
};
	  float_Data @[5] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	};
      };
      DataTable @[4] { 
	DataTableCols @.data = [8] {
	  int_Data @[0] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  int_Data @[1] { 
      UserDataItem_List @*(.user_data_) {
	      UserDataItem @[0] { };
      };
};
	  float_Data @[2] { };
	  float_Data @[3] { };
	  float_Data @[4] { };
	  float_Data @[5] { };
	  float_Data @[6] { };
	  float_Data @[7] { };
	};
      };
    };
    DataTable_Group @.gp[2] { 
    };
  };

  taBase_Group @.data_proc = [4] {
    taDataProc @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taDataAnal @[1] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taDataGen @[2] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
    taImageProc @[3] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
   };
};
  };

  Program_Group @.programs = [1] {
    Program @[0] { 
      ProgObjList @.objs = [0] {
      };

      ProgType_List @.types = [0] {
      };

      ProgVar_List @.args = [0] {
      };

      ProgVar_List @.vars = [12] {
	ProgVar @[0] { };
	ProgVar @[1] { };
	ProgVar @[2] { };
	ProgVar @[3] { };
	ProgVar @[4] { };
	ProgVar @[5] { };
	ProgVar @[6] { };
	ProgVar @[7] { };
	ProgVar @[8] { };
	ProgVar @[9] { };
	ProgVar @[10] { };
	ProgVar @[11] { };
      };

      Function_List @.functions = [0] {
      };

      ProgEl_List @.load_code = [0] {
      };

      ProgEl_List @.init_code = [0] {
      };

      ProgEl_List @.prog_code = [10] {
	MemberAssign @[0] { };
	MemberAssign @[1] { };
	MemberAssign @[2] { };
	MemberAssign @[3] { };
	MemberAssign @[4] { };
	MemberAssign @[5] { };
	MemberAssign @[6] { };
	MemberAssign @[7] { };
	MethodCall @[8] { 
	  ProgArg_List @.meth_args = [2] {
	    ProgArg @[0] { };
	    ProgArg @[1] { };
	  };
	};
	MethodCall @[9] { 
	  ProgArg_List @.meth_args = [0] {
	  };
	};
      };
    };
    Program_Group @.gp[0] = [11] { 
      Program @[0] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  NetCounterInit @[0] { };
	  ResetDataRows @[1] { };
	};

	ProgEl_List @.prog_code = [4] {
	  ResetDataRows @[0] { };
	  NetCounterInit @[1] { };
	  WhileLoop @[2] { 
	    ProgEl_List @.loop_code = [2] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [3] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		  ProgArg @[2] { };
		};
	      };
	      NetCounterIncr @[1] { };
	    };
	  };
	  ProgramCall @[3] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};
      };
      Program @[1] { 
	ProgObjList @.objs = [1] {
	  RndSeed @[0] { };
	};

	ProgType_List @.types = [1] {
	  DynEnumType @[0] { 
	    DynEnumItem_List @.enums = [2] {
	      DynEnumItem @[0] { };
	      DynEnumItem @[1] { };
	    };
	  };
	};

	ProgVar_List @.args = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	ProgVar_List @.vars = [10] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	  ProgVar @[6] { };
	  ProgVar @[7] { };
	  ProgVar @[8] { };
	  ProgVar @[9] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [8] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  AssignExpr @[2] { };
	  IfElse @[3] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  IfGuiPrompt @[4] { 
	    ProgEl_List @.yes_code = [2] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	      PrintExpr @[1] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MemberMethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};

	ProgEl_List @.prog_code = [8] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  AssignExpr @[1] { };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MemberAssign @[3] { };
	  IfElse @[4] { 
	    ProgEl_List @.true_code = [2] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	      PrintExpr @[1] { };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  AssignExpr @[5] { };
	  WhileLoop @[6] { 
	    ProgEl_List @.loop_code = [3] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      IfBreak @[2] { };
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[2] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [5] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	};

	ProgEl_List @.prog_code = [10] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetDataLoop @[4] { 
	    ProgEl_List @.loop_code = [1] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	    };
	  };
	  IfElse @[5] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[7] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[8] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  ProgramCall @[9] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};
      };
      Program @[3] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [7] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  WhileLoop @[2] { 
	    ProgEl_List @.loop_code = [3] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      MethodCall @[2] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  If @[4] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  ProgramCall @[5] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  NetUpdateView @[6] { };
	};
      };
      Program @[4] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [10] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[2] { 
	    ProgArg_List @.prog_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[4] { 
	    ProgEl_List @.true_code = [1] {
	      AssignExpr @[0] { };
	    };

	    ProgEl_List @.false_code = [1] {
	      AssignExpr @[0] { };
	    };
	  };
	  WhileLoop @[5] { 
	    ProgEl_List @.loop_code = [4] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [1] {
		  ProgArg @[0] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      IfContinue @[2] { };
	      IfBreak @[3] { };
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[7] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  IfElse @[8] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  NetUpdateView @[9] { };
	};
      };
      Program @[5] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetUpdateView @[1] { };
	};
      };
      Program @[6] { 
	ProgObjList @.objs = [1] {
	  LayerWriter @[0] { 
	    LayerDataEl_List @.layer_data = [2] {
	      LayerWriterEl @[0] { };
	      LayerWriterEl @[1] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [1] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[7] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [9] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	      NetMonItem @[5] { };
	      NetMonItem @[6] { };
	      NetMonItem @[7] { };
	      NetMonItem @[8] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [3] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [4] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
      Program @[8] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [5] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [4] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [4] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [5] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  OtherProgramVar @[2] { };
	  DataVarProg @[3] { };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[9] { 
	ProgObjList @.objs = [1] {
	  DataTable @[0] { 
	    DataTableCols @.data = [2] {
	      int_Data @[0] { 
	UserDataItem_List @*(.user_data_) {
		  UserDataItem @[0] { };
		  UserDataItem @[1] { };
	};
};
	      float_Data @[1] { 
	UserDataItem_List @*(.user_data_) {
		  UserDataItem @[0] { };
	};
};
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [2] {
	  DataGroupProg @[0] { 
	    DataOpList @.ops = [2] {
	      DataGroupEl @[0] { };
	      DataGroupEl @[1] { };
	    };
	  };
	  DataGroupProg @[1] { 
	    DataOpList @.ops = [4] {
	      DataGroupEl @[0] { };
	      DataGroupEl @[1] { };
	      DataGroupEl @[2] { };
	      DataGroupEl @[3] { };
	    };
	  };
	};
      };
      Program @[10] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [6] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [6] {
	  IfReturn @[0] { };
	  MiscCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MiscCall @[2] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  AssignExpr @[3] { };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
    };
    Program_Group @.gp[1] = [8] { 
      Program @[0] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [9] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	  ProgVar @[6] { };
	  ProgVar @[7] { };
	  ProgVar @[8] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  NetCounterInit @[0] { };
	  AssignExpr @[1] { };
	};

	ProgEl_List @.prog_code = [14] {
	  NetCounterInit @[0] { };
	  MemberAssign @[1] { };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  AssignExpr @[3] { };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetDataLoop @[6] { 
	    ProgEl_List @.loop_code = [2] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      IfElse @[1] { 
		ProgEl_List @.true_code = [1] {
		  MethodCall @[0] { 
		    ProgArg_List @.meth_args = [0] {
		    };
		  };
		};

		ProgEl_List @.false_code = [0] {
		};
	      };
	    };
	  };
	  IfElse @[7] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  MethodCall @[8] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[9] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[10] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  ProgramCall @[11] { 
	    ProgArg_List @.prog_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[12] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MemberAssign @[13] { };
	};
      };
      Program @[1] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [6] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  WhileLoop @[2] { 
	    ProgEl_List @.loop_code = [3] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      MethodCall @[2] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[4] { 
	    ProgArg_List @.prog_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  NetUpdateView @[5] { };
	};
      };
      Program @[2] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [1] {
	  NetCounterInit @[0] { };
	};

	ProgEl_List @.prog_code = [10] {
	  NetCounterInit @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  ProgramCall @[2] { 
	    ProgArg_List @.prog_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[4] { 
	    ProgEl_List @.true_code = [1] {
	      AssignExpr @[0] { };
	    };

	    ProgEl_List @.false_code = [1] {
	      AssignExpr @[0] { };
	    };
	  };
	  WhileLoop @[5] { 
	    ProgEl_List @.loop_code = [4] {
	      ProgramCall @[0] { 
		ProgArg_List @.prog_args = [1] {
		  ProgArg @[0] { };
		};
	      };
	      NetCounterIncr @[1] { };
	      IfContinue @[2] { };
	      IfBreak @[3] { };
	    };
	  };
	  MethodCall @[6] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  IfElse @[7] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  IfElse @[8] { 
	    ProgEl_List @.true_code = [1] {
	      MethodCall @[0] { 
		ProgArg_List @.meth_args = [0] {
		};
	      };
	    };

	    ProgEl_List @.false_code = [0] {
	    };
	  };
	  NetUpdateView @[9] { };
	};
      };
      Program @[3] { 
	ProgObjList @.objs = [0] {
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  NetUpdateView @[1] { };
	};
      };
      Program @[4] { 
	ProgObjList @.objs = [1] {
	  LayerWriter @[0] { 
	    LayerDataEl_List @.layer_data = [2] {
	      LayerWriterEl @[0] { };
	      LayerWriterEl @[1] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [1] {
	  ProgVar @[0] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [2] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [1] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[5] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [6] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	      NetMonItem @[5] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [3] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [4] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	};
      };
      Program @[6] { 
	ProgObjList @.objs = [1] {
	  NetMonitor @[0] { 
	    NetMonItem_List @.items = [8] {
	      NetMonItem @[0] { };
	      NetMonItem @[1] { };
	      NetMonItem @[2] { };
	      NetMonItem @[3] { };
	      NetMonItem @[4] { };
	      NetMonItem @[5] { };
	      NetMonItem @[6] { };
	      NetMonItem @[7] { };
	    };
	  };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [1] {
	  ProgVar @[0] { };
	};

	ProgVar_List @.vars = [3] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [4] {
	  AssignExpr @[0] { };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [2] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	    };
	  };
	  MethodCall @[2] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [1] {
	      ProgArg @[0] { };
	    };
	  };
	};

	ProgEl_List @.prog_code = [6] {
	  MethodCall @[0] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  MethodCall @[1] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	  AssignExpr @[2] { };
	  MethodCall @[3] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[4] { 
	    ProgArg_List @.meth_args = [4] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	    };
	  };
	  MethodCall @[5] { 
	    ProgArg_List @.meth_args = [0] {
	    };
	  };
	};
      };
      Program @[7] { 
	ProgObjList @.objs = [2] {
	  DataTable @[0] { 
	    DataTableCols @.data = [11] {
	      String_Data @[0] { };
	      float_Data @[1] { };
	      float_Data @[2] { };
	      float_Data @[3] { };
	      float_Data @[4] { };
	      float_Data @[5] { };
	      float_Data @[6] { };
	      float_Data @[7] { };
	      float_Data @[8] { };
	      float_Data @[9] { };
	      float_Data @[10] { };
	    };
	  };
	  Relation @[1] { };
	};

	ProgType_List @.types = [0] {
	};

	ProgVar_List @.args = [2] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	};

	ProgVar_List @.vars = [6] {
	  ProgVar @[0] { };
	  ProgVar @[1] { };
	  ProgVar @[2] { };
	  ProgVar @[3] { };
	  ProgVar @[4] { };
	  ProgVar @[5] { };
	};

	Function_List @.functions = [0] {
	};

	ProgEl_List @.load_code = [0] {
	};

	ProgEl_List @.init_code = [0] {
	};

	ProgEl_List @.prog_code = [3] {
	  DataAnalCall @[0] { 
	    ProgArg_List @.meth_args = [9] {
	      ProgArg @[0] { };
	      ProgArg @[1] { };
	      ProgArg @[2] { };
	      ProgArg @[3] { };
	      ProgArg @[4] { };
	      ProgArg @[5] { };
	      ProgArg @[6] { };
	      ProgArg @[7] { };
	      ProgArg @[8] { };
	    };
	  };
	  AssignExpr @[1] { };
	  ForLoop @[2] { 
	    ProgEl_List @.loop_code = [2] {
	      MathCall @[0] { 
		ProgArg_List @.meth_args = [2] {
		  ProgArg @[0] { };
		  ProgArg @[1] { };
		};
	      };
	      If @[1] { 
		ProgEl_List @.true_code = [1] {
		  VarIncr @[0] { };
		};
	      };
	    };
	  };
	};
      };
    };
  };

  DataViewer_List @.viewers = [1] {
    MainWindowViewer @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
	UserDataItem @[1] { };
	UserDataItem @[2] { };
	UserDataItem @[3] { };
	UserDataItem @[4] { };
	UserDataItem @[5] { };
   };

      ToolBar_List @.toolbars = [1] {
	ToolBar @[0] { 
     UserDataItem_List @*(.user_data_) {
	    UserDataItem @[0] { };
     };
};
      };

      FrameViewer_List @.frames = [3] {
	tabBrowseViewer @[0] { };
	PanelViewer @[1] { };
	T3DataViewer @[2] { 
	  T3DataViewFrame_List @.frames = [3] {
	    T3DataViewFrame @[0] { 
	      T3DataView_List @.children = [3] {
		NetView @[0] { 
		  ScaleRange_List @.scale_ranges = [2] {
		    ScaleRange @[0] { };
		    ScaleRange @[1] { };
		  };
		};
		GraphTableView @[1] { 
		  T3DataView_List @.children = [5] {
		    GraphColView @[0] { };
		    GraphColView @[1] { };
		    GraphColView @[2] { };
		    GraphColView @[3] { };
		    GraphColView @[4] { };
		  };
		};
		GridTableView @[2] { 
		  T3DataView_List @.children = [5] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		    GridColView @[3] { };
		    GridColView @[4] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[1] { 
	      T3DataView_List @.children = [2] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [2] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		  };
		};
		GridTableView @[1] { 
		  T3DataView_List @.children = [2] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	    T3DataViewFrame @[2] { 
	      T3DataView_List @.children = [1] {
		GridTableView @[0] { 
		  T3DataView_List @.children = [4] {
		    GridColView @[0] { };
		    GridColView @[1] { };
		    GridColView @[2] { };
		    GridColView @[3] { };
		  };
		};
	      };

	      T3SavedView_List @.saved_views = [6] {
		T3SavedView @[0] { };
		T3SavedView @[1] { };
		T3SavedView @[2] { };
		T3SavedView @[3] { };
		T3SavedView @[4] { };
		T3SavedView @[5] { };
	      };
	    };
	  };
	};
      };

      DockViewer_List @.docks = [1] {
	ToolBoxDockViewer @[0] { 
     UserDataItem_List @*(.user_data_) {
	    UserDataItem @[0] { };
	    UserDataItem @[1] { };
	    UserDataItem @[2] { };
	    UserDataItem @[3] { };
	    UserDataItem @[4] { };
	    UserDataItem @[5] { };
     };
};
      };
    };
  };

  Network_Group @.networks = [1] {
    LeabraNetwork @[0] { 
   UserDataItem_List @*(.user_data_) {
	UserDataItem @[0] { };
	UserDataItem @[1] { };
	UserDataItem @[2] { };
	UserDataItem @[3] { };
	UserDataItem @[4] { };
	UserDataItem @[5] { };
	UserDataItem @[6] { };
	UserDataItem @[7] { };
	UserDataItem @[8] { };
	UserDataItem @[9] { };
	UserDataItem @[10] { };
	UserDataItem @[11] { };
	UserDataItem @[12] { };
	UserDataItem @[13] { };
	UserDataItem @[14] { };
	UserDataItem @[15] { };
	UserDataItem @[16] { };
	UserDataItem @[17] { };
	UserDataItem @[18] { };
   };

      BaseSpec_Group @.specs = [5] {
	LeabraUnitSpec @[0] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.noise_sched = [0] {
	  };
	};
	LeabraConSpec @[1] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.lrate_sched = [0] {
	  };
	};
	LeabraLayerSpec @[2] { 
	  BaseSpec_Group @.children = [2] {
	    LeabraLayerSpec @[0] { 
	      BaseSpec_Group @.children = [0] {
	      };
	    };
	    LeabraLayerSpec @[1] { 
	      BaseSpec_Group @.children = [0] {
	      };
	    };
	  };
	};
	FullPrjnSpec @[3] { 
	  BaseSpec_Group @.children = [0] {
	  };
	};
	LeabraBiasSpec @[4] { 
	  BaseSpec_Group @.children = [0] {
	  };

	  Schedule @.lrate_sched = [0] {
	  };
	};
      };

      Layer_Group @.layers = [2] {
	LeabraLayer @[0] { 
	  Projection_Group @.projections = [0] {
	  };

	  Unit_Group @.units = [25] {
	  };
	};
	LeabraLayer @[1] { 
	  Projection_Group @.projections = [1] {
	    LeabraPrjn @[0] { };
	  };

	  Unit_Group @.units = [20] {
	  };
	};
      };

      NetViewObj_Group @.view_objs = [0] {
      };
    };
  };
};
LeabraProject .projects[0] {
 name="Project_0";
 desc="


";
 tags=;
 version {
  major=0;
  minor=0;
  step=0;
 };
 wiki_url {
  sync=0;
  wiki=;
  url=;
 };
 templates {
  name=;
  el_typ=taBase;
  el_def=0;
 };
 docs {
  name=;
  el_typ=taDoc;
  el_def=0;
  taDoc @[0] {
   name="ProjectDocs";
   desc=;
   auto_open=1;
   web_doc=0;
   wiki=;
   url="local";
   full_url="local";
   text_size=1;
   text="<html>
<head></head>
<body>
= Self Organizing Learning =

* GENERAL USAGE NOTE: To start, it is usually a good idea to do <code>Object/Edit Dialog</code> in the menu just above this text, which will open this documentation in a separate window that you can more easily come back to.  Alternatively, you can just always return to this document by clicking on the <code>ProjectDocs</code> tab at the top of the middle '''Panels''' frame.

We will continue with the \"lines\" theme in this exploration, by exposing a set of hidden units to an environment consisting of horizontal and vertical lines on a 5x5 input \"retina.\"

We focus first on the network.  The 5x5 input projects to a hidden layer of 20 units, which are all fully connected to the input with random initial weights.

* As usual, select r.wt and view the initialized weights for these units by clicking on several hidden units (use red arrow).  You will see that the initial wts have been randomized to different values.

Because viewing the pattern of weights over all the hidden units will be of primary concern as the network learns, we have a special grid view showing on the upper left of the network display, which displays the weights for all hidden units.  In addition, there is a graph view in the upper right, which will display key information as the network learns.

Let's see the environment the network will be experiencing.

* Click the [[.T3Tab.Lines_Input_Data]] tab in the right 3D view window.

This will bring up a display showing the first 10 training items on the left, which are composed of the elemental horizontal and vertical lines shown in the grid view display on the right.  You can use the narrow vertical violet scrollbar for the left grid view to scroll through all 45 of the patterns (you may have to click the red arrow first to be able to grab the scrollbar).  These 45 input patterns represent all unique pairwise combinations of vertical and horizontal lines. Thus, there are no real correlations between the lines, with the only reliable correlations being between the pixels that make up a particular line. To put this another way, each line can be thought of as appearing in a number of different randomly related contexts (i.e., with other lines).

It should be clear that if we computed the correlations between individual pixels across all of these images, everything would be equally (weakly) correlated with everything else.  Thus, learning must be conditional on the particular type of line for any meaningful correlations to be extracted.  We will see that this conditionality will simply self-organize through the interactions of the learning rule and the kWTA inhibitory competition.  Note also that because two lines are present in every image, the network will require at least two active hidden units per input, assuming each unit is representing a particular line.  

* Click back to the [[.T3Tab.Network]] display, and return to viewing act in the network window.  Then, hit [[.programs.LeabraTrain.Init()|Train: Init]] (say Yes to initializing the weights) and [[.programs.LeabraTrain.Step()|Step]] in the control panel, to present a  single pattern to the network.

You should see one of the event patterns containing two lines in the input of the network, and a pattern of roughly two active hidden units.

The hidden layer is using the average-based kWTA inhibition function, with the k parameter set to 2 as you can see in the kwta.k parameter in the control panel.  This function allows for some variability of actual activation level depending on the actual distribution of excitation across units in the hidden layer.  Thus, when more than two units are active, these units are being fairly equally activated by the input pattern due to the random initial weights not being very selective.  This is an important effect, because these weaker additional activations may enable these units to bootstrap into stronger activations through gradual learning, should they end up being reliably active in conjunction with a particular input feature (i.e., a particular line in this case).

* You can Step some more.  When you tire of single stepping, just press the (Train) [[.programs.LeabraTrain.Run()|Run]]  button on the control panel.  You may want to turn off the Display in the network (in the network view panel, [[.PanelTab.Network]]).

After 30 ''epochs'' (passes through all 45 different events in the environment) of learning, the network will stop. You should have noticed that the grid weights view was updated as the training proceeded. This grid view display shows all of the network's weights (figure 4.13 in the textbook shows an example).  The larger-scale 5x4 grid is topographically arranged in the same layout as the Hidden layer of the network.  Within each of these 20 grid elements is a smaller 5x5 grid representing the input units, showing the weights for each unit.  By clicking on the hidden units in the network window with the r.wt variable selected, you should be able to verify this correspondence.

As training proceded, the weights came to more and more clearly reflect the lines present in the environment (figure 4.13).  Thus, individual units developed ''selective'' representations of the correlations present within individual lines, while ignoring the random context of the other lines.

These individual line representations developed as a result of the interaction between learning and inhibitory competition as follows. Early on, the units that won the inhibitory competition were those that happened to have larger random weights for the input pattern. CPCA learning then tuned these weights to be more selective for that input pattern, causing them to be more likely to respond to that pattern and others that overlap with it (i.e., other patterns sharing one of the two lines).  To the extent that the weights are stronger for one of the two lines in the input, the unit will be more likely to respond to inputs having this line, and thus the conditional probability for the input units in this line will be stronger than for the other units, and the weights will continue to increase.  This is where the contrast enhancement bias plays an important role, because it emphasizes the strongest of the unit's correlations and deemphasizes the weaker ones.  This will make it much more likely that the strongest correlation in the environment -- the single lines -- end up getting represented.

You might have noticed in the weights displayed in the grid view during learning that some units initially seemed to be becoming selective for multiple lines, but then as other units were better able to represent one of those lines, they started to lose that competition and fall back to representing only one line.  Thus, the dynamics of the inhibitory competition are critical for the self-organizing effect, and it should be clear that a firm inhibitory constraint is important for this kind of learning (otherwise units will just end up being active a lot, and representing a mish-mash of line features). Nevertheless, the average-based kWTA function is sufficiently flexible that it can allow more than two units to become active, so you will probably see that sometimes multiple hidden units end up encoding the same line feature.

The net result of this self-organizing learning is a nice ''combinatorial'' distributed representation, where each input pattern is represented as the combination of the two line features present therein.  This is the \"obvious\" way to represent such inputs, but you should appreciate that the network nevertheless had to discover this representation through the somewhat complex self-organizing learning procedure.  

* To see this representation in action, turn the network Display back on, and Step through a few more events. (If you had previously let the network train to completion (30 epochs), you will have to increase the max_epoch paramenter to 31 in the ControlPanel to let you Step through a few more trials.)

Notice that in general two or more units are strongly activated by each input pattern, with the extra activation reflecting the fact that some lines are coded by multiple units.

Another thing to notice in the weights shown in the grid view (figure 4.13 in text) is that some units are obviously not selective for anything.  These \"loser\" units (also known as \"dead\" units) were never reliably activated by any input feature, and thus did not experience much learning.  It is typically quite important to have such units lying around, because self-organization requires some \"elbow room\" during learning to sort out the allocation of units to stable correlational features.  Having more hidden units also increases the chances of having a large enough range of initial random selectivities to seed the self-organization process.  The consequence is that you need to have more units than is minimally necessary, and that you will often end up with leftovers (plus the redundant units mentioned previously).

From a biological perspective, we know that the cortex does not produce a lot of new cortical neurons in adults, so we conclude that in general there is probably an excess of neural capacity relative to the demands of any given learning context.  Thus, it is useful to have these leftover and redundant units, because they constitute a \"reserve\" that could presumably get activated if new features were later presented to the network (e.g., diagonal lines).  We are much more suspicious of algorithms that require precisely tuned quantities of hidden units to work properly (more on this later).

== Unique Pattern Statistic ==

Although looking at the weights is informative, we could use a more concise measure of how well the network's internal model matches the underlying structure of the environment.  We one such measure is plotted in the graph view as the network learns.

This log shows the results of the '''unique pattern statistic''' (shown as uniq_pats in the graph), which records the number of unique hidden unit activity patterns that were produced as a result of probing the network with all 10 different types of horizontal and vertical lines (presented individually).  Thus, there is a separate testing process which, after each epoch of learning, tests the network on all 10 lines, records the resulting hidden unit activity patterns (with the kWTA parameter set to 1, though this is not critical due to the flexibility of the average-based kWTA function), and then counts up the number of unique such patterns (subject to thresholding so we only care about binary patterns of activity).

<em>'''Software Hint:''' You can view a \"close-up\" of just the graph itself by clicking on the small tab labeled \"Graph\" at the bottom of the far right window. </em>

The logic behind this measure is that if each line is encoded by (at least) one distinct hidden unit, then this will show up as a unique pattern.  If, however, there are units that encode two or more lines together (which is not a good model of this environment), then this will not result in a unique representation for these lines, and the resulting measure will be lower.  Thus, to the extent that this statistic is less than 10, the internal model produced by the network does not fully capture the underlying independence of each line from the other lines.  Note, however, that the unique pattern statistic does not care if ''multiple'' hidden units encode the same line (i.e., if there is redundancy across different hidden units) -- it only cares that the ''same'' hidden unit not encode ''two different'' lines.

You should have seen on this run that the model produced a perfect internal model according to this statistic, which accords well with our analysis of the weight patterns.  To get a better sense of how well the network learns in general, you can run a ''batch'' of 8 training runs starting with a different set of random initial weights
each time.

* Press Batch Init and Batch Run in the control panel to run.  You probably want to turn off the network Display again.  When it is done, you can click on the [[.T3Tab.BatchOutputData]] tab to view the results.

After the 8 training runs, the batch view shows summary statistics about the average (mean), maximum, and minimum of the unique pattern statistic at the end of each network training run.  The last column contains a count of the number of times that a \"perfect 10\" on the unique pattern statistic was recorded.  You should get a perfect score for all 8 runs.

== Parameter Manipulations ==

Now, let's explore the effects of some of the parameters in the control panel.  First, let's manipulate the wt_sig.gain parameter, which should affect the contrast (and therefore selectivity) of the unit's weights.

* Set wt_sig.gain to 1 instead of 6, Apply, and Batch Init, Run the network.

<hr>

'''Question 4.6 (a)''' ''What statistics for the number of uniquely represented lines did you obtain?'' '''(b)''' ''In what ways were the final weight patterns shown in the weight grid log different from the default case?'' '''(c)''' ''Explain how these two findings of hidden unit activity and weight patterns are related, making specific reference to the role of selectivity in self-organizing learning.''

<hr>

* Set wt_sig.gain back to 6, change wt_sig.off from 1.25 to 1, Apply, and run a Batch.  To make the effects of this parameter more dramatic, lower wt_sig.off to .75 and Batch again.


<em>'''Hint:''' If the EpochOutputData Grid and Graph do not display after training, click on the corresponding tabs at the bottom of the [[.T3Tab.Network]] tab (middle frame), and click on the <code>Refresh</code> button at the top right corner.

<hr>

'''Question 4.7 (a)''' ''What statistics did you obtain for these two cases (1 and .75)?'' '''(b)''' ''Was there a noticeable change in the weight patterns compared to the default case? (Hint: Consider what the unique pattern   statistic is looking for).'' '''(c)''' ''Explain these results in terms of the effects of wt_sig.off as adjusting the threshold for where correlations are enhanced or decreased as a function of the wt_sig.gain contrast enhancement mechanism.'' '''(d)''' ''Again, explain why this is important for self-organizing learning.''

<hr>

* Set wt_sig.off back to 1.25 (or hit Defaults).

Now, let's consider the savg_cor.cor parameter, which controls the amount of renormalization of the weight values based on the expected activity level in the sending layer.  A value of 1 in this parameter will make the weights increase more rapidly, as they are driven to a larger maximum value (equation 4.18 in text).  A value of 0 will result in smaller weight increases.  As described before, smaller values of savg_cor.cor are appropriate when we want the units to have more selective representations, while larger values are more appropriate for more general or categorical representations.  Thus, using a smaller value of this parameter should help to prevent units from developing less selective representations of multiple lines. This is why we have a default value of .5 for this parameter.

*  Switch to using a savg_cor.cor value of 1, and then Batch Run the network.

You should observe results very similar to those when you decreased wt_sig.off -- both of these manipulations reduce the level of correlation that is necessary to produce strong weights.

* Set savg_cor.cor back to .5, and then set rnd.mean to  .5.

This sets the initial random weight values to have a mean value of .5 instead of .25.  

* Batch run the network, and pay particular attention to the weights.

You should see that this ended up eliminating the loser units, so that every unit now codes for a line.  This result illustrates one of the interesting details about self-organizing learning.  In general, the CPCA rule causes weights to increase for those input units that are active, and decrease for those that are not.  However, this qualitative pattern is modulated by the soft weight bounding property discussed earlier --- larger weights increase less rapidly and decrease more rapidly, and vice versa for smaller weights.

When we start off with larger weight values, the amount of weight decrease will be large relative to the amount of increase.  Thus, hidden units that were active for a given pattern will subsequently receive ''less'' net input for a similar but not identical pattern (i.e., a pattern containing 1 of the 2 lines in common with the previous pattern), because the weights will have decreased substantially to those units that were off in the original pattern but on in the subsequent one.  This decreased probability of reactivation means that other, previously inactive units will be more likely to be activated, with the result that all of the units end up participating. This can sometimes be a useful effect if the network is not drawing in sufficient numbers of units, and just a few units are \"hogging\" all of the input patterns.

Finally, let's manipulate the learning rate parameter <code>lrate</code>.

* First, set rnd.mean back to .25, and then set lrate  to .1 instead of .01 and do a  Batch run.

<hr>

'''Question 4.8 (a)''' ''Does this tenfold increase in learning rate have any noticeable effect on the network, as measured by the unique pattern statistics and the weight patterns shown in the grid log?'' '''(b)''' ''Explain why this might be the case, comparing these results to the effects of learning rate that you observed in question 4.1.''

<hr>

This exercise should give you a feel for the dynamics that underly self-organizing learning, and also for the importance of contrast enhancement for the CPCA algorithm to be effective.  More generally, you should now appreciate the extent to which various parameters can provide appropriate (or not) a priori biases on the learning process, and the benefit (or harm) that this can produce.

* To continue on to the next simulation, close this project first by selecting <code>File->Close Project</code>. It's probably better to not save upon closing so you can sure the exercises will work when reopened. Or, if you wish to stop now, quit by then selecting <code>File->Quit</code> in the <code>.viewers[0](root) window.


</body>
</html>
";
   html_text="<html><head></head><body>
<h1> Self Organizing Learning </h1>
<p>
</p><ul><li> GENERAL USAGE NOTE: To start, it is usually a good idea to do <code>Object/Edit Dialog</code> in the menu just above this text, which will open this documentation in a separate window that you can more easily come back to.  Alternatively, you can just always return to this document by clicking on the <code>ProjectDocs</code> tab at the top of the middle  <b>Panels</b>  frame.
</li></ul>
We will continue with the \"lines\" theme in this exploration, by exposing a set of hidden units to an environment consisting of horizontal and vertical lines on a 5x5 input \"retina.\"
<p>
We focus first on the network.  The 5x5 input projects to a hidden layer of 20 units, which are all fully connected to the input with random initial weights.
</p><p>
</p><ul><li> As usual, select r.wt and view the initialized weights for these units by clicking on several hidden units (use red arrow).  You will see that the initial wts have been randomized to different values.
</li></ul>
Because viewing the pattern of weights over all the hidden units will be of primary concern as the network learns, we have a special grid view showing on the upper left of the network display, which displays the weights for all hidden units.  In addition, there is a graph view in the upper right, which will display key information as the network learns.
<p>
Let's see the environment the network will be experiencing.
</p><p>
</p><ul><li> Click the <a href=\"ta:.T3Tab.Lines_Input_Data\">Lines_Input_Data</a> tab in the right 3D view window.
</li></ul>
This will bring up a display showing the first 10 training items on the left, which are composed of the elemental horizontal and vertical lines shown in the grid view display on the right.  You can use the narrow vertical violet scrollbar for the left grid view to scroll through all 45 of the patterns (you may have to click the red arrow first to be able to grab the scrollbar).  These 45 input patterns represent all unique pairwise combinations of vertical and horizontal lines. Thus, there are no real correlations between the lines, with the only reliable correlations being between the pixels that make up a particular line. To put this another way, each line can be thought of as appearing in a number of different randomly related contexts (i.e., with other lines).
<p>
It should be clear that if we computed the correlations between individual pixels across all of these images, everything would be equally (weakly) correlated with everything else.  Thus, learning must be conditional on the particular type of line for any meaningful correlations to be extracted.  We will see that this conditionality will simply self-organize through the interactions of the learning rule and the kWTA inhibitory competition.  Note also that because two lines are present in every image, the network will require at least two active hidden units per input, assuming each unit is representing a particular line.  
</p><p>
</p><ul><li> Click back to the <a href=\"ta:.T3Tab.Network\">Network</a> display, and return to viewing act in the network window.  Then, hit <a href=\"ta:.programs.LeabraTrain.Init()\">Train: Init</a> (say Yes to initializing the weights) and <a href=\"ta:.programs.LeabraTrain.Step()\">Step</a> in the control panel, to present a  single pattern to the network.
</li></ul>
You should see one of the event patterns containing two lines in the input of the network, and a pattern of roughly two active hidden units.
<p>
The hidden layer is using the average-based kWTA inhibition function, with the k parameter set to 2 as you can see in the kwta.k parameter in the control panel.  This function allows for some variability of actual activation level depending on the actual distribution of excitation across units in the hidden layer.  Thus, when more than two units are active, these units are being fairly equally activated by the input pattern due to the random initial weights not being very selective.  This is an important effect, because these weaker additional activations may enable these units to bootstrap into stronger activations through gradual learning, should they end up being reliably active in conjunction with a particular input feature (i.e., a particular line in this case).
</p><p>
</p><ul><li> You can Step some more.  When you tire of single stepping, just press the (Train) <a href=\"ta:.programs.LeabraTrain.Run()\">Run</a>  button on the control panel.  You may want to turn off the Display in the network (in the network view panel, <a href=\"ta:.PanelTab.Network\">Network</a>).
</li></ul>
After 30  <i>epochs</i>  (passes through all 45 different events in the environment) of learning, the network will stop. You should have noticed that the grid weights view was updated as the training proceeded. This grid view display shows all of the network's weights (figure 4.13 in the textbook shows an example).  The larger-scale 5x4 grid is topographically arranged in the same layout as the Hidden layer of the network.  Within each of these 20 grid elements is a smaller 5x5 grid representing the input units, showing the weights for each unit.  By clicking on the hidden units in the network window with the r.wt variable selected, you should be able to verify this correspondence.
<p>
As training proceded, the weights came to more and more clearly reflect the lines present in the environment (figure 4.13).  Thus, individual units developed  <i>selective</i>  representations of the correlations present within individual lines, while ignoring the random context of the other lines.
</p><p>
These individual line representations developed as a result of the interaction between learning and inhibitory competition as follows. Early on, the units that won the inhibitory competition were those that happened to have larger random weights for the input pattern. CPCA learning then tuned these weights to be more selective for that input pattern, causing them to be more likely to respond to that pattern and others that overlap with it (i.e., other patterns sharing one of the two lines).  To the extent that the weights are stronger for one of the two lines in the input, the unit will be more likely to respond to inputs having this line, and thus the conditional probability for the input units in this line will be stronger than for the other units, and the weights will continue to increase.  This is where the contrast enhancement bias plays an important role, because it emphasizes the strongest of the unit's correlations and deemphasizes the weaker ones.  This will make it much more likely that the strongest correlation in the environment -- the single lines -- end up getting represented.
</p><p>
You might have noticed in the weights displayed in the grid view during learning that some units initially seemed to be becoming selective for multiple lines, but then as other units were better able to represent one of those lines, they started to lose that competition and fall back to representing only one line.  Thus, the dynamics of the inhibitory competition are critical for the self-organizing effect, and it should be clear that a firm inhibitory constraint is important for this kind of learning (otherwise units will just end up being active a lot, and representing a mish-mash of line features). Nevertheless, the average-based kWTA function is sufficiently flexible that it can allow more than two units to become active, so you will probably see that sometimes multiple hidden units end up encoding the same line feature.
</p><p>
The net result of this self-organizing learning is a nice  <i>combinatorial</i>  distributed representation, where each input pattern is represented as the combination of the two line features present therein.  This is the \"obvious\" way to represent such inputs, but you should appreciate that the network nevertheless had to discover this representation through the somewhat complex self-organizing learning procedure.  
</p><p>
</p><ul><li> To see this representation in action, turn the network Display back on, and Step through a few more events. (If you had previously let the network train to completion (30 epochs), you will have to increase the max_epoch paramenter to 31 in the ControlPanel to let you Step through a few more trials.)
</li></ul>
Notice that in general two or more units are strongly activated by each input pattern, with the extra activation reflecting the fact that some lines are coded by multiple units.
<p>
Another thing to notice in the weights shown in the grid view (figure 4.13 in text) is that some units are obviously not selective for anything.  These \"loser\" units (also known as \"dead\" units) were never reliably activated by any input feature, and thus did not experience much learning.  It is typically quite important to have such units lying around, because self-organization requires some \"elbow room\" during learning to sort out the allocation of units to stable correlational features.  Having more hidden units also increases the chances of having a large enough range of initial random selectivities to seed the self-organization process.  The consequence is that you need to have more units than is minimally necessary, and that you will often end up with leftovers (plus the redundant units mentioned previously).
</p><p>
From a biological perspective, we know that the cortex does not produce a lot of new cortical neurons in adults, so we conclude that in general there is probably an excess of neural capacity relative to the demands of any given learning context.  Thus, it is useful to have these leftover and redundant units, because they constitute a \"reserve\" that could presumably get activated if new features were later presented to the network (e.g., diagonal lines).  We are much more suspicious of algorithms that require precisely tuned quantities of hidden units to work properly (more on this later).
</p><p>
</p><h2> Unique Pattern Statistic </h2>
<p>
Although looking at the weights is informative, we could use a more concise measure of how well the network's internal model matches the underlying structure of the environment.  We one such measure is plotted in the graph view as the network learns.
</p><p>
This log shows the results of the  <b>unique pattern statistic</b>  (shown as uniq_pats in the graph), which records the number of unique hidden unit activity patterns that were produced as a result of probing the network with all 10 different types of horizontal and vertical lines (presented individually).  Thus, there is a separate testing process which, after each epoch of learning, tests the network on all 10 lines, records the resulting hidden unit activity patterns (with the kWTA parameter set to 1, though this is not critical due to the flexibility of the average-based kWTA function), and then counts up the number of unique such patterns (subject to thresholding so we only care about binary patterns of activity).
</p><p>
<em> <b>Software Hint:</b>  You can view a \"close-up\" of just the graph itself by clicking on the small tab labeled \"Graph\" at the bottom of the far right window. </em>
</p><p>
The logic behind this measure is that if each line is encoded by (at least) one distinct hidden unit, then this will show up as a unique pattern.  If, however, there are units that encode two or more lines together (which is not a good model of this environment), then this will not result in a unique representation for these lines, and the resulting measure will be lower.  Thus, to the extent that this statistic is less than 10, the internal model produced by the network does not fully capture the underlying independence of each line from the other lines.  Note, however, that the unique pattern statistic does not care if  <i>multiple</i>  hidden units encode the same line (i.e., if there is redundancy across different hidden units) -- it only cares that the  <i>same</i>  hidden unit not encode  <i>two different</i>  lines.
</p><p>
You should have seen on this run that the model produced a perfect internal model according to this statistic, which accords well with our analysis of the weight patterns.  To get a better sense of how well the network learns in general, you can run a  <i>batch</i>  of 8 training runs starting with a different set of random initial weights
each time.
</p><p>
</p><ul><li> Press Batch Init and Batch Run in the control panel to run.  You probably want to turn off the network Display again.  When it is done, you can click on the <a href=\"ta:.T3Tab.BatchOutputData\">BatchOutputData</a> tab to view the results.
</li></ul>
After the 8 training runs, the batch view shows summary statistics about the average (mean), maximum, and minimum of the unique pattern statistic at the end of each network training run.  The last column contains a count of the number of times that a \"perfect 10\" on the unique pattern statistic was recorded.  You should get a perfect score for all 8 runs.
<p>
</p><h2> Parameter Manipulations </h2>
<p>
Now, let's explore the effects of some of the parameters in the control panel.  First, let's manipulate the wt_sig.gain parameter, which should affect the contrast (and therefore selectivity) of the unit's weights.
</p><p>
</p><ul><li> Set wt_sig.gain to 1 instead of 6, Apply, and Batch Init, Run the network.
</li></ul>
<hr>
<p>
 <b>Question 4.6 (a)</b>   <i>What statistics for the number of uniquely represented lines did you obtain?</i>   <b>(b)</b>   <i>In what ways were the final weight patterns shown in the weight grid log different from the default case?</i>   <b>(c)</b>   <i>Explain how these two findings of hidden unit activity and weight patterns are related, making specific reference to the role of selectivity in self-organizing learning.</i> 
</p><p>
</p><hr>
<p>
</p><ul><li> Set wt_sig.gain back to 6, change wt_sig.off from 1.25 to 1, Apply, and run a Batch.  To make the effects of this parameter more dramatic, lower wt_sig.off to .75 and Batch again.
</li></ul>
<p>
<em> <b>Hint:</b>  If the EpochOutputData Grid and Graph do not display after training, click on the corresponding tabs at the bottom of the <a href=\"ta:.T3Tab.Network\">Network</a> tab (middle frame), and click on the <code>Refresh</code> button at the top right corner.
</em></p><em><p>
</p><hr>
<p>
 <b>Question 4.7 (a)</b>   <i>What statistics did you obtain for these two cases (1 and .75)?</i>   <b>(b)</b>   <i>Was there a noticeable change in the weight patterns compared to the default case? (Hint: Consider what the unique pattern   statistic is looking for).</i>   <b>(c)</b>   <i>Explain these results in terms of the effects of wt_sig.off as adjusting the threshold for where correlations are enhanced or decreased as a function of the wt_sig.gain contrast enhancement mechanism.</i>   <b>(d)</b>   <i>Again, explain why this is important for self-organizing learning.</i> 
</p><p>
</p><hr>
<p>
</p><ul><li> Set wt_sig.off back to 1.25 (or hit Defaults).
</li></ul>
Now, let's consider the savg_cor.cor parameter, which controls the amount of renormalization of the weight values based on the expected activity level in the sending layer.  A value of 1 in this parameter will make the weights increase more rapidly, as they are driven to a larger maximum value (equation 4.18 in text).  A value of 0 will result in smaller weight increases.  As described before, smaller values of savg_cor.cor are appropriate when we want the units to have more selective representations, while larger values are more appropriate for more general or categorical representations.  Thus, using a smaller value of this parameter should help to prevent units from developing less selective representations of multiple lines. This is why we have a default value of .5 for this parameter.
<p>
</p><ul><li>  Switch to using a savg_cor.cor value of 1, and then Batch Run the network.
</li></ul>
You should observe results very similar to those when you decreased wt_sig.off -- both of these manipulations reduce the level of correlation that is necessary to produce strong weights.
<p>
</p><ul><li> Set savg_cor.cor back to .5, and then set rnd.mean to  .5.
</li></ul>
This sets the initial random weight values to have a mean value of .5 instead of .25.  
<p>
</p><ul><li> Batch run the network, and pay particular attention to the weights.
</li></ul>
You should see that this ended up eliminating the loser units, so that every unit now codes for a line.  This result illustrates one of the interesting details about self-organizing learning.  In general, the CPCA rule causes weights to increase for those input units that are active, and decrease for those that are not.  However, this qualitative pattern is modulated by the soft weight bounding property discussed earlier --- larger weights increase less rapidly and decrease more rapidly, and vice versa for smaller weights.
<p>
When we start off with larger weight values, the amount of weight decrease will be large relative to the amount of increase.  Thus, hidden units that were active for a given pattern will subsequently receive  <i>less</i>  net input for a similar but not identical pattern (i.e., a pattern containing 1 of the 2 lines in common with the previous pattern), because the weights will have decreased substantially to those units that were off in the original pattern but on in the subsequent one.  This decreased probability of reactivation means that other, previously inactive units will be more likely to be activated, with the result that all of the units end up participating. This can sometimes be a useful effect if the network is not drawing in sufficient numbers of units, and just a few units are \"hogging\" all of the input patterns.
</p><p>
Finally, let's manipulate the learning rate parameter <code>lrate</code>.
</p><p>
</p><ul><li> First, set rnd.mean back to .25, and then set lrate  to .1 instead of .01 and do a  Batch run.
</li></ul>
<hr>
<p>
 <b>Question 4.8 (a)</b>   <i>Does this tenfold increase in learning rate have any noticeable effect on the network, as measured by the unique pattern statistics and the weight patterns shown in the grid log?</i>   <b>(b)</b>   <i>Explain why this might be the case, comparing these results to the effects of learning rate that you observed in question 4.1.</i> 
</p><p>
</p><hr>
<p>
This exercise should give you a feel for the dynamics that underly self-organizing learning, and also for the importance of contrast enhancement for the CPCA algorithm to be effective.  More generally, you should now appreciate the extent to which various parameters can provide appropriate (or not) a priori biases on the learning process, and the benefit (or harm) that this can produce.
</p><p>
</p><ul><li> To continue on to the next simulation, close this project first by selecting <code>File-&gt;Close Project</code>. It's probably better to not save upon closing so you can sure the exercises will work when reopened. Or, if you wish to stop now, quit by then selecting <code>File-&gt;Quit</code> in the <code>.viewers[0](root) window.
</code></li></ul><code>
<p>


</p></code></em></body></html>";
  };
  taDoc @[1] {
   name="WikiDoc";
   desc=;
   auto_open=0;
   web_doc=1;
   wiki="CCN";
   url="CECN1_Self_Organizing";
   full_url="http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Self_Organizing";
   text_size=1;
   text="<html>
<head></head>
<body>
== Enter Title Here ==
</body>
</html>
";
   html_text="<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\" dir=\"ltr\"><head>
		<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">
		<meta http-equiv=\"Content-Style-Type\" content=\"text/css\">
		<meta name=\"generator\" content=\"MediaWiki 1.16alpha-wmf\">
		<meta name=\"keywords\" content=\"CECN1 Self Organizing,CECN1 Projects,Emergent,.T3Tab.Lines Input Data,.T3Tab.Network,.programs.LeabraTrain.Init(),.programs.LeabraTrain.Step(),.programs.LeabraTrain.Run(),.PanelTab.Network,.T3Tab.BatchOutputData\">
		<link rel=\"shortcut icon\" href=\"/emergent/favicon.ico\">
		<link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/CompCogNeuro/opensearch_desc.php\" title=\"Computational Cognitive Neuroscience Wiki (en)\">
		<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Computational Cognitive Neuroscience Wiki RSS Feed\" href=\"/CompCogNeuro/index.php?title=Special:RecentChanges&amp;feed=rss\">
		<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Computational Cognitive Neuroscience Wiki Atom Feed\" href=\"/CompCogNeuro/index.php?title=Special:RecentChanges&amp;feed=atom\">
		<title>CECN1 Self Organizing - Computational Cognitive Neuroscience Wiki</title>
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/common/shared.css?233z\" type=\"text/css\" media=\"screen\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/common/commonPrint.css?233z\" type=\"text/css\" media=\"print\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/main.css?233z\" type=\"text/css\" media=\"screen\">
		<!--[if lt IE 5.5000]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE50Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 5.5000]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE55Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 6]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE60Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<!--[if IE 7]><link rel=\"stylesheet\" href=\"/CompCogNeuro/skins/monobook/IE70Fixes.css?233z\" type=\"text/css\" media=\"screen\" /><![endif]-->
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\" media=\"print\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=MediaWiki:monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000\" type=\"text/css\">
		<link rel=\"stylesheet\" href=\"/CompCogNeuro/index.php?title=-&amp;action=raw&amp;maxage=18000&amp;gen=css\" type=\"text/css\">
		<!--[if lt IE 7]><script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/IEFixes.js?233z\"></script>
		<meta http-equiv=\"imagetoolbar\" content=\"no\" /><![endif]-->

		<script type=\"text/javascript\">/*<![CDATA[*/
		var skin = \"monobook\";
		var stylepath = \"/CompCogNeuro/skins\";
		var wgArticlePath = \"/CompCogNeuro/index.php/$1\";
		var wgScriptPath = \"/CompCogNeuro\";
		var wgScript = \"/CompCogNeuro/index.php\";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = \"http://grey.colorado.edu\";
		var wgCanonicalNamespace = \"\";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = \"CECN1_Self_Organizing\";
		var wgTitle = \"CECN1 Self Organizing\";
		var wgAction = \"view\";
		var wgArticleId = \"26\";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = \"en\";
		var wgContentLanguage = \"en\";
		var wgBreakFrames = false;
		var wgCurRevisionId = 51;
		var wgVersion = \"1.16alpha-wmf\";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = [\"\", \"\"];
		var wgDigitTransformTable = [\"\", \"\"];
		var wgMainPageTitle = \"Main Page\";
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		var wgFCKEditorDir = \"extensions/FCKeditor/fckeditor/\";
		var wgFCKEditorExtDir = \"extensions/FCKeditor\";
		var wgFCKEditorToolbarSet = \"Wiki\";
		var wgFCKEditorHeight = \"0\";
		/*]]>*/</script>

		<script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/wikibits.js?233z\"><!-- wikibits js --></script><style type=\"text/css\">@import \"/CompCogNeuro/skins/monobook/KHTMLFixes.css\";</style>
		<!-- Head Scripts -->
		<script type=\"text/javascript\" src=\"/CompCogNeuro/skins/common/ajax.js?233z\"></script>
		<script type=\"text/javascript\" src=\"/CompCogNeuro/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook\"><!-- site js --></script>
	<style type=\"text/css\">@import \"/CompCogNeuro/extensions/Collection/collection/Gadget-navpop.css?2\";</style></head><body class=\"mediawiki ltr ns-0 ns-subject page-CECN1_Self_Organizing skin-monobook\">
	<div id=\"globalWrapper\">
		<div id=\"column-content\">
	<div id=\"content\">
		<a name=\"top\" id=\"top\"></a>
				<h1 id=\"firstHeading\" class=\"firstHeading\">CECN1 Self Organizing</h1>
		<div id=\"bodyContent\">
			<h3 id=\"siteSub\">From Computational Cognitive Neuroscience Wiki</h3>
			<div id=\"contentSub\"></div>
									<div id=\"jump-to-nav\">Jump to: <a href=\"#column-one\">navigation</a>, <a href=\"#searchInput\">search</a></div>			<!-- start content -->
			<table id=\"toc\" class=\"toc\" summary=\"Contents\"><tbody><tr><td><div id=\"toctitle\"><h2>Contents</h2> <span class=\"toctoggle\">[<a id=\"togglelink\" class=\"internal\" href=\"javascript:toggleToc()\">hide</a>]</span></div>
<ul>
<li class=\"toclevel-1\"><a href=\"#Self-Organizing_Learning\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Self-Organizing Learning</span></a></li>
<li class=\"toclevel-1\"><a href=\"#Project_Documentation\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Project Documentation</span></a>
<ul>
<li class=\"toclevel-2\"><a href=\"#Unique_Pattern_Statistic\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Unique Pattern Statistic</span></a></li>
<li class=\"toclevel-2\"><a href=\"#Parameter_Manipulations\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Parameter Manipulations</span></a></li>
</ul>
</li>
</ul>
</td></tr></tbody></table><script type=\"text/javascript\"> if (window.showTocToggle) { var tocShowText = \"show\"; var tocHideText = \"hide\"; showTocToggle(); } </script>
<a name=\"Self-Organizing_Learning\" id=\"Self-Organizing_Learning\"></a><h1> <span class=\"mw-headline\"> Self-Organizing Learning </span></h1>
<ul><li> The project file: <a href=\"/mediawiki/sites/CompCogNeuro/images/7/7d/self_org.proj\" class=\"internal\" title=\"self org.proj\">self_org.proj</a> (click and Save As to download, then open in <a href=\"/CompCogNeuro/index.php/Emergent\" title=\"Emergent\">Emergent</a>)
</li></ul>
<p>Back to <a href=\"/CompCogNeuro/index.php/CECN1_Projects\" title=\"CECN1 Projects\">CECN1 Projects</a>
</p>
<a name=\"Project_Documentation\" id=\"Project_Documentation\"></a><h1> <span class=\"mw-headline\"> Project Documentation </span></h1>
<p>(note: this is a literal copy from the simulation documentation -- it contains links that will not work within the wiki)
</p><p>We will continue with the \"lines\" theme in this exploration, by exposing a set of hidden units to an environment consisting of horizontal and vertical lines on a 5x5 input \"retina.\"
</p><p>We focus first on the network.  The 5x5 input projects to a hidden layer of 20 units, which are all fully connected to the input with random initial weights.
</p>
<ul><li> As usual, select r.wt and view the weights for these units.
</li></ul>
<p>Because viewing the pattern of weights over all the hidden units will be of primary concern as the network learns, we have a special grid view showing on the upper left of the network display, which displays the weights for all hidden units.  In addition, there is a graph view in the upper right, which will display key information as the network learns.
</p><p>Let's see the environment the network will be experiencing.
</p>
<ul><li> Click the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.Lines_Input_Data&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.Lines Input Data (page does not exist)\">.T3Tab.Lines_Input_Data</a> tab in the right 3D view window.
</li></ul>
<p>This will bring up a display showing the first 10 training items on the left, which are composed of the elemental horizontal and vertical lines shown in the grid view display on the right.  You can use the narrow violet scrollbar for the left grid view to scroll through all 45 of the patterns (you have to click the red arrow first to be able to grab the scrollbar).  These 45 input patterns represent all unique pairwise combinations of vertical and horizontal lines. Thus, there are no real correlations between the lines, with the only reliable correlations being between the pixels that make up a particular line. To put this another way, each line can be thought of as appearing in a number of different randomly related contexts (i.e., with other lines).
</p><p>It should be clear that if we computed the correlations between individual pixels across all of these images, everything would be equally (weakly) correlated with everything else.  Thus, learning must be conditional on the particular type of line for any meaningful correlations to be extracted.  We will see that this conditionality will simply self-organize through the interactions of the learning rule and the kWTA inhibitory competition.  Note also that because two lines are present in every image, the network will require at least two active hidden units per input, assuming each unit is representing a particular line.  
</p>
<ul><li> Click back to the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.Network&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.Network (page does not exist)\">.T3Tab.Network</a> display, and return to viewing act in the network window.  Then, hit <a href=\"/CompCogNeuro/index.php?title=.programs.LeabraTrain.Init()&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".programs.LeabraTrain.Init() (page does not exist)\">Init</a> (say Yes to initializing the weights) and <a href=\"/CompCogNeuro/index.php?title=.programs.LeabraTrain.Step()&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".programs.LeabraTrain.Step() (page does not exist)\">Step</a> in the control panel, to present a  single pattern to the network.
</li></ul>
<p>You should see one of the event patterns containing two lines in the input of the network, and a pattern of roughly two active hidden units.
</p><p>The hidden layer is using the average-based kWTA inhibition function, with the k parameter set to 2 as you can see in the kwta.k parameter in the control panel.  This function allows for some variability of actual activation level depending on the actual distribution of excitation across units in the hidden layer.  Thus, when more than two units are active, these units are being fairly equally activated by the input pattern due to the random initial weights not being very selective.  This is an important effect, because these weaker additional activations may enable these units to bootstrap into stronger activations through gradual learning, should they end up being reliably active in conjunction with a particular input feature (i.e., a particular line in this case).
</p>
<ul><li> You can Step some more.  When you tire of single stepping, just press the <a href=\"/CompCogNeuro/index.php?title=.programs.LeabraTrain.Run()&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".programs.LeabraTrain.Run() (page does not exist)\">Run</a>  button on the control panel.  You may want to turn off the Display in the network (in the network view panel, <a href=\"/CompCogNeuro/index.php?title=.PanelTab.Network&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".PanelTab.Network (page does not exist)\">.PanelTab.Network</a>).
</li></ul>
<p>After 30 <i>epochs</i> (passes through all 45 different events in the environment) of learning, the network will stop. You should have noticed that the grid weights view was updated as the training proceeded. This grid view display shows all of the network's weights (figure 4.13 in the textbook shows an example).  The larger-scale 5x4 grid is topographically arranged in the same layout as the network.  Within each of these 20 grid elements is a smaller 5x5 grid representing the input units, showing the weights for each unit.  By clicking on the hidden units in the network window with the r.wt variable selected, you should be able to verify this correspondence.
</p><p>As training proceded, the weights came to more and more clearly reflect the lines present in the environment (figure 4.13).  Thus, individual units developed <i>selective</i> representations of the correlations present within individual lines, while ignoring the random context of the other lines.
</p><p>These individual line representations developed as a result of the interaction between learning and inhibitory competition as follows. Early on, the units that won the inhibitory competition were those that happened to have larger random weights for the input pattern. CPCA learning then tuned these weights to be more selective for that input pattern, causing them to be more likely to respond to that pattern and others that overlap with it (i.e., other patterns sharing one of the two lines).  To the extent that the weights are stronger for one of the two lines in the input, the unit will be more likely to respond to inputs having this line, and thus the conditional probability for the input units in this line will be stronger than for the other units, and the weights will continue to increase.  This is where the contrast enhancement bias plays an important role, because it emphasizes the strongest of the unit's correlations and deemphasizes the weaker ones.  This will make it much more likely that the strongest correlation in the environment -- the single lines -- end up getting represented.
</p><p>You might have noticed in the weights displayed in the grid view during learning that some units initially seemed to be becoming selective for multiple lines, but then as other units were better able to represent one of those lines, they started to lose that competition and fall back to representing only one line.  Thus, the dynamics of the inhibitory competition are critical for the self-organizing effect, and it should be clear that a firm inhibitory constraint is important for this kind of learning (otherwise units will just end up being active a lot, and representing a mish-mash of line features). Nevertheless, the average-based kWTA function is sufficiently flexible that it can allow more than two units to become active, so you will probably see that sometimes multiple hidden units end up encoding the same line feature.
</p><p>The net result of this self-organizing learning is a nice <i>combinatorial</i> distributed representation, where each input pattern is represented as the combination of the two line features present therein.  This is the \"obvious\" way to represent such inputs, but you should appreciate that the network nevertheless had to discover this representation through the somewhat complex self-organizing learning procedure.  
</p>
<ul><li> To see this representation in action, turn the network Display back on, and Step through a few more events.
</li></ul>
<p>Notice that in general two or more units are strongly activated by each input pattern, with the extra activation reflecting the fact that some lines are coded by multiple units.
</p><p>Another thing to notice in the weights shown in the grid view (figure 4.13) is that some units are obviously not
selective for anything.  These \"loser\" units (also known as \"dead\" units) were never reliably activated by any input feature, and thus did not experience much learning.  It is typically quite important to have such units lying around, because self-organization requires some \"elbow room\" during learning to sort out the allocation of units to stable correlational features.  Having more hidden units also increases the chances of having a large enough range of initial random selectivities to seed the self-organization process.  The consequence is that you need to have more units than is minimally necessary, and that you will often end up with leftovers (plus the redundant units mentioned previously).
</p><p>From a biological perspective, we know that the cortex does not produce new neurons in adults, so we conclude that in general there is probably an excess of neural capacity relative to the demands of any given learning context.  Thus, it is useful to have these leftover and redundant units, because they constitute a \"reserve\" that could presumably get activated if new features were later presented to the network (e.g., diagonal lines).  We are much more suspicious of algorithms that require precisely tuned quantities of hidden units to work properly (more on this later).
</p>
<a name=\"Unique_Pattern_Statistic\" id=\"Unique_Pattern_Statistic\"></a><h2> <span class=\"mw-headline\"> Unique Pattern Statistic </span></h2>
<p>Although looking at the weights is informative, we could use a more concise measure of how well the network's internal model matches the underlying structure of the environment.  We one such measure is plotted in the graph view as the network learns.
</p><p>This log shows the results of the <b>unique pattern statistic</b>, shown as uniq_pats in the graph), which records the number of unique hidden unit activity patterns that were produced as a result of probing the network with all 10 different types of horizontal and vertical lines (presented individually).  Thus, there is a separate testing process which, after each epoch of learning, tests the network on all 10 lines, records the resulting hidden unit activity patterns (with the kWTA parameter set to 1, though this is not critical due to the flexibility of the average-based kWTA function), and then counts up the number of unique such patterns (subject to thresholding so we only care about binary patterns of activity).
</p><p>The logic behind this measure is that if each line is encoded by (at least) one distinct hidden unit, then this will show up as a unique pattern.  If, however, there are units that encode two or more lines together (which is not a good model of this environment), then this will not result in a unique representation for these lines, and the resulting measure will be lower.  Thus, to the extent that this statistic is less than 10, the internal model produced by the network does not fully capture the underlying independence of each line from the other lines.  Note, however, that the unique pattern statistic does not care if <i>multiple</i> hidden units encode the same line (i.e., if there is redundancy across different hidden units) -- it only cares that the <i>same</i> hidden unit not encode <i>two different</i> lines.
</p><p>You should have seen on this run that the model produced a perfect internal model according to this statistic, which accords well with our analysis of the weight patterns.  To get a better sense of how well the network learns in general, you can run a <i>batch</i> of 8 training runs starting with a different set of random initial weights
each time.
</p>
<ul><li> Press Batch Init and Batch Run in the control panel to run.  You probably want to turn off the network Display again.  When it is done, you can click on the <a href=\"/CompCogNeuro/index.php?title=.T3Tab.BatchOutputData&amp;action=edit&amp;redlink=1\" class=\"new\" title=\".T3Tab.BatchOutputData (page does not exist)\">.T3Tab.BatchOutputData</a> tab to view the results.
</li></ul>
<p>After the 8 training runs, the batch view shows summary statistics about the average (mean), maximum, and minimum of the unique pattern statistic at the end of each network training run.  The last column contains a count of the number of times that a \"perfect 10\" on the unique pattern statistic was recorded.  You should get a perfect score for all 8 runs.
</p>
<a name=\"Parameter_Manipulations\" id=\"Parameter_Manipulations\"></a><h2> <span class=\"mw-headline\"> Parameter Manipulations </span></h2>
<p>Now, let's explore the effects of some of the parameters in the control panel.  First, let's manipulate the wt_sig.gain parameter, which should affect the contrast (and therefore selectivity) of the unit's weights.
</p>
<ul><li> Set wt_sig.gain to 1 instead of 6, Apply, and Batch Init, Run the network.
</li></ul>
<hr>
<p><b>Question 4.6 (a)</b> <i>What statistics for the number of uniquely represented lines did you obtain?</i> <b>(b)</b> <i>In what ways were the final weight patterns shown in the weight grid log different from the default case?</i> <b>(c)</b> <i>Explain how these two findings of hidden unit activity and weight patterns are related, making specific reference to the role of selectivity in self-organizing learning.</i>
</p>
<hr>
<ul><li> Set wt_sig.gain back to 6, change wt_sig.off from 1.25 to 1, Apply, and run a Batch.  To make the effects of this parameter more dramatic, lower wt_sig.off to .75 and Batch again.
</li></ul>
<hr>
<p><b>Question 4.7 (a)</b> <i>What statistics did you obtain for these two cases (1 and .75)?</i> <b>(b)</b> <i>Was there a noticeable change in the weight patterns compared to the default case? (Hint: Consider what the unique pattern   statistic is looking for).</i> <b>(c)</b> <i>Explain these results in terms of the effects of wt_sig.off as adjusting the threshold for where correlations are enhanced or decreased as a function of the wt_sig.gain contrast enhancement mechanism.</i> <b>(d)</b> <i>Again, explain why this is important for self-organizing learning.</i>
</p>
<hr>
<ul><li> Set wt_sig.off back to 1.25 (or hit Defaults).
</li></ul>
<p>Now, let's consider the savg_cor.cor parameter, which controls the amount of renormalization of the weight values based on the expected activity level in the sending layer.  A value of 1 in this parameter will make the weights increase more rapidly, as they are driven to a larger maximum value (equation 4.18).  A value of 0 will result in smaller weight increases.  As described before, smaller values of savg_cor.cor are appropriate when we want the units to have more selective representations, while larger values are more appropriate for more general or categorical representations.  Thus, using a smaller value of this parameter should help to prevent units from developing less selective representations of multiple lines. This is why we have a default value of .5 for this parameter.
</p>
<ul><li>  Switch to using a savg_cor.cor value of 1, and then Batch Run the network.
</li></ul>
<p>You should observe results very similar to those when you decreased wt_sig.off -- both of these manipulations reduce the level of correlation that is necessary to produce strong weights.
</p>
<ul><li> Set savg_cor.cor back to .5, and then set rnd.mean to  .5.
</li></ul>
<p>This sets the initial random weight values to have a mean value of .5 instead of .25.  
</p>
<ul><li> Batch run the network, and pay particular attention to the weights.} 
</li></ul>
<p>You should see that this ended up eliminating the loser units, so that every unit now codes for a line.  This result illustrates one of the interesting details about self-organizing learning.  In general, the CPCA rule causes weights to increase for those input units that are active, and decrease for those that are not.  However, this qualitative pattern is modulated by the soft weight bounding property discussed earlier --- larger weights increase less rapidly and decrease more rapidly, and vice versa for smaller weights.
</p><p>When we start off with larger weight values, the amount of weight decrease will be large relative to the amount of increase.  Thus, hidden units that were active for a given pattern will subsequently receive <i>less</i> net input for a similar but not identical pattern (i.e., a pattern containing 1 of the 2 lines in common with the previous pattern), because the weights will have decreased substantially to those units that were off in the original pattern but on in the subsequent one.  This decreased probability of reactivation means that other, previously inactive units will be more likely to be activated, with the result that all of the units end up participating. This can sometimes be a useful effect if the network is not drawing in sufficient numbers of units, and just a few units are \"hogging\" all of the input patterns.
</p><p>Finally, let's manipulate the learning rate parameter \\verb\\lrate\\.
</p>
<ul><li> First, set rnd.mean back to .25, and then set lrate  to .1 instead of .01 and do a  Batch run.
</li></ul>
<hr>
<p><b>Question 4.8 (a)</b> <i>Does this tenfold increase in learning rate have any noticeable effect on the network, as measured by the unique pattern statistics and the weight patterns shown in the grid log?</i> <b>(b)</b> <i>Explain why this might be the case, comparing these results to the effects of learning rate that you observed in question 4.1.</i>
</p>
<hr>
<p>This exercise should give you a feel for the dynamics that underly self-organizing learning, and also for the importance of contrast enhancement for the CPCA algorithm to be effective.  More generally, you should now appreciate the extent to which various parameters can provide appropriate (or not) a priori biases on the learning process, and the benefit (or harm) that this can produce.
</p>
<!-- 
NewPP limit report
Preprocessor node count: 5/1000000
Post-expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key compcogneuro:pcache:idhash:26-0!1!0!!en!2!edit=0 and timestamp 20090904082947 -->
<div class=\"printfooter\">
Retrieved from \"<a href=\"http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Self_Organizing\">http://grey.colorado.edu/CompCogNeuro/index.php/CECN1_Self_Organizing</a>\"</div>
						<!-- end content -->
						<div class=\"visualClear\"></div>
		</div>
	</div>
		</div>
		<div id=\"column-one\">
	<div id=\"p-cactions\" class=\"portlet\">
		<h5>Views</h5>
		<div class=\"pBody\">
			<ul lang=\"en\" xml:lang=\"en\">
	
				 <li id=\"ca-nstab-main\" class=\"selected\"><a href=\"/CompCogNeuro/index.php/CECN1_Self_Organizing\" title=\"View the content page [ctrl-alt-c]\" accesskey=\"c\">Page</a></li>
				 <li id=\"ca-talk\" class=\"new\"><a href=\"/CompCogNeuro/index.php?title=Talk:CECN1_Self_Organizing&amp;action=edit&amp;redlink=1\" title=\"Discussion about the content page [ctrl-alt-t]\" accesskey=\"t\">Discussion</a></li>
				 <li id=\"ca-viewsource\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Self_Organizing&amp;action=edit\" title=\"This page is protected.
You can view its source [ctrl-alt-e]\" accesskey=\"e\">View source</a></li>
				 <li id=\"ca-history\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Self_Organizing&amp;action=history\" title=\"Past revisions of this page [ctrl-alt-h]\" accesskey=\"h\">History</a></li>			</ul>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-personal\">
		<h5>Personal tools</h5>
		<div class=\"pBody\">
			<ul lang=\"en\" xml:lang=\"en\">
				<li id=\"pt-login\"><a href=\"/CompCogNeuro/index.php?title=Special:UserLogin&amp;returnto=CECN1_Self_Organizing\" title=\"You are encouraged to log in; however, it is not mandatory [ctrl-alt-o]\" accesskey=\"o\">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-logo\">
		<a style=\"background-image: url(/mediawiki/sites//CompCogNeuro/logo.png);\" href=\"/CompCogNeuro/index.php/Main_Page\" title=\"Visit the main page [ctrl-alt-z]\" accesskey=\"z\"></a>
	</div>
	<script type=\"text/javascript\"> if (window.isMSIE55) fixalpha(); </script>
	<div class=\"generated-sidebar portlet\" id=\"p-navigation\">
		<h5 lang=\"en\" xml:lang=\"en\">Navigation</h5>
		<div class=\"pBody\">
			<ul>
				<li id=\"n-mainpage-description\"><a href=\"/CompCogNeuro/index.php/Main_Page\">Main Page</a></li>
				<li id=\"n-portal\"><a href=\"/CompCogNeuro/index.php/Project:Community_Portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li>
				<li id=\"n-currentevents\"><a href=\"/CompCogNeuro/index.php/Project:Current_events\" title=\"Find background information on current events\">Current events</a></li>
				<li id=\"n-recentchanges\"><a href=\"/CompCogNeuro/index.php/Special:RecentChanges\" title=\"The list of recent changes in the wiki [ctrl-alt-r]\" accesskey=\"r\">Recent changes</a></li>
				<li id=\"n-randompage\"><a href=\"/CompCogNeuro/index.php/Special:Random\" title=\"Load a random page [ctrl-alt-x]\" accesskey=\"x\">Random page</a></li>
				<li id=\"n-help\"><a href=\"/CompCogNeuro/index.php/Help:Contents\" title=\"The place to find out\">Help</a></li>
			</ul>
		</div>
	</div>
	<div id=\"p-search\" class=\"portlet\">
		<h5 lang=\"en\" xml:lang=\"en\"><label for=\"searchInput\">Search</label></h5>
		<div id=\"searchBody\" class=\"pBody\">
			<form action=\"/CompCogNeuro/index.php\" id=\"searchform\"><div>
				<input type=\"hidden\" name=\"title\" value=\"Special:Search\">
				<input id=\"searchInput\" name=\"search\" type=\"text\" title=\"Search Computational Cognitive Neuroscience Wiki [ctrl-alt-f]\" accesskey=\"f\" value=\"\">
				<input type=\"submit\" name=\"go\" class=\"searchButton\" id=\"searchGoButton\" value=\"Go\" title=\"Go to a page with this exact name if exists\">&nbsp;
				<input type=\"submit\" name=\"fulltext\" class=\"searchButton\" id=\"mw-searchButton\" value=\"Search\" title=\"Search the pages for this text\">
			</div></form>
		</div>
	</div>
	<div class=\"portlet\" id=\"p-tb\">
		<h5 lang=\"en\" xml:lang=\"en\">Toolbox</h5>
		<div class=\"pBody\">
			<ul>
				<li id=\"t-whatlinkshere\"><a href=\"/CompCogNeuro/index.php/Special:WhatLinksHere/CECN1_Self_Organizing\" title=\"List of all wiki pages that link here [ctrl-alt-j]\" accesskey=\"j\">What links here</a></li>
				<li id=\"t-recentchangeslinked\"><a href=\"/CompCogNeuro/index.php/Special:RecentChangesLinked/CECN1_Self_Organizing\" title=\"Recent changes in pages linked from this page [ctrl-alt-k]\" accesskey=\"k\">Related changes</a></li>
<li id=\"t-upload\"><a href=\"/CompCogNeuro/index.php/Special:Upload\" title=\"Upload files [ctrl-alt-u]\" accesskey=\"u\">Upload file</a></li>
<li id=\"t-specialpages\"><a href=\"/CompCogNeuro/index.php/Special:SpecialPages\" title=\"List of all special pages [ctrl-alt-q]\" accesskey=\"q\">Special pages</a></li>
				<li id=\"t-print\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Self_Organizing&amp;printable=yes\" rel=\"alternate\" title=\"Printable version of this page [ctrl-alt-p]\" accesskey=\"p\">Printable version</a></li>				<li id=\"t-permalink\"><a href=\"/CompCogNeuro/index.php?title=CECN1_Self_Organizing&amp;oldid=51\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-download-as-pdf\"><a href=\"/CompCogNeuro/index.php?title=Special:Book/render_article/&amp;arttitle=CECN1+Self+Organizing&amp;oldid=51&amp;writer=rl\" rel=\"nofollow\">PDF version</a></li>			</ul>
		</div>
	</div>
	<div class=\"generated-sidebar portlet\" id=\"p-coll-create_a_book\">
		<h5 lang=\"en\" xml:lang=\"en\">Create a book</h5>
		<div class=\"pBody\">
<ul id=\"collectionPortletList\"><li id=\"coll-add_page\"><a href=\"/CompCogNeuro/index.php?title=Special:Book/add_article/&amp;arttitle=CECN1+Self+Organizing&amp;oldid=0\" title=\"Add the current wiki page to your book\" onclick=\"collectionCall('AddArticle', ['removepage', wgNamespaceNumber, wgTitle, 0]); return false;\" rel=\"nofollow\">Add page to book</a></li><li id=\"coll-help_collections\"><a href=\"/CompCogNeuro/index.php/Help:Books\" title=\"Show help about the book tool\">Books help</a></li></ul><script type=\"text/javascript\">/*<![CDATA[*/
		var wgCollectionAddRemoveSate = \"addpage\";
		/*]]>*/</script>
<script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/portlet.js?2\"></script><script type=\"text/javascript\">/*<![CDATA[*/
		var wgCollectionNavPopupJSURL = \"/CompCogNeuro/extensions/Collection/collection/Gadget-popups.js?2\";
		var wgCollectionNavPopupCSSURL = \"/CompCogNeuro/extensions/Collection/collection/Gadget-navpop.css?2\";
		var wgCollectionAddPageText = \"Add linked wiki page to your book\";
		var wgCollectionAddCategoryText = \"Add wiki pages in linked category to your book\";
		var wgCollectionRemovePageText = \"Remove linked wiki page from your book\";
		var wgCollectionPopupHelpText = \"To deactivate this feature click \\\"Clear book\\\" in the \\\"Create a book\\\" box\";
		var wgCollectionArticleNamespaces = [0, 1, 2, 3, 4, 5, 8, 9, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111];
		/*]]>*/</script>
<script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/json2.js?2\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/popupcheck.js?2\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/popup.js\"></script><script type=\"text/javascript\" src=\"/CompCogNeuro/extensions/Collection/collection/Gadget-popups.js?2\"></script>		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class=\"visualClear\"></div>
			<div id=\"footer\">
				<div id=\"f-poweredbyico\"><a href=\"http://www.mediawiki.org/\"><img src=\"/CompCogNeuro/skins/common/images/poweredby_mediawiki_88x31.png\" alt=\"Powered by MediaWiki\"></a></div>
			<ul id=\"f-list\">
					<li id=\"lastmod\"> This page was last modified on 12 January 2008, at 07:32.</li>
					<li id=\"viewcount\">This page has been accessed 1,626 times.</li>
					<li id=\"privacy\"><a href=\"/CompCogNeuro/index.php/Project:Privacy_policy\" title=\"Project:Privacy policy\">Privacy policy</a></li>
					<li id=\"about\"><a href=\"/CompCogNeuro/index.php/Project:About\" title=\"Project:About\">About Computational Cognitive Neuroscience Wiki</a></li>
					<li id=\"disclaimer\"><a href=\"/CompCogNeuro/index.php/Project:General_disclaimer\" title=\"Project:General disclaimer\">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type=\"text/javascript\">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served in 0.219 secs. -->
</body></html>";
  };
 };
 wizards {
  name=;
  el_typ=LeabraWizard;
  el_def=0;
  LeabraWizard @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="LeabraWizard_1";
   auto_open=0;
   n_layers=3;
   layer_cfg {
    name=;
    el_typ=LayerWizEl;
    el_def=0;
    LayerWizEl @[0] {
     name="LayerWizEl";
     n_units=25;
     io_type=138576;
    };
    LayerWizEl @[1] {
     name="LayerWizEl";
     n_units=25;
     io_type=131073;
    };
    LayerWizEl @[2] {
     name="LayerWizEl";
     n_units=25;
     io_type=131072;
    };
   };
   connectivity=BIDIRECTIONAL;
   default_net_type=LeabraNetwork;
  };
 };
 edits {
  name=;
  el_typ=SelectEdit;
  el_def=0;
  SelectEdit @[0] {
   name="ControlPanel";
   auto_edit=1;
   desc="Master control panel for Self Organizing Network";
   mbrs {
    name=;
    el_typ=EditMbrItem;
    el_def=0;
    EditMbrItem @[0] {
     label="kwta";
     desc=" desired activity level over entire layer (NOTE: used to set target activity for UNIT_INHIB, AVG_MAX_PT_INHIB, but not used for actually computing inhib for these cases)<br>  k from:  how is the active_k determined: directly by k, by pct, or by no. of units where ext > pat_q<br>    USE K:  use the k specified directly<br>    USE PCT:  use the percentage pct to compute the k as a function of layer size<br>    USE PAT K:  use the activity level of the current event pattern (k = of units > pat_q)<br>  k:  desired number of active units in the layer<br>  pct:  desired proportion of activity (used to compute a k value based on layer size, .25 std)<br>  pat q: [Default: 0.2;0.5]  threshold for pat_k based activity level: add to k if ext > pat_q<br>  diff act pct: [Default: false]  if true, use different actual percent activity for overall layer activation<br>  act pct:  actual percent activity to put in kwta.pct field of layer<br>  gp i:  compute inhibition including all of the layers in the same group, or unit groups within the layer: each items computed inhib vals are multipled by gp_g scaling, then MAX'd, and each item's inhib is the MAX of this pooled MAX value and its original own value<br>  gp g:  how much this item (layer or unit group) contributes to the pooled layer group values";
     cust_desc=0;
     base=.projects[0].networks[0].specs[2].children[0]$$;
     mbr=LeabraLayerSpec::kwta;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[1] {
     label="wt_sig";
     desc=" sigmoidal weight function for contrast enhancement: high gain makes weights more binary & discriminative<br>  gain: [Default: 1;6]  gain (contrast, sharpness) of the weight contrast function (1 = linear)<br>  off: [Default: 1:1.25]  offset of the function (1=centered at .5, >1=higher, <1=lower) -- 1.25 is standard for Leabra CHL, 1.2 for XCAL";
     cust_desc=0;
     base=.projects[0].networks[0].specs[1]$$;
     mbr=LeabraConSpec::wt_sig;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[2] {
     label="savg_cor";
     desc=" for Hebbian and netinput computation: correction for sending average act levels (i.e., renormalization); also norm_con_n for normalizing netinput computation<br>  cor: [Default: 0.4:0.8]  proportion of correction to apply (0=none, 1=all, .5=half, etc)<br>  thresh: [Default: 0.001]  threshold of sending average activation below which learning does not occur (prevents learning when there is no input)<br>  norm con n: [Default: true]  WARNING: this is now obsolete and only used if wt_scale.old = true -- in normalizing netinput, divide by the actual number of connections (recv group n), not the overall number of units in the sending layer -- THIS SHOULD ALWAYS BE ON AND IS THE NEW DEFAULT";
     cust_desc=0;
     base=$.projects[0].networks[0].specs[1]$;
     mbr=LeabraConSpec::savg_cor;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[3] {
     label="rnd";
     desc=" Weight randomization specification. Note that NONE means no value at all, not the mean, and should be used if some other source is setting the weights, e.g., from a projectionspec or loading from a file etc<br>  type:  type of random variable to generate<br>    UNIFORM:  uniform with var = range on either side of the mean<br>    BINOMIAL:  binomial with var = p, par = n<br>    POISSON:  poisson with lambda = var<br>    GAMMA:  gamma with var and par = stages<br>    GAUSSIAN:  normal with var<br>    NONE:  just the mean<br>  mean:  mean of random distribution<br>  var:  'varibility' parameter for the random numbers (gauss = standard deviation, not variance; uniform = half-range)<br>  par:  extra parameter for distribution (depends on each one)";
     cust_desc=0;
     base=$.projects[0].networks[0].specs[1]$;
     mbr=ConSpec::rnd;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[4] {
     label="lrate";
     desc="[Default: 0.01;0.02]  [0.01 for std Leabra, .02 for CtLeabra] learning rate -- how fast do the weights change per experience";
     cust_desc=0;
     base=$.projects[0].networks[0].specs[1]$;
     mbr=LeabraConSpec::lrate;
     is_numeric=1;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[5] {
     label="inhib";
     desc=" how to compute inhibition -- for kwta modes, a single global inhibition value is computed for the entire layer<br>  type:  how to compute inhibition (g_i)<br>    KWTA INHIB:  between thresholds of k and k+1th most activated units (sets precise k value, should use i_kwta_pt = .25 std)<br>    KWTA AVG INHIB:  average of top k vs avg of rest (provides more flexibility in actual k value, should use i_kwta_pt = .6 std)<br>    KWTA KV2K:  average of top k vs avg of next k (2k) -- avoids long 'tail' of distribution of weakly active units, while providing similar flexibility as KWTA_AVG_INHIB, and also is equivalent to KWTA_INHIB for k=1 -- i_kwta_pt = .25 is std. In general, this is now preferred to KWTA_AVG_INHIB<br>    KWTA COMP COST:  competitor cost kwta function: inhibition is i_kwta_pt below the k'th unit's threshold inhibition value if there are no strong competitors (>comp_thr proportion of kth inhib val), and each competitor increases inhibition linearly (normalized by total possible = n-k) with gain comp_gain -- produces cleaner competitive dynamics and considerable kwta flexibility<br>    AVG MAX PT INHIB:  put inhib value at i_kwta_pt between avg and max values for layer<br>    MAX INHIB:  put inhib value at i_kwta_pt below max guy in layer<br>    UNIT INHIB:  unit-based inhibition (g_i from netinput -- requires connections with inhib flag set to provide inhibition)<br>  kwta pt: [Default: 0.25;0.6;0.2]  [Default: .25 for KWTA_INHIB and KWTA_KV2K, .6 for KWTA_AVG, .2 for AVG_MAX_PT_INHIB] point to place inhibition between k and k+1 (or avg and max for AVG_MAX_PT_INHIB)<br>  min i: [Default: 0]  minimum inhibition value -- set this higher than zero to prevent units from getting active even if there is not much overall excitation<br>  fb act thr: [Default: 0;0.5]  threshold for max activation in layer or group for full kwta inhibition value to be delivered -- below this threshold, the feedback portion of inhibition is proportional to the max act compared to this threshold -- ff_pct of inhibition is always delivered regardless -- allows for an initial wave of activation to get things flowing in the network, followed by inhibitory control<br>  ff pct: [Default: 0.5]  proportion of inhibition that is considered feed forward, and thus not subject to modulation from the fb_act_thr feedback threshold -- this portion of the kwta inhibition is always delivered regardless<br>  fb max dt: [Default: 0.1]  time constant of decay for max activation in the layer or group -- instantly goes to a new max value, but then decays back down with this time constant -- provides needed memory to the fb_act_thr dynamics<br>  comp thr:  [0-1] Threshold for competitors in KWTA_COMP_COST -- competitor threshold inhibition is normalized by k'th inhibition and those above this threshold are counted as competitors <br>  comp gain:  Gain for competitors in KWTA_COMP_COST -- how much to multiply contribution of competitors to increase inhibition level<br>  gp pt: [Default: 0.2]  for unit groups: point to place inhibition between avg and max for AVG_MAX_PT_INHIB";
     cust_desc=0;
     base=$.projects[0].networks[0].specs[2].children[0]$;
     mbr=LeabraLayerSpec::inhib;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[6] {
     label="max_epoch";
     desc=" integer value (also for enum types)";
     cust_desc=0;
     base=.projects[0].programs.gp[0][1].vars[0]$$;
     mbr=ProgVar::int_val;
     is_numeric=1;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem @[7] {
     label="cycle update view";
     desc=" boolean value";
     cust_desc=0;
     base=.projects[0].programs.gp[0][5].vars[0]$$;
     mbr=ProgVar::bool_val;
     is_numeric=0;
     param_search {
      search=0;
      min_val=0;
      max_val=1;
      next_val=0;
      incr=0.1000000014901161;
     };
    };
    EditMbrItem_Group @.gp[0] {
     name="Net Data";
     el_typ=EditMbrItem;
     el_def=0;
     EditMbrItem @[0] {
      label="SelfOrgNet trial";
      desc=" trial counter: number of external input patterns that have been presented in the current epoch (updated by program)";
      cust_desc=0;
      base=.projects[0].networks[0]$$;
      mbr=Network::trial;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[1] {
      label="SelfOrgNet trial name";
      desc=" name associated with the current trial (e.g., name of input pattern, typically set by a LayerWriter)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::trial_name;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[2] {
      label="SelfOrgNet epoch";
      desc=" epoch counter: number of times a complete set of training patterns has been presented (updated by program)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::epoch;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
     EditMbrItem @[3] {
      label="SelfOrgNet batch";
      desc=" batch counter: number of times network has been trained over a full sequence of epochs (updated by program)";
      cust_desc=0;
      base=$.projects[0].networks[0]$;
      mbr=Network::batch;
      is_numeric=0;
      param_search {
       search=0;
       min_val=0;
       max_val=1;
       next_val=0;
       incr=0.1000000014901161;
      };
     };
    };
   };
   mths {
    name=;
    el_typ=EditMthItem;
    el_def=0;
    group_type=GT_BUTTONS;
    EditMthItem @[0] {
     label="Defaults";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=.projects[0].programs[0]$$;
     mth=Program::Run_Gui;
    };
    EditMthItem @[1] {
     label="Train: Init";
     desc=" set the program state back to the beginning";
     cust_desc=0;
     base=.projects[0].programs.gp[0][1]$$;
     mth=Program::Init;
    };
    EditMthItem @[2] {
     label="Run";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][1]$;
     mth=Program::Run_Gui;
    };
    EditMthItem @[3] {
     label="Step";
     desc=" step the program at the level of the given program -- if NULL then step_prog default value will be used";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][1]$;
     mth=Program::Step_Gui;
    };
    EditMthItem @[4] {
     label="Stop";
     desc=" stop the current program at its next natural stopping point (i.e., cleanly stopping when appropriate chunks of computation have completed)";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][1]$;
     mth=Program::Stop;
    };
    EditMthItem @[5] {
     label="Batch: Init";
     desc=" set the program state back to the beginning";
     cust_desc=0;
     base=.projects[0].programs.gp[0][0]$$;
     mth=Program::Init;
    };
    EditMthItem @[6] {
     label="Run";
     desc=" run the program -- if not yet Init, will run Init first";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][0]$;
     mth=Program::Run_Gui;
    };
    EditMthItem @[7] {
     label="Stop";
     desc=" stop the current program at its next natural stopping point (i.e., cleanly stopping when appropriate chunks of computation have completed)";
     cust_desc=0;
     base=$.projects[0].programs.gp[0][0]$;
     mth=Program::Stop;
    };
   };
  };
 };
 data {
  name=;
  el_typ=DataTable;
  el_def=0;
  DataTable_Group @.gp[0] {
   name="InputData";
   el_typ=DataTable;
   el_def=0;
   DataTable @[0] {
    name="Lines5x5x2";
    desc="horizontal and vertical lines on 5x5 input, 2 lines per input, input patterns only";
    data {
     name="data";
     el_typ=String_Data;
     el_def=0;
     String_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [45] "V0_V1";"V0_V2";"V0_V3";"V0_V4";"V0_H0";"V0_H1";"V0_H2";"V0_H3";"V0_H4";"V1_V2";
"V1_V3";"V1_V4";"V1_H0";"V1_H1";"V1_H2";"V1_H3";"V1_H4";"V2_V3";"V2_V4";"V2_H0";
"V2_H1";"V2_H2";"V2_H3";"V2_H4";"V3_V4";"V3_H0";"V3_H1";"V3_H2";"V3_H3";"V3_H4";
"V4_H0";"V4_H1";"V4_H2";"V4_H3";"V4_H4";"H0_H1";"H0_H2";"H0_H3";"H0_H4";"H1_H2";
"H1_H3";"H1_H4";"H2_H3";"H2_H4";"H3_H4";      };
     };
     float_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Input";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 5;5;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [5 5 45] 1;1;0;0;0;1;1;0;0;0;
1;1;0;0;0;1;1;0;0;0;
1;1;0;0;0;1;0;1;0;0;
1;0;1;0;0;1;0;1;0;0;
1;0;1;0;0;1;0;1;0;0;
1;0;0;1;0;1;0;0;1;0;
1;0;0;1;0;1;0;0;1;0;
1;0;0;1;0;1;0;0;0;1;
1;0;0;0;1;1;0;0;0;1;
1;0;0;0;1;1;0;0;0;1;
1;1;1;1;1;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;1;1;1;1;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;1;1;1;1;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;1;1;1;1;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;1;1;1;1;0;1;1;0;0;
0;1;1;0;0;0;1;1;0;0;
0;1;1;0;0;0;1;1;0;0;
0;1;0;1;0;0;1;0;1;0;
0;1;0;1;0;0;1;0;1;0;
0;1;0;1;0;0;1;0;0;1;
0;1;0;0;1;0;1;0;0;1;
0;1;0;0;1;0;1;0;0;1;
1;1;1;1;1;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
1;1;1;1;1;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
1;1;1;1;1;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
1;1;1;1;1;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
1;1;1;1;1;0;0;1;1;0;
0;0;1;1;0;0;0;1;1;0;
0;0;1;1;0;0;0;1;1;0;
0;0;1;0;1;0;0;1;0;1;
0;0;1;0;1;0;0;1;0;1;
0;0;1;0;1;1;1;1;1;1;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;1;1;1;1;1;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;1;1;1;1;1;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;1;1;1;1;1;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;1;1;1;1;1;
0;0;0;1;1;0;0;0;1;1;
0;0;0;1;1;0;0;0;1;1;
0;0;0;1;1;1;1;1;1;1;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;1;1;1;1;1;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;1;1;1;1;1;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;1;1;1;1;1;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;1;1;1;1;1;
1;1;1;1;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
1;1;1;1;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
1;1;1;1;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
1;1;1;1;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
1;1;1;1;1;1;1;1;1;1;
1;1;1;1;1;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
1;1;1;1;1;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
1;1;1;1;1;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
1;1;1;1;1;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
1;1;1;1;1;      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[1] {
    name="Lines5x5x1";
    desc="horizontal and vertical lines on 5x5 input, 1 line per input, input patterns only";
    data {
     name="data";
     el_typ=String_Data;
     el_def=0;
     String_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [10] "V0";"V1";"V2";"V3";"V4";"H0";"H1";"H2";"H3";"H4";
      };
     };
     float_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Input";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 5;5;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [5 5 10] 1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;1;0;0;0;0;
1;0;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;1;0;0;0;0;1;0;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;1;0;0;
0;0;1;0;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;1;0;0;0;0;1;0;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;0;0;0;0;1;
0;0;0;0;1;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;0;0;0;0;0;
0;0;0;0;0;1;1;1;1;1;
      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
  };
  DataTable_Group @.gp[1] {
   name="OutputData";
   el_typ=DataTable;
   el_def=0;
   DataTable @[0] {
    name="TrialOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     int_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="batch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="epoch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[2] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="trial";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     String_Data @[3] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="trial_name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     String_Data @[4] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="group_name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[5] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="phase_no";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[6] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="minus_cycles";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[7] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="sse";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[8] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="ext_rew";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[1] {
    name="EpochOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     int_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="batch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="epoch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[2] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="avg_cycles";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[3] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Hidden_Fm_Input_r_wt";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 5;5;5;4;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [4] ;;;;      };
      ar {
       name=;
	    [5 5 5 4 0]       };
     };
     float_Data @[4] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="uniq_pats";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[2] {
    name="BatchOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     float_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="uniq_pats_last_mean";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [1] 10;      };
     };
     float_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="uniq_pats_last_min";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [1] 10;      };
     };
     float_Data @[2] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="uniq_pats_last_max";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [1] 10;      };
     };
     float_Data @[3] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="uniq_pats_last_count";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [1] 8;      };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[3] {
    name="TrialTestOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     int_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="batch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="epoch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[2] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="trial";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     String_Data @[3] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="trial_name";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[4] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
       UserDataItem @[1] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="cycle";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[5] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="view_panel_wd";
	value 6 0=0.1865671575069427;
	val_type_fixed=0;
       };
      };
      name="Hidden_act_eq";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=1;
      cell_geom{ 5;4;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [2] ;;      };
      ar {
       name=;
	    [5 4 0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
   DataTable @[4] {
    name="EpochTestOutputData";
    desc=;
    data {
     name="data";
     el_typ=int_Data;
     el_def=0;
     int_Data @[0] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
      };
      name="batch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     int_Data @[1] {
      UserDataItem_List @*(.user_data_) {
       name=;
       el_typ=UserDataItemBase;
       el_def=0;
       UserDataItem @[0] {
	name="NARROW";
	value 1 0=1;
	val_type_fixed=0;
       };
      };
      name="epoch";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[2] {
      name="avg_sse";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[3] {
      name="cnt_err";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[4] {
      name="avg_ext_rew";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[5] {
      name="avg_cycles";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[6] {
      name="epoch_time_tot";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
     float_Data @[7] {
      name="epoch_time_usr";
      col_flags=SAVE_ROWS|SAVE_DATA;
      is_matrix=0;
      cell_geom{ 1;      };
      calc_expr {
       expr=;
      };
      dim_names {
       name=;
	    [0]       };
      ar {
       name=;
	    [0]       };
     };
    };
    data_flags=SAVE_ROWS|AUTO_CALC;
    auto_load=NO_AUTO_LOAD;
    auto_load_file=;
    keygen 4 0=0;
   };
  };
  DataTable_Group @.gp[2] {
   name="AnalysisData";
   el_typ=DataTable;
   el_def=0;
  };
 };
 data_proc {
  name=;
  el_typ=taDataProc;
  el_def=0;
  taDataProc @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_base";
  };
  taDataAnal @[1] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_anal";
  };
  taDataGen @[2] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="data_gen";
  };
  taImageProc @[3] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="NO_CLIP";
     value 1 0=1;
     val_type_fixed=0;
    };
   };
   name="image_proc";
  };
 };
 programs {
  name=;
  el_typ=Program;
  el_def=0;
  tags=;
  desc=;
  Program @[0] {
   name="SetDefaults";
   short_nm="SDflts";
   tags=;
   desc="restores default initial parameters in the simulation";
   flags=;
   objs {
    name=;
    el_typ=taNBase;
    el_def=0;
   };
   types {
    name=;
    el_typ=ProgType;
    el_def=0;
   };
   args {
    name=;
    el_typ=ProgVar;
    el_def=0;
   };
   vars {
    name=;
    el_typ=ProgVar;
    el_def=0;
    ProgVar @[0] {
     name="kwta";
     var_type=T_Int;
     int_val=2;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[1] {
     name="lrate";
     var_type=T_Real;
     real_val=0.01;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[2] {
     name="savg_cor";
     var_type=T_Real;
     real_val=0.5;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[3] {
     name="wt_sig_off";
     var_type=T_Real;
     real_val=1.25;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[4] {
     name="wt_sig_gain";
     var_type=T_Real;
     real_val=6;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[5] {
     name="rnd_wt_mean";
     var_type=T_Real;
     real_val=0.25;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[6] {
     name="inhib_pt";
     var_type=T_Real;
     real_val=0.7;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[7] {
     name="inhib_type";
     var_type=T_HardEnum;
     int_val=1;
     hard_enum_type=LeabraInhibSpec::InhibType;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[8] {
     name="ControlPanel";
     var_type=T_Object;
     object_type=SelectEdit;
     object_val=.projects[0].edits[0]$$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[9] {
     name="con_spec";
     var_type=T_Object;
     object_type=LeabraConSpec;
     object_val=$.projects[0].networks[0].specs[1]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[10] {
     name="HiddenLayer";
     var_type=T_Object;
     object_type=LeabraLayerSpec;
     object_val=$.projects[0].networks[0].specs[2].children[0]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
    ProgVar @[11] {
     name="LeabraTrain";
     var_type=T_Object;
     object_type=Program;
     object_val=$.projects[0].programs.gp[0][1]$;
     objs_ptr=0;
     flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
     reference=0;
     desc=;
     init_from=NULL;
    };
   };
   functions {
    name=;
    el_typ=Function;
    el_def=0;
   };
   load_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   init_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
   };
   prog_code {
    name=;
    el_typ=ProgEl;
    el_def=0;
    MemberAssign @[0] {
     desc=;
     flags=;
     obj=.projects[0].programs[0].vars[10]$$;
     path="kwta.k";
     expr {
      expr="kwta";
     };
     update_after=0;
    };
    MemberAssign @[1] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[10]$;
     path="inhib.type";
     expr {
      expr="inhib_type";
     };
     update_after=0;
    };
    MemberAssign @[2] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[10]$;
     path="inhib.kwta_pt";
     expr {
      expr="inhib_pt";
     };
     update_after=0;
    };
    MemberAssign @[3] {
     desc=;
     flags=;
     obj=.projects[0].programs[0].vars[9]$$;
     path="lrate";
     expr {
      expr="lrate";
     };
     update_after=0;
    };
    MemberAssign @[4] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[9]$;
     path="savg_cor.cor";
     expr {
      expr="savg_cor";
     };
     update_after=0;
    };
    MemberAssign @[5] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[9]$;
     path="wt_sig.off";
     expr {
      expr="wt_sig_off";
     };
     update_after=0;
    };
    MemberAssign @[6] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[9]$;
     path="wt_sig.gain";
     expr {
      expr="wt_sig_gain";
     };
     update_after=0;
    };
    MemberAssign @[7] {
     desc=;
     flags=;
     obj=$.projects[0].programs[0].vars[9]$;
     path="rnd.mean";
     expr {
      expr="rnd_wt_mean";
     };
     update_after=0;
    };
    MethodCall @[8] {
     desc=;
     flags=;
     result_var=NULL;
     obj=.projects[0].programs[0].vars[11]$$;
     method=Program::SetVar;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
      ProgArg @[0] {
       arg_type=const_taString_ref;
       type="const taString&";
       name="var_nm";
       required=1;
       def_val="\"\"";
       expr {
	expr="\"max_epoch\"";
       };
      };
      ProgArg @[1] {
       arg_type=const_Variant_ref;
       type="const Variant&";
       name="value";
       required=1;
       def_val=;
       expr {
	expr="30";
       };
      };
     };
    };
    MethodCall @[9] {
     desc=;
     flags=;
     result_var=NULL;
     obj=.projects[0].programs[0].vars[8]$$;
     method=SelectEdit::UpdateAfterEdit;
     meth_args {
      name=;
      el_typ=ProgArg;
      el_def=0;
     };
    };
   };
   step_prog=NULL;
   step_n=1;
  };
  Program_Group @.gp[0] {
   name="LeabraAll_Std";
   el_typ=Program;
   el_def=0;
   tags="Leabra, Std, All";
   desc="The full set of programs for training a standard Leabra network";
   Program @[0] {
    name="LeabraBatch";
    short_nm="Batch";
    tags="Leabra, Std";
    desc="Iterate over training runs (a batch of training runs) -- just a simple loop that calls training program";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on -- updates batch counter on network and passes it to train program";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[0][0]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable with training patterns -- not used by this program, but passed to train program";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="batch";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="batch counter";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="max_batch";
      var_type=T_Int;
      int_val=8;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="maximum number of batch runs to perform";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="EpochOutputData";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[1][1]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initializes local batch counter and batch field on network";
      flags=;
      network_var=.projects[0].programs.gp[0][0].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][0].vars[0]$$;
      counter=Network::batch;
      update_after=0;
     };
     ResetDataRows @[1] {
      desc=;
      flags=;
      data_var=.projects[0].programs.gp[0][0].vars[2]$$;
     };
    };
    prog_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
     ResetDataRows @[0] {
      desc=;
      flags=;
      data_var=$.projects[0].programs.gp[0][0].vars[2]$;
     };
     NetCounterInit @[1] {
      desc="initializes local batch counter and batch field on network";
      flags=;
      network_var=$.projects[0].programs.gp[0][0].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][0].vars[0]$;
      counter=Network::batch;
      update_after=0;
     };
     WhileLoop @[2] {
      desc="the main loop over training runs";
      flags=;
      loop_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       ProgramCall @[0] {
	desc="run the training program -- sets the network and input_data args";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	 ProgArg @[2] {
	  arg_type=bool;
	  type="bool";
	  name="no_prompts";
	  required=1;
	  def_val=;
	  expr {
	   expr="true";
	  };
	 };
	};
	target=$.projects[0].programs.gp[0][1]$;
	targ_ld_init="*LeabraTrain*";
       };
       NetCounterIncr @[1] {
	desc="increment the local batch counter and copy to network";
	flags=;
	network_var=$.projects[0].programs.gp[0][0].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][0].vars[0]$;
	counter=Network::batch;
	update_after=0;
       };
      };
      test {
       expr="batch < max_batch";
      };
     };
     ProgramCall @[3] {
      desc=;
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[0][9]$$;
      targ_ld_init="*LeabraBatchMonitor*";
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[1] {
    name="LeabraTrain";
    short_nm="Train";
    tags="Leabra, Std";
    desc="A complete training run of a Leabra network: iterating over epochs until the network has learned the task";
    flags=;
    objs {
     name=;
     el_typ=RndSeed;
     el_def=0;
     RndSeed @[0] {
      name="rnd_seed";
      seed{ -1392252720;1340161243;-1352422396;-980675487;-841319250;-2002336442;1043937242;-1435716855;-234846625;1050689109;115807379;-147666678;-2219623;-1244353585;-1150059281;686169744;-552263968;-317609312;1790872929;1953900275;1444077454;2147400320;1456840187;1571298745;1531130288;-17738770;43708827;-240499390;-939254847;-1228421721;152651575;1150715858;1490583903;473454647;-420397867;680887953;-503795623;133414311;926495241;-1885958476;-406866954;1302535378;-1181988247;1964613474;152886587;-77276300;1551779105;1957651919;-1756338058;-2050274827;-846570075;-1153513295;2047998419;881259023;-483358943;-1536916831;-66730617;-1684631219;1129552741;-1109339473;-114510979;1260601075;1379227576;1829543228;-825577903;1769908379;-77009148;-712897274;1282003005;-942455823;-648785728;1456551990;-182346501;-1643403743;-445233383;-1116932211;627192503;-471666304;979198973;2034620448;236908117;-2146269990;843973002;-631278139;-31822478;253077226;-767290200;412658382;-79322722;222349386;-1748721780;1591210337;352230204;405429001;2091695083;2082233777;-182180144;600784032;815041410;1372691629;1295965248;-1888309494;555898510;-1195367315;-1974024397;590139326;-1307794336;-643609323;-1521995750;1205850597;266130274;-1897080807;1876211223;922197279;-1835035475;609243262;-1439354838;-824612803;-163492116;394988482;-579570174;1478498270;-1400323467;-951621522;-1391884163;-1371025000;-457761728;1144193518;363965131;-217315944;-570742359;-653694315;-589605966;2015936090;-831599251;-1012339987;1809845870;-1339549356;-289733256;1343552786;-1019476981;-1592926283;1228092097;-1432631729;-1800441359;785907824;1451498690;-489114494;-744537991;-223626569;-1349059174;594568591;1016764675;401996232;1261409410;1943319370;300605491;1762312124;738511663;1357467946;615123351;1834522676;316369547;1784835194;-2143313877;1391403474;-1573436443;-495621686;-563196427;-1292408649;999828755;850261034;2071056190;-628589688;1187193221;-225976893;1971731824;-1896958138;-685919610;-1058825172;27969087;204533392;1156132742;991952890;-344799142;1475325142;1659846797;-440179721;-499121152;-444845844;716715529;-1244191924;-1092113274;-1269451563;-1451726699;-593816746;1775902285;1633198273;993930374;1694844837;-739768196;-1768926748;-401709432;-1269049182;-1148577812;-204746829;794698046;547310661;1351419145;-1030994695;756482420;335980439;-1083117977;400890798;854985340;1611825091;603535970;-2109703293;-1307589697;-970760340;-1978659161;313464054;1812261868;-1347556768;582609802;-617822125;-1441933198;-1420143341;1906354585;-1840430627;-237742879;-1268748271;-628399257;-1192576163;-965032859;1750340393;-1920731212;43721147;-597794123;-284534595;1841607142;-484454380;109734149;-1577968404;-1467823910;385668653;932812215;1823998250;-1989838353;-725356422;1817026999;2049258441;-472156444;210274592;1126185630;1768896698;-1889897017;1276765370;113005001;2022692432;-1834489863;-213853684;-139390991;33672577;-868803091;1246047727;-60719632;-1266500374;956608660;1164238705;-1200678850;829467835;1795242455;-1136043905;-1330262173;-1688421544;55514518;2145045315;-286882784;-23208474;-1656022671;1969526392;1317347287;1600722569;-549671740;953658016;29749822;1768800661;267490436;1382432053;-712836442;-883805892;545334783;-1908247104;-1047836496;1723890374;-619319125;-1576412303;-1200021367;570505986;-2011276554;1599240049;1099173982;209079722;300064578;-2005850053;-2001051473;1342159476;-538956195;953457227;243270605;-786090472;1281346783;-1467964721;1098576155;809372285;1099041165;-1036144263;-123252640;-1698909362;-8754628;-908025060;1724183421;-362451665;1302634400;80159946;-1362649352;-1716812823;699453439;1443530724;-400282717;-1560422549;1447833273;-1206458395;-1368056207;-626683986;-957332079;-1861970453;275240767;-2115918802;202724016;-1334193979;2050678489;-228359025;-1828308844;701930119;-2012334179;-491189738;-1678165851;-382354880;515201229;330088256;1883288992;-836644122;-847789381;444353531;-275755413;-1027827603;1425867468;2112672072;-278027211;1755099319;-1117970632;-569811635;297963314;583156263;-283379247;-1149701303;-67624697;-911463419;1889965520;-593693208;-420165077;-2049234115;-598357935;-397808687;1058762066;680592595;-1030696007;-2037902371;-2056573065;-1478338650;-223389390;-1304401196;7384558;-1559560601;-969053093;731830331;83878859;-932609124;912918081;-856407508;923944211;1756458248;144234263;-989254498;432644221;853161950;118479396;1811568067;-1040799462;-1300358802;693032238;-1200506183;-1595293605;1654097330;674860085;-600854656;1951554375;-29328841;406981662;-413345935;-217381994;-1118427034;425162002;-1733962823;-1512530585;1148462970;592537641;-1527051568;1402185854;770077376;-1835792538;1880584219;-856480278;1352050582;-1270812867;-60810106;-456036571;1831219627;-1806986304;-701358279;-1491968622;222362497;1304577175;-864856351;456014558;-1160771253;369802371;-592216986;589636241;-618840594;-970439365;1064716499;1483253755;-217771681;-523364598;1759635788;605438497;-518864442;1048306043;15190602;649751286;-1081877805;1188441915;1415359913;-2129171184;186297315;515329369;-534436120;-2065096829;2052880562;-1812436115;378129306;730382226;813086827;-696973559;-1506401595;1936275799;-1316182333;1291982075;-1981672839;-948822177;1850907941;950813966;1481490017;640515516;677394697;-944024725;878875111;-599183101;1796822753;-1331877822;-498392285;-212796028;961693480;2007137454;1688066546;-1517352505;1040992674;1773060308;1492587252;861051285;-2099620170;-948532494;-1699296252;-109595058;-186309806;1636059623;1376206769;1002525284;2031683433;1068406270;-803726035;895689502;-1145443633;1989958107;-457498883;1650141746;1123152668;-967151249;1381338523;465455554;-1545998965;-1881667057;536342052;-29476296;391351884;-550383102;-502176404;439250387;836518216;-1278391438;493729083;719459667;-2115971380;1481310036;-812762216;104888631;2093958084;527248331;-1458639830;73176540;767417825;-1530071845;-237781836;361260363;-435020880;-1143162183;1025556706;1129516358;1389379104;-1135661533;-640426460;-645233021;-1558080863;439162737;-982730056;317767915;-1163468324;-943133508;1714462850;-22384425;896268749;753091851;-588635518;-765614063;1315107655;270824140;325351595;-605806425;-353065243;941682928;-1669365533;1819100153;-1136424179;-1921391071;473270534;245188502;745965159;427894749;-2125135508;-162565982;-1325098302;-1998467074;-649532245;419645576;-69965847;-1781580908;-356529551;-501226690;970673750;-1664356300;1501343125;908112300;1169106725;2080946046;840719974;-1870670198;-1443467787;617845697;936547956;-976915948;-2087365532;719250576;842088227;-1507023325;-345229734;-751430541;341181063;318390427;-1853132160;98156964;1392913423;728031714;-1596124537;1673821655;1018637773;-1201485503;1635992784;-967507497;978333447;670977831;2109873096;217221555;793125126;-1652473914;-1116074307;239405765;-77353180;-987694129;1599571433;-41353482;-1406093800;      };
      mti=624;
     };
    };
    types {
     name=;
     el_typ=DynEnumType;
     el_def=0;
     DynEnumType @[0] {
      name="RndInitType";
      desc=;
      enums {
       name=;
       el_typ=DynEnumItem;
       el_def=0;
       DynEnumItem @[0] {
	name="OLD_SEED";
	value=0;
	desc="use stored random seed value (recreates same sequence every time)";
       };
       DynEnumItem @[1] {
	name="NEW_SEED";
	value=1;
	desc="generate new random seed (new sequence of random numbers)";
       };
      };
      bits=0;
     };
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to train";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable with training patterns";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="no_prompts";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="If train is called by other programs (e.g., Batch), they should set this to true -- otherwise it is reset to false in Init";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="max_epoch";
      var_type=T_Int;
      int_val=30;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="maximum number of epochs to run";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch";
      var_type=T_Int;
      int_val=30;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current epoch -- local copy, which is used to update network's epoch counter";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="train_mode";
      var_type=T_HardEnum;
      int_val=1;
      hard_enum_type=Network::TrainMode;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="TRAIN = update weights (learn), TEST = just record network's responses but don't learn";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="rnd_init";
      var_type=T_DynEnum;
      dyn_enum_val {
       enum_type=.projects[0].programs.gp[0][1].types[0]$$;
       value=1;
      };
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="how to initialize the random numbers when the Init button is pressed";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="err_stopcrit";
      var_type=T_Real;
      real_val=-1;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="stopping criterion -- when error measure (count of trials with a non-zero error by defult)
goes <= this value, stop training (set to -1 to disable stopping criterion, and always train to max_epoch epochs)";
      init_from=NULL;
     };
     ProgVar @[5] {
      name="rnd_seed";
      var_type=T_Object;
      object_type=RndSeed;
      object_val=.projects[0].programs.gp[0][1].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="random seed that is used at start of training -- if OldSeed is called";
      init_from=NULL;
     };
     ProgVar @[6] {
      name="train_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=.projects[0].networks[0].train_time$$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="records time used to train network (object lives on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[7] {
      name="Hidden";
      var_type=T_Object;
      object_type=LeabraLayer;
      object_val=.projects[0].networks[0].layers[1]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[8] {
      name="HiddenLayer";
      var_type=T_Object;
      object_type=LeabraLayerSpec;
      object_val=$.projects[0].networks[0].specs[2].children[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[9] {
      name="LeabraConSpec_0";
      var_type=T_Object;
      object_type=LeabraConSpec;
      object_val=$.projects[0].networks[0].specs[1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc=;
      flags=;
      result_var=.projects[0].programs.gp[0][1].args[2]$$;
      expr {
       expr="false";
      };
     };
     MethodCall @[1] {
      desc="check network to make sure it is ready to be run";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][1].args[0]$$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     AssignExpr @[2] {
      desc="get our pointer to the network training time object";
      flags=;
      result_var=.projects[0].programs.gp[0][1].vars[6]$$;
      expr {
       expr="network.train_time";
      };
     };
     IfElse @[3] {
      desc="initialize random seed (either old or new)";
      flags=;
      cond {
       expr="rnd_init == OLD_SEED";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="restore previous random seed (all runs produce same results)";
	flags=;
	result_var=NULL;
	obj=.projects[0].programs.gp[0][1].vars[5]$$;
	method=RndSeed::OldSeed;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="new random numbers each time";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][1].vars[5]$;
	method=RndSeed::NewSeed;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
     };
     IfGuiPrompt @[4] {
      desc="don't initialize weights without checking";
      flags=;
      prompt="Do you want to Initialize Network Weights";
      yes_label="Yes";
      no_label="No";
      yes_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="initialize network weights: could also load pre-set weights or something else here";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][1].args[0]$;
	method=Network::Init_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
       PrintExpr @[1] {
	desc=;
	flags=;
	expr {
	 expr="network.name << \" Weights Initialized\"";
	};
       };
      };
     };
     MethodCall @[5] {
      desc="restore to standard layer spec";
      flags=NON_STD;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][1].vars[7]$$;
      method=LeabraLayer::SetLayerSpec;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=LayerSpec_ptr;
	type="LayerSpec*";
	name="sp";
	required=1;
	def_val=;
	expr {
	 expr="HiddenLayer";
	};
       };
      };
     };
     MethodCall @[6] {
      desc="need to update to reflect any changes in params";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][1].vars[9]$$;
      method=taBase::UpdateAfterEdit;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MemberMethodCall @[7] {
      desc="update from any changes to wt_sig";
      flags=NON_STD;
      obj=$.projects[0].programs.gp[0][1].args[0]$;
      path="specs.LeabraConSpec_0";
      result_var=NULL;
      method=taList_impl::UpdateAfterEdit;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="need to update to reflect any changes in params";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].vars[9]$;
      method=taBase::UpdateAfterEdit;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     AssignExpr @[1] {
      desc="get our pointer to the network training time object";
      flags=;
      result_var=$.projects[0].programs.gp[0][1].vars[6]$;
      expr {
       expr="network.train_time";
      };
     };
     MethodCall @[2] {
      desc="start timer to keep track of how long it takes to run entire training run";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].vars[6]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MemberAssign @[3] {
      desc="set network's training mode to our local value";
      flags=;
      obj=$.projects[0].programs.gp[0][1].args[0]$;
      path="train_mode";
      expr {
       expr="train_mode";
      };
      update_after=0;
     };
     IfElse @[4] {
      desc=;
      flags=;
      cond {
       expr="no_prompts";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="initialize network weights: could also load pre-set weights or something else here";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][1].args[0]$;
	method=Network::Init_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
       PrintExpr @[1] {
	desc=;
	flags=;
	expr {
	 expr="network.name << \" Weights Initialized\"";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     AssignExpr @[5] {
      desc="grab the official network epoch counter: will be initialized if needed by now";
      flags=;
      result_var=.projects[0].programs.gp[0][1].vars[1]$$;
      expr {
       expr="network.epoch";
      };
     };
     WhileLoop @[6] {
      desc="main loop over epochs of training";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the epoch program (one epoch), passes our network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][2]$$;
	targ_ld_init="*LeabraEpoch*";
       };
       NetCounterIncr @[1] {
	desc="increment the epoch counter (locally and on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][1].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][1].vars[1]$;
	counter=Network::epoch;
	update_after=1;
       };
       IfBreak @[2] {
	desc="stop if errors go below stopping criterion (note: could use sse or avg_sse here instead)";
	flags=;
	cond {
	 expr="network.cnt_err <= err_stopcrit";
	};
       };
      };
      test {
       expr="epoch < max_epoch";
      };
     };
     MethodCall @[7] {
      desc="stop the timer -- time elapsed is now recorded in this object, and can be displayed or recorded to a data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][1].vars[6]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[2] {
    name="LeabraEpoch";
    short_nm="Epoch";
    tags="Leabra, Std";
    desc="iterates over all of the items in a data table and calls LeabraTrial process on them";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="table of patterns to present to the network, one row at a time";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="data_loop_order";
      var_type=T_HardEnum;
      int_val=1;
      hard_enum_type=DataLoop::Order;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="controls the order in which events (rows of the input data datatable) are presented to the network
(SEQUENTIAL, PERMUTED, RANDOM)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[1][0]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="trial-level output data -- we reset it every epoch by default, so it just contains last epoch of data";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=.projects[0].networks[0].epoch_time$$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="timer to record time required to perform one epoch of processing (object is on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="data_loop_index";
      var_type=T_Int;
      int_val=45;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="index counter for the looping over items in the input_data datatable (not always the same as trial counter, depending on distributed memory computation)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=.projects[0].programs.gp[0][2].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][2].vars[1]$$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=.projects[0].programs.gp[0][2].vars[3]$$;
      expr {
       expr="network.epoch_time";
      };
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=$.projects[0].programs.gp[0][2].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][2].vars[1]$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=$.projects[0].programs.gp[0][2].vars[3]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[2] {
      desc="start the epoch timer to record computation time per epoch";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][2].vars[3]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="reset trial-level monitor data every epoch, so it reflects only the most recent epoch's worth of data (turn flags OFF to accumulate trial data across entire training run)";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][2].vars[2]$$;
      method=DataTable::ResetData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetDataLoop @[4] {
      desc="iterates over the events/rows of input_data, according to data_loop_order variable";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the trial program, passing network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][3]$$;
	targ_ld_init="*LeabraTrial*";
       };
      };
      data_var=.projects[0].programs.gp[0][2].args[1]$$;
      index_var=.projects[0].programs.gp[0][2].vars[4]$$;
      order_var=.projects[0].programs.gp[0][2].vars[0]$$;
      order=PERMUTED;
      item_idx_list{ 7;11;32;18;34;2;22;42;12;5;31;13;38;37;1;23;9;0;8;4;35;3;28;33;41;21;24;17;6;16;19;27;20;40;15;36;44;10;29;30;26;25;39;43;14;      };
      update_after=0;
      dmem_nprocs=1;
      dmem_this_proc=0;
      grouped=0;
      group_col 9 0="Group";
      group_index_var=NULL;
      group_order_var=NULL;
      group_order=PERMUTED;
      group_idx_list{       };
     };
     IfElse @[5] {
      desc="if full batch mode, update only at end of epoch";
      flags=;
      cond {
       expr="network.wt_update == Network::BATCH";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="final update of weights based on accumulated changes";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][2].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     MethodCall @[6] {
      desc="network accumulates some core statistics over the epoch -- this finalizes that process and computes summary stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][2].args[0]$;
      method=LeabraNetwork::Compute_EpochStats;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[7] {
      desc="done with the computation in the epoch -- record time it took";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][2].vars[3]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[8] {
      desc="call testing program";
      flags=NEW_EL;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=LeabraNetwork;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[1][0]$$;
      targ_ld_init="*LeabraEpochTest*";
     };
     ProgramCall @[9] {
      desc="run program that records data from network and possibly other sources about the epoch";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[0][8]$$;
      targ_ld_init="*LeabraEpochMonitor*";
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[3] {
    name="LeabraTrial";
    short_nm="Trial";
    tags="Leabra, Std";
    desc="Leabra processing of a single input/toutput event or external information: typically runs a minus and a plus phase, then learns (unless testing)";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on -- typically set by higher-level calling programs";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable containing training input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="phase_no";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="local phase counting variable (0 is typically minus phase, 1 is typically plus -- depends on network settings)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether to update any network view displays after trial is completed";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=.projects[0].programs.gp[0][3].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][3].vars[0]$$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=$.projects[0].programs.gp[0][3].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][3].vars[0]$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
     MethodCall @[1] {
      desc="initializes various counters at start of trial";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][3].args[0]$;
      method=LeabraNetwork::Trial_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     WhileLoop @[2] {
      desc="loop over phases of settling in the network";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the settle program (which iterates over cyles of network activation updating) for each phase";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][4]$$;
	targ_ld_init="*LeabraSettle*";
       };
       NetCounterIncr @[1] {
	desc="increment the phase number (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][3].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][3].vars[0]$;
	counter=LeabraNetwork::phase_no;
	update_after=0;
       };
       MethodCall @[2] {
	desc="increments other phase state information to prepare for the next phase of settling";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][3].args[0]$;
	method=LeabraNetwork::Trial_UpdatePhase;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      test {
       expr="phase_no < network.phase_max";
      };
     };
     MethodCall @[3] {
      desc="after the trial is over, do final computations: Compute_dWt (learn weights), compute stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][3].args[0]$;
      method=LeabraNetwork::Trial_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     If @[4] {
      desc=;
      flags=;
      cond {
       expr="network.Compute_Weights_Test(network.trial+1)";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="update the weight values based on changes computed by trial program";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][3].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
     };
     ProgramCall @[5] {
      desc="records data about the trial-level processing to a datatable for graphing/processing";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[0][7]$$;
      targ_ld_init="*LeabraTrialMonitor*";
     };
     NetUpdateView @[6] {
      desc="update the network view(s) (only if update_net_view is true)";
      flags=;
      network_var=$.projects[0].programs.gp[0][3].args[0]$;
      update_var=.projects[0].programs.gp[0][3].vars[1]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[4] {
    name="LeabraSettle";
    short_nm="Settle";
    tags="Leabra, Std";
    desc="iterates over cycles of updating until network has settled into a stable state, or output activations have exceeded a threshold";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="cycle";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current cycle of settling (local loop counter)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="min_cycles";
      var_type=T_Int;
      int_val=5;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="IMPORTANT: this value is obtained from the network min_cycles and min_cycles_phase2 -- change the value on the network object, not here in this program!
sets the minimum number of cycles to settle for, regardless of network state changes, etc";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=1;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="if true, will update network views at end of settling";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=.projects[0].programs.gp[0][4].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[0][4].vars[0]$$;
      counter=Network::cycle;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=$.projects[0].programs.gp[0][4].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[0][4].vars[0]$;
      counter=Network::cycle;
      update_after=0;
     };
     MethodCall @[1] {
      desc="resets input data, before getting new external inputs data from apply inputs call";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][4].args[0]$;
      method=Network::Init_InputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[2] {
      desc="apply external input activations from the input_data table to the network
this program can be extended to do arbitrary things to generate data and apply it to network layers";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
       ProgArg @[1] {
	arg_type=DataTable;
	type="DataTable*";
	name="input_data";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
      };
      target=.projects[0].programs.gp[0][6]$$;
      targ_ld_init="*ApplyInputs*";
     };
     MethodCall @[3] {
      desc="initializes various counters at start of settling";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][4].args[0]$;
      method=LeabraNetwork::Settle_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[4] {
      desc="get appropriate min_cycles value depending on which phase we're in";
      flags=;
      cond {
       expr="network.phase_no <= 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=.projects[0].programs.gp[0][4].vars[1]$$;
	expr {
	 expr="network.min_cycles";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=$.projects[0].programs.gp[0][4].vars[1]$;
	expr {
	 expr="network.min_cycles_phase2";
	};
       };
      };
     };
     WhileLoop @[5] {
      desc="the main loop over cycles of updating";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the cycle program, which computes one cycle of activations";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	};
	target=.projects[0].programs.gp[0][5]$$;
	targ_ld_init="*LeabraCycle*";
       };
       NetCounterIncr @[1] {
	desc="increment cycle counter (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[0][4].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[0][4].vars[0]$;
	counter=Network::cycle;
	update_after=0;
       };
       IfContinue @[2] {
	desc="avoid subsequent stopping criteria if below min_cycles";
	flags=;
	cond {
	 expr="cycle < min_cycles";
	};
       };
       IfBreak @[3] {
	desc="stopping criterion for settling: based either on maximum change in activation (maxda) or on the maximum activation value in the network getting over threshold (which ever comes first).  Set either parmeter to values that are always false (e.g., trg_max_act_stopcrit = -1) to eliminate associated source of criterion for stopping settling.";
	flags=;
	cond {
	 expr="(network.maxda < network.maxda_stopcrit) ||
 (network.trg_max_act > network.trg_max_act_stopcrit)";
	};
       };
      };
      test {
       expr="cycle < network.cycle_max";
      };
     };
     MethodCall @[6] {
      desc="perform final operations at end of settling (storing final activations, etc)";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][4].args[0]$;
      method=LeabraNetwork::Settle_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[7] {
      desc="only run trial-level statistics in minus phase (otherwise network may have correct answer clamped on!).  IMPORTANT: this assumes that you've got target activation values for output layers already
presented in the minus phase -- if this is not the case (values are computed on the fly), you may want to run this instead at the start of the plus phase, after ApplyInputs";
      flags=;
      cond {
       expr="network.phase == LeabraNetwork::MINUS_PHASE";
      };
      true_code {
       name=;
       el_typ=MethodCall;
       el_def=0;
       MethodCall @[0] {
	desc="compute trial-level statistics";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][4].args[0]$;
	method=LeabraNetwork::Compute_TrialStats;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     IfElse @[8] {
      desc="this stat must be called in plus phase when reward information is avail";
      flags=;
      cond {
       expr="network.phase_no == 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="get external reward information";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[0][4].args[0]$;
	method=LeabraNetwork::Compute_ExtRew;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     NetUpdateView @[9] {
      desc="update network views, if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[0][4].args[0]$;
      update_var=.projects[0].programs.gp[0][4].vars[2]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[5] {
    name="LeabraCycle";
    short_nm="Cycle";
    tags="Leabra, Std";
    desc="runs one cycle of leabra processing (updating net inputs and activations)";
    flags=;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether network views will be updated on a cycle-by-cycle basis (slow, but often quite useful for seeing how processing is proceeding)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="this does all the standard leabra processing for one cycle of activation updating";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][5].args[0]$$;
      method=LeabraNetwork::Cycle_Run;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetUpdateView @[1] {
      desc="update network views if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[0][5].args[0]$;
      update_var=$.projects[0].programs.gp[0][5].vars[0]$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[6] {
    name="ApplyInputs";
    short_nm="AplyIn";
    tags="Network, InputData, Apply";
    desc="apply the current input data to the network as external input and target values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=LayerWriter;
     el_def=0;
     LayerWriter @[0] {
      name="LayerWriter_0";
      data=$.projects[0].data.gp[0][0]$;
      network=$.projects[0].networks[0]$;
      layer_data {
       name=;
       el_typ=LayerWriterEl;
       el_def=0;
       LayerWriterEl @[0] {
	chan_name="Input";
	net_target=LAYER;
	layer_name="Input";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=EXT;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[1] {
	chan_name="Name";
	net_target=TRIAL_NAME;
	layer_name="Name";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
      };
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to apply inputs to -- typically set by calling program";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="input datatable containing input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="LayerWriter_0";
      var_type=T_Object;
      object_type=LayerWriter;
      object_val=.projects[0].programs.gp[0][6].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="this is a pointer to the LayerWriter object in objs -- edit that object to determine how information is presented to the network";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][6].vars[0]$$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the layer writer -- will emit warnings and errors for missing or misconfigured items";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[0]$;
      method=taList_impl::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="apply inputs to the network!  layer writer has all the key specs";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][6].vars[0]$;
      method=LayerWriter::ApplyInputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[7] {
    name="LeabraTrialMonitor";
    short_nm="TrlMon";
    tags="Leabra, Std, Monitor";
    desc="monitor trial-level data from the network (and potentially other sources) -- stores results in datatable (TrialOutputData typically) that can be used for graph/grid views and further analysis ";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="trial_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="trial";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="trial_name";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial_name";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="group_name";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="group_name";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[5] {
	name="phase_no";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="phase_no";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[6] {
	name="minus_cycles";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="minus_cycles";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[7] {
	name="sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[8] {
	name="ext_rew";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="ext_rew";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][0]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to record data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to record trial-level data to (this program writes new data to this table!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[0][7].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the NetMonitor object in objs secton of this program that contains configuration for what to record and where to get it";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="set the network and datatable for the NetMonitor";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][7].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the network monitor -- will emit warnings and errors for misconfigurations";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="update the monitor items and data schema based on current settings of the NetMonitor object";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][7].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data from the network and other sources -- this does the main work";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[2] {
      desc="update views and other things after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][7].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[3] {
      desc="only functional for dmem projects: synchronizes trial data across processes so that all distributed memory processors have the same trial-level data, despite having run only a subset of them each";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][7].args[0]$$;
      method=Network::DMem_ShareTrialData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="n_rows";
	required=0;
	def_val="1";
	expr {
	 expr="1";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[8] {
    name="LeabraEpochMonitor";
    short_nm="EpcMon";
    tags="Leabra, Std, Monitor";
    desc="monitor epoch-level data from the network to a datatable (EpochOutputData typically) for use in graphing and viewing and further analysis";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="epoch_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="avg_cycles";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_cycles";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="Hidden_Fm_Input_r_wt";
	computed=0;
	object_type=LeabraPrjn;
	object=.projects[0].networks[0].layers[1].projections[0]$$;
	variable="r.wt";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="Aggregate": op=NONE: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="uniq_pats";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="Aggregate": op=NONE: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][1]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to get data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="epoch_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to write the epoch data to";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[0][8].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network monitor object that contains full specs for what to record and where to get it";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the network's epoch-level timer, to record how long it took to process an epoch";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="uniq_pats";
      var_type=T_Int;
      int_val=10;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="we get this from UniqPatStat program to record in our data table";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=AssignExpr;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=.projects[0].programs.gp[0][8].vars[2]$$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[1] {
      desc="set data and network on NetMonitor object";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][8].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="epoch_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="check configuration and emit errors/warnings for problems";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][8].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="update the monitor items and data schema based on current settings of NetMonitor";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][8].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[0][8].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data and stor it into the data table -- this does the main job here";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][8].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     OtherProgramVar @[2] {
      desc=;
      flags=;
      other_prog=.projects[0].programs.gp[1][7]$$;
      set_other=0;
      var_1=.projects[0].programs.gp[0][8].vars[3]$$;
      var_2=NULL;
      var_3=NULL;
      var_4=NULL;
     };
     DataVarProg @[3] {
      desc=;
      flags=;
      data_var=$.projects[0].programs.gp[0][8].vars[0]$;
      set_data=1;
      row_spec=CUR_ROW;
      row_var=NULL;
      quiet=0;
      var_1=$.projects[0].programs.gp[0][8].vars[3]$;
      var_2=NULL;
      var_3=NULL;
      var_4=NULL;
     };
     MethodCall @[4] {
      desc="update after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][8].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[9] {
    name="LeabraBatchMonitor";
    short_nm="BtcMnt";
    tags="Leabra, Std, Monitor";
    desc=;
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=DataTable;
     el_def=0;
     DataTable @[0] {
      name="DataByBatch";
      desc=;
      data {
       name="data";
       el_typ=DataColTp;
       el_def=0;
       int_Data @[0] {
	UserDataItem_List @*(.user_data_) {
	 name=;
	 el_typ=UserDataItemBase;
	 el_def=0;
	 UserDataItem @[0] {
	  name="NARROW";
	  value 1 0=1;
	  val_type_fixed=0;
	 };
	 UserDataItem @[1] {
	  name="view_panel_wd";
	  value 6 0=0.1865671575069427;
	  val_type_fixed=0;
	 };
	};
	name="batch_group";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
	ar {
	 name=;
		[8] 0;1;2;3;4;5;6;7;	};
       };
       float_Data @[1] {
	UserDataItem_List @*(.user_data_) {
	 name=;
	 el_typ=UserDataItemBase;
	 el_def=0;
	 UserDataItem @[0] {
	  name="view_panel_wd";
	  value 6 0=0.1865671575069427;
	  val_type_fixed=0;
	 };
	};
	name="uniq_pats_last";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
	ar {
	 name=;
		[8] 10;10;10;10;10;10;10;10;	};
       };
      };
      data_flags=SAVE_ROWS|AUTO_CALC;
      auto_load=NO_AUTO_LOAD;
      auto_load_file=;
      keygen 4 0=0;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="network to get data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="batch_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[1][2]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to write the data to";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="EpochOutputData";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[2] {
      name="DataByBatch";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].programs.gp[0][9].objs[0]$$;
      objs_ptr=1;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=AssignExpr;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     DataGroupProg @[0] {
      desc=;
      flags=;
      src_data_var=.projects[0].programs.gp[0][9].vars[1]$$;
      dest_data_var=.projects[0].programs.gp[0][9].vars[2]$$;
      group_spec {
       name="group_spec";
       ops {
	name=;
	el_typ=DataGroupEl;
	el_def=0;
	DataGroupEl @[0] {
	 col_name="batch";
	 agg {name="Aggregate": op=GROUP: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	};
	DataGroupEl @[1] {
	 col_name="uniq_pats";
	 agg {name="Aggregate": op=LAST: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	};
       };
       append_agg_name=1;
      };
     };
     DataGroupProg @[1] {
      desc=;
      flags=;
      src_data_var=$.projects[0].programs.gp[0][9].vars[2]$;
      dest_data_var=.projects[0].programs.gp[0][9].vars[0]$$;
      group_spec {
       name="group_spec";
       ops {
	name=;
	el_typ=DataGroupEl;
	el_def=0;
	DataGroupEl @[0] {
	 col_name="uniq_pats_last";
	 agg {name="Aggregate": op=MEAN: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	};
	DataGroupEl @[1] {
	 col_name="uniq_pats_last";
	 agg {name="Aggregate": op=MIN: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	};
	DataGroupEl @[2] {
	 col_name="uniq_pats_last";
	 agg {name="Aggregate": op=MAX: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	};
	DataGroupEl @[3] {
	 col_name="uniq_pats_last";
	 agg {name="Aggregate": op=COUNT: rel={name="Relation": rel=EQUAL: val=10: use_var=0: var=NULL: }: };
	};
       };
       append_agg_name=1;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[10] {
    name="SaveWeights";
    short_nm="SvWts";
    tags="Network, Weights";
    desc="save network's current weight values to file using WriteWeights function, with file name based on project name + batch + epoch values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="tag";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="user-provided tag (startup script will set this!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="wts_subdir";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|EDIT_VAL;
      reference=0;
      desc="user-provided subdirectory to save weights in";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="fname";
      var_type=T_String;
      string_val=;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="final generated file name -- do not edit!";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="epoch_str";
      var_type=T_String;
      string_val="0036";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="string rep of epoch with leading zeros";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="batch_str";
      var_type=T_String;
      string_val="03";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="string rep of batch with leading zeros";
      init_from=NULL;
     };
     ProgVar @[5] {
      name="final_tag";
      var_type=T_String;
      string_val=".03_0036";
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="batch + epoch";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     IfReturn @[0] {
      desc="do not save if not the first dmem process (only relevant for dmem = distributed memory processing)";
      flags=;
      cond {
       expr="taMisc::dmem_proc > 0";
      };
     };
     MiscCall @[1] {
      desc="get current batch counter for file name, with leading zeros to length 3";
      flags=;
      result_var=.projects[0].programs.gp[0][10].vars[4]$$;
      object_type=taMisc;
      method=taMisc::LeadingZeros;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=int;
	type="int";
	name="num";
	required=1;
	def_val=;
	expr {
	 expr="network.batch";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="len";
	required=1;
	def_val=;
	expr {
	 expr="2";
	};
       };
      };
     };
     MiscCall @[2] {
      desc="get current epoch counter with leading zeros to length 4";
      flags=;
      result_var=.projects[0].programs.gp[0][10].vars[3]$$;
      object_type=taMisc;
      method=taMisc::LeadingZeros;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=int;
	type="int";
	name="num";
	required=1;
	def_val=;
	expr {
	 expr="network.epoch";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="len";
	required=1;
	def_val=;
	expr {
	 expr="4";
	};
       };
      };
     };
     AssignExpr @[3] {
      desc="string 'tag' to identify the batch, epoch, and other user id info for the weights";
      flags=;
      result_var=.projects[0].programs.gp[0][10].vars[5]$$;
      expr {
       expr="tag + \".\" + batch_str + \"_\" + epoch_str";
      };
     };
     MethodCall @[4] {
      desc="get a file name based on the project's current file name, for saving the weights";
      flags=;
      result_var=.projects[0].programs.gp[0][10].vars[2]$$;
      obj=.projects[0].programs.gp[0][10].args[0]$$;
      method=taBase::GetFileNameFmProject;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="ext";
	required=1;
	def_val=;
	expr {
	 expr="\".wts.gz\"";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="tag";
	required=0;
	def_val="\"\"";
	expr {
	 expr="final_tag";
	};
       };
       ProgArg @[2] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="subdir";
	required=0;
	def_val="\"\"";
	expr {
	 expr="wts_subdir";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="dmem_proc_no";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[5] {
      desc="save the weights to that file name";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[0][10].args[0]$;
      method=Network::SaveWeights;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="fname";
	required=0;
	def_val="\"\"";
	expr {
	 expr="fname";
	};
       };
       ProgArg @[1] {
	arg_type=Network::WtSaveFormat;
	type="Network::WtSaveFormat";
	name="fmt";
	required=0;
	def_val="Network::NET_FMT";
	expr {
	 expr="Network::NET_FMT";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
  };
  Program_Group @.gp[1] {
   name="LeabraAll_Test";
   el_typ=Program;
   el_def=0;
   tags="Leabra, Std, All, Test";
   desc="The full set of programs for testing a standard Leabra network (starting with Epoch)";
   Program @[0] {
    name="LeabraEpochTest";
    short_nm="pchTst";
    tags="Leabra, Std, Test";
    desc="sets testing flag, iterates over all of the items in a data table and calls LeabraTestTrial process on them";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[0][1]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="table of patterns to present to the network, one row at a time";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="data_loop_order";
      var_type=T_HardEnum;
      int_val=0;
      hard_enum_type=DataLoop::Order;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="controls the order in which events (rows of the input data datatable) are presented to the network
(SEQUENTIAL, PERMUTED, RANDOM)";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="trial";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current trial (event) within the epoch -- increments automatically";
      init_from=NULL;
     };
     ProgVar @[3] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].data.gp[1][3]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="trial-level output data -- we reset it every epoch by default, so it just contains last epoch of data";
      init_from=NULL;
     };
     ProgVar @[4] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="timer to record time required to perform one epoch of processing (object is on network -- this is a pointer to it)";
      init_from=NULL;
     };
     ProgVar @[5] {
      name="data_loop_index";
      var_type=T_Int;
      int_val=10;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="index counter for the looping over items in the input_data datatable (not always the same as trial counter, depending on distributed memory computation)";
      init_from=NULL;
     };
     ProgVar @[6] {
      name="Hidden";
      var_type=T_Object;
      object_type=LeabraLayer;
      object_val=$.projects[0].networks[0].layers[1]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[7] {
      name="OneUnitActive";
      var_type=T_Object;
      object_type=LeabraLayerSpec;
      object_val=.projects[0].networks[0].specs[2].children[1]$$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[8] {
      name="HiddenLayer";
      var_type=T_Object;
      object_type=LeabraLayerSpec;
      object_val=$.projects[0].networks[0].specs[2].children[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=.projects[0].programs.gp[1][0].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][0].vars[2]$$;
      counter=Network::trial;
      update_after=0;
     };
     AssignExpr @[1] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=.projects[0].programs.gp[1][0].vars[4]$$;
      expr {
       expr="network.epoch_time";
      };
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize trial counter (local variable and in the network)";
      flags=;
      network_var=$.projects[0].programs.gp[1][0].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][0].vars[2]$;
      counter=Network::trial;
      update_after=0;
     };
     MemberAssign @[1] {
      desc="set to testing mode";
      flags=NEW_EL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      path="train_mode";
      expr {
       expr="Network::TEST";
      };
      update_after=0;
     };
     MethodCall @[2] {
      desc="for testing, set to one unit active";
      flags=NON_STD;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][0].vars[6]$$;
      method=LeabraLayer::SetLayerSpec;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=LayerSpec_ptr;
	type="LayerSpec*";
	name="sp";
	required=1;
	def_val=;
	expr {
	 expr="OneUnitActive";
	};
       };
      };
     };
     AssignExpr @[3] {
      desc="get pointer to epoch timer object on network";
      flags=;
      result_var=$.projects[0].programs.gp[1][0].vars[4]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[4] {
      desc="start the epoch timer to record computation time per epoch";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].vars[4]$;
      method=TimeUsed::StartTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_used";
	required=0;
	def_val="true";
	expr {
	 expr="true";
	};
       };
      };
     };
     MethodCall @[5] {
      desc="reset trial-level monitor data every epoch, so it reflects only the most recent epoch's worth of data (turn flags OFF to accumulate trial data across entire training run)";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][0].vars[3]$$;
      method=DataTable::ResetData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetDataLoop @[6] {
      desc="iterates over the events/rows of input_data, according to data_loop_order variable";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the trial program, passing network and input_data";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[1][1]$$;
	targ_ld_init="*LeabraTrial*";
       };
       IfElse @[1] {
	desc="test if it is time to update the weight values from delta weights (dWt) computed over trials";
	flags=;
	cond {
	 expr="network.Compute_Weights_Test(trial+1)";
	};
	true_code {
	 name=;
	 el_typ=MethodCall;
	 el_def=0;
	 MethodCall @[0] {
	  desc="update the weight values based on changes computed by trial program";
	  flags=;
	  result_var=NULL;
	  obj=$.projects[0].programs.gp[1][0].args[0]$;
	  method=Network::Compute_Weights;
	  meth_args {
	   name=;
	   el_typ=ProgArg;
	   el_def=0;
	  };
	 };
	};
	false_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	};
       };
      };
      data_var=.projects[0].programs.gp[1][0].vars[0]$$;
      index_var=.projects[0].programs.gp[1][0].vars[5]$$;
      order_var=.projects[0].programs.gp[1][0].vars[1]$$;
      order=SEQUENTIAL;
      item_idx_list{ 0;1;2;3;4;5;6;7;8;9;      };
      update_after=0;
      dmem_nprocs=1;
      dmem_this_proc=0;
      grouped=0;
      group_col 9 0="Group";
      group_index_var=NULL;
      group_order_var=NULL;
      group_order=PERMUTED;
      group_idx_list{       };
     };
     IfElse @[7] {
      desc="if full batch mode, update only at end of epoch";
      flags=;
      cond {
       expr="network.wt_update == Network::BATCH";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="final update of weights based on accumulated changes";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][0].args[0]$;
	method=Network::Compute_Weights;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     MethodCall @[8] {
      desc="network accumulates some core statistics over the epoch -- this finalizes that process and computes summary stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      method=LeabraNetwork::Compute_EpochStats;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[9] {
      desc="done with the computation in the epoch -- record time it took";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].vars[4]$;
      method=TimeUsed::EndTimer;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[10] {
      desc="run program that records data from network and possibly other sources about the epoch";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[1][6]$$;
      targ_ld_init="*LeabraEpochMonitor*";
     };
     ProgramCall @[11] {
      desc=;
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable;
	type="DataTable*";
	name="data_src";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=taString;
	type="String";
	name="col_name";
	required=1;
	def_val=;
	expr {
	 expr="\"Hidden_act_eq\"";
	};
       };
      };
      target=$.projects[0].programs.gp[1][7]$;
      targ_ld_init="*UniquePatStat*";
     };
     MethodCall @[12] {
      desc="restore to standard layer spec";
      flags=NON_STD;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][0].vars[6]$;
      method=LeabraLayer::SetLayerSpec;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=LayerSpec_ptr;
	type="LayerSpec*";
	name="sp";
	required=1;
	def_val=;
	expr {
	 expr="HiddenLayer";
	};
       };
      };
     };
     MemberAssign @[13] {
      desc="set back to training mode";
      flags=NEW_EL;
      obj=$.projects[0].programs.gp[1][0].args[0]$;
      path="train_mode";
      expr {
       expr="Network::TRAIN";
      };
      update_after=0;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[1] {
    name="LeabraTrialTest";
    short_nm="TrlTst";
    tags="Leabra, Std";
    desc="Leabra processing of a single input/toutput event or external information: typically runs a minus and a plus phase, then learns (unless testing)";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to operate on -- typically set by higher-level calling programs";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][1]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="datatable containing training input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="phase_no";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="local phase counting variable (0 is typically minus phase, 1 is typically plus -- depends on network settings)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether to update any network view displays after trial is completed";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=.projects[0].programs.gp[1][1].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][1].vars[0]$$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize the local phase_no counter, and corresponding network one";
      flags=;
      network_var=$.projects[0].programs.gp[1][1].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][1].vars[0]$;
      counter=LeabraNetwork::phase_no;
      update_after=0;
     };
     MethodCall @[1] {
      desc="initializes various counters at start of trial";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][1].args[0]$;
      method=LeabraNetwork::Trial_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     WhileLoop @[2] {
      desc="loop over phases of settling in the network";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the settle program (which iterates over cyles of network activation updating) for each phase";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=DataTable;
	  type="DataTable*";
	  name="input_data";
	  required=1;
	  def_val=;
	  expr {
	   expr="input_data";
	  };
	 };
	};
	target=.projects[0].programs.gp[1][2]$$;
	targ_ld_init="*LeabraSettle*";
       };
       NetCounterIncr @[1] {
	desc="increment the phase number (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[1][1].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[1][1].vars[0]$;
	counter=LeabraNetwork::phase_no;
	update_after=0;
       };
       MethodCall @[2] {
	desc="increments other phase state information to prepare for the next phase of settling";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][1].args[0]$;
	method=LeabraNetwork::Trial_UpdatePhase;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      test {
       expr="phase_no < network.phase_max";
      };
     };
     MethodCall @[3] {
      desc="after the trial is over, do final computations: Compute_dWt (learn weights), compute stats";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][1].args[0]$;
      method=LeabraNetwork::Trial_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[4] {
      desc="records data about the trial-level processing to a datatable for graphing/processing";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
      target=.projects[0].programs.gp[1][5]$$;
      targ_ld_init="*LeabraTrialMonitor*";
     };
     NetUpdateView @[5] {
      desc="update the network view(s) (only if update_net_view is true)";
      flags=;
      network_var=$.projects[0].programs.gp[1][1].args[0]$;
      update_var=.projects[0].programs.gp[1][1].vars[1]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[2] {
    name="LeabraSettleTest";
    short_nm="SttTst";
    tags="Leabra, Std";
    desc="iterates over cycles of updating until network has settled into a stable state, or output activations have exceeded a threshold";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][1]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="cycle";
      var_type=T_Int;
      int_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|CTRL_READ_ONLY|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="current cycle of settling (local loop counter)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="min_cycles";
      var_type=T_Int;
      int_val=5;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="IMPORTANT: this value is obtained from the network min_cycles and min_cycles_phase2 -- change the value on the network object, not here in this program!
sets the minimum number of cycles to settle for, regardless of network state changes, etc";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="if true, will update network views at end of settling";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=.projects[0].programs.gp[1][2].args[0]$$;
      local_ctr_var=.projects[0].programs.gp[1][2].vars[0]$$;
      counter=Network::cycle;
      update_after=0;
     };
    };
    prog_code {
     name=;
     el_typ=NetCounterInit;
     el_def=0;
     NetCounterInit @[0] {
      desc="initialize local cycle counter and corresponding counter on network";
      flags=;
      network_var=$.projects[0].programs.gp[1][2].args[0]$;
      local_ctr_var=$.projects[0].programs.gp[1][2].vars[0]$;
      counter=Network::cycle;
      update_after=0;
     };
     MethodCall @[1] {
      desc="resets input data, before getting new external inputs data from apply inputs call";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=Network::Init_InputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     ProgramCall @[2] {
      desc="apply external input activations from the input_data table to the network
this program can be extended to do arbitrary things to generate data and apply it to network layers";
      flags=;
      prog_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=Network;
	type="LeabraNetwork*";
	name="network";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
       ProgArg @[1] {
	arg_type=DataTable;
	type="DataTable*";
	name="input_data";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
      };
      target=.projects[0].programs.gp[1][4]$$;
      targ_ld_init="*ApplyInputs*";
     };
     MethodCall @[3] {
      desc="initializes various counters at start of settling";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=LeabraNetwork::Settle_Init;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[4] {
      desc="get appropriate min_cycles value depending on which phase we're in";
      flags=;
      cond {
       expr="network.phase_no <= 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=.projects[0].programs.gp[1][2].vars[1]$$;
	expr {
	 expr="network.min_cycles";
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       AssignExpr @[0] {
	desc="get minimum number of cycles from parameter on network (which is where you should change this value!)";
	flags=;
	result_var=$.projects[0].programs.gp[1][2].vars[1]$;
	expr {
	 expr="network.min_cycles_phase2";
	};
       };
      };
     };
     WhileLoop @[5] {
      desc="the main loop over cycles of updating";
      flags=;
      loop_code {
       name=;
       el_typ=ProgramCall;
       el_def=0;
       ProgramCall @[0] {
	desc="run the cycle program, which computes one cycle of activations";
	flags=;
	prog_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=LeabraNetwork;
	  type="LeabraNetwork*";
	  name="network";
	  required=1;
	  def_val=;
	  expr {
	   expr="network";
	  };
	 };
	};
	target=.projects[0].programs.gp[1][3]$$;
	targ_ld_init="*LeabraCycle*";
       };
       NetCounterIncr @[1] {
	desc="increment cycle counter (also on network)";
	flags=;
	network_var=$.projects[0].programs.gp[1][2].args[0]$;
	local_ctr_var=$.projects[0].programs.gp[1][2].vars[0]$;
	counter=Network::cycle;
	update_after=0;
       };
       IfContinue @[2] {
	desc="avoid subsequent stopping criteria if below min_cycles";
	flags=;
	cond {
	 expr="cycle < min_cycles";
	};
       };
       IfBreak @[3] {
	desc="stopping criterion for settling: based either on maximum change in activation (maxda) or on the maximum activation value in the network getting over threshold (which ever comes first).  Set either parmeter to values that are always false (e.g., trg_max_act_stopcrit = -1) to eliminate associated source of criterion for stopping settling.";
	flags=;
	cond {
	 expr="(network.maxda < network.maxda_stopcrit) ||
 (network.trg_max_act > network.trg_max_act_stopcrit)";
	};
       };
      };
      test {
       expr="cycle < network.cycle_max";
      };
     };
     MethodCall @[6] {
      desc="perform final operations at end of settling (storing final activations, etc)";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][2].args[0]$;
      method=LeabraNetwork::Settle_Final;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     IfElse @[7] {
      desc="only run trial-level statistics in minus phase (otherwise network may have correct answer clamped on!).  IMPORTANT: this assumes that you've got target activation values for output layers already
presented in the minus phase -- if this is not the case (values are computed on the fly), you may want to run this instead at the start of the plus phase, after ApplyInputs";
      flags=;
      cond {
       expr="network.phase == LeabraNetwork::MINUS_PHASE";
      };
      true_code {
       name=;
       el_typ=MethodCall;
       el_def=0;
       MethodCall @[0] {
	desc="compute trial-level statistics";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][2].args[0]$;
	method=LeabraNetwork::Compute_TrialStats;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     IfElse @[8] {
      desc="this stat must be called in plus phase when reward information is avail";
      flags=;
      cond {
       expr="network.phase_no == 1";
      };
      true_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MethodCall @[0] {
	desc="get external reward information";
	flags=;
	result_var=NULL;
	obj=$.projects[0].programs.gp[1][2].args[0]$;
	method=LeabraNetwork::Compute_ExtRew;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	};
       };
      };
      false_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
      };
     };
     NetUpdateView @[9] {
      desc="update network views, if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[1][2].args[0]$;
      update_var=.projects[0].programs.gp[1][2].vars[2]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[3] {
    name="LeabraCycleTest";
    short_nm="CycTst";
    tags="Leabra, Std";
    desc="runs one cycle of leabra processing (updating net inputs and activations)";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=taOBase;
     el_def=0;
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=LeabraNetwork;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="update_net_view";
      var_type=T_Bool;
      bool_val=0;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="determines whether network views will be updated on a cycle-by-cycle basis (slow, but often quite useful for seeing how processing is proceeding)";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="this does all the standard leabra processing for one cycle of activation updating";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][3].args[0]$$;
      method=LeabraNetwork::Cycle_Run;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     NetUpdateView @[1] {
      desc="update network views if update_net_view == true";
      flags=;
      network_var=$.projects[0].programs.gp[1][3].args[0]$;
      update_var=.projects[0].programs.gp[1][3].vars[0]$$;
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[4] {
    name="ApplyInputsTest";
    short_nm="AplyIn";
    tags="Network, InputData, Apply";
    desc="apply the current input data to the network as external input and target values";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=LayerWriter;
     el_def=0;
     LayerWriter @[0] {
      name="LayerWriter_0";
      data=$.projects[0].data.gp[0][1]$;
      network=$.projects[0].networks[0]$;
      layer_data {
       name=;
       el_typ=LayerWriterEl;
       el_def=0;
       LayerWriterEl @[0] {
	chan_name="Input";
	net_target=LAYER;
	layer_name="Input";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=EXT;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
       LayerWriterEl @[1] {
	chan_name="Name";
	net_target=TRIAL_NAME;
	layer_name="Name";
	offset {x=0: y=0: };
	use_layer_type=1;
	na_by_range=0;
	ext_flags=;
	noise {name="": type=NONE: mean=0: var=0.5: par=1: };
       };
      };
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to apply inputs to -- typically set by calling program";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="input_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[0][1]$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="input datatable containing input/output patterns";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="LayerWriter_0";
      var_type=T_Object;
      object_type=LayerWriter;
      object_val=.projects[0].programs.gp[1][4].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="this is a pointer to the LayerWriter object in objs -- edit that object to determine how information is presented to the network";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="sets the datatable and network for the layer writer, so it knows what to write to";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][4].vars[0]$$;
      method=LayerWriter::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataBlock_ptr;
	type="DataBlock*";
	name="db";
	required=1;
	def_val=;
	expr {
	 expr="input_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the layer writer -- will emit warnings and errors for missing or misconfigured items";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][4].vars[0]$;
      method=taList_impl::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="apply inputs to the network!  layer writer has all the key specs";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][4].vars[0]$;
      method=LayerWriter::ApplyInputData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[5] {
    name="LeabraTrialMonitorTest";
    short_nm="TrlMon";
    tags="Leabra, Std, Monitor";
    desc="monitor trial-level data from the network (and potentially other sources) -- stores results in datatable (TrialOutputData typically) that can be used for graph/grid views and further analysis ";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="trial_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="trial";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="trial_name";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="trial_name";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="cycle";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="cycle";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[5] {
	name="Hidden_act_eq";
	computed=0;
	object_type=LeabraLayer;
	object=$.projects[0].networks[0].layers[1]$;
	variable="act_eq";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="Aggregate": op=NONE: rel={name="Relation": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="SimpleMathSpec": opr=THRESH: arg=0.5: lw=0: hi=1: };
	pre_proc_2 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="SimpleMathSpec": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=$.projects[0].data.gp[1][3]$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to record data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="trial_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][3]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to record trial-level data to (this program writes new data to this table!)";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="trial_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[1][5].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the NetMonitor object in objs secton of this program that contains configuration for what to record and where to get it";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="set the network and datatable for the NetMonitor";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[1] {
      desc="check the configuration of the network monitor -- will emit warnings and errors for misconfigurations";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="update the monitor items and data schema based on current settings of the NetMonitor object";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data from the network and other sources -- this does the main work";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[2] {
      desc="update views and other things after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][5].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[3] {
      desc="only functional for dmem projects: synchronizes trial data across processes so that all distributed memory processors have the same trial-level data, despite having run only a subset of them each";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][5].args[0]$$;
      method=Network::DMem_ShareTrialData;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="trial_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=int;
	type="int";
	name="n_rows";
	required=0;
	def_val="1";
	expr {
	 expr="1";
	};
       };
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[6] {
    name="LeabraEpochMonitorTest";
    short_nm="EpcMon";
    tags="Leabra, Std, Monitor";
    desc="monitor epoch-level data from the network to a datatable (EpochOutputData typically) for use in graphing and viewing and further analysis";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=NetMonitor;
     el_def=0;
     NetMonitor @[0] {
      name="epoch_netmon";
      items {
       name=;
       el_typ=NetMonItem;
       el_def=0;
       NetMonItem @[0] {
	name="batch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="batch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[1] {
	name="epoch";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="epoch";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[2] {
	name="avg_sse";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_sse";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[3] {
	name="cnt_err";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="cnt_err";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[4] {
	name="avg_ext_rew";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_ext_rew";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[5] {
	name="avg_cycles";
	computed=0;
	object_type=LeabraNetwork;
	object=$.projects[0].networks[0]$;
	variable="avg_cycles";
	var_label=;
	name_style=AUTO_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[6] {
	name="epoch_time_tot";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
       NetMonItem @[7] {
	name="epoch_time_usr";
	computed=1;
	object_type=NULL;
	object=NULL;
	variable="act";
	var_label=;
	name_style=MY_NAME;
	max_name_len=6;
	val_type=VT_FLOAT;
	matrix=0;
	matrix_geom{ 	};
	data_agg=0;
	data_src=NULL;
	agg_col {
	 col_name=;
	};
	agg {name="": op=NONE: rel={name="": rel=LESSTHANOREQUAL: val=0: use_var=0: var=NULL: }: };
	select_rows=0;
	select_spec {
	 col_name=;
	 on=1;
	 rel=EQUAL;
	 use_var=0;
	 cmp 0 1;
	 var=NULL;
	 enable_var=NULL;
	};
	pre_proc_1 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_2 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
	pre_proc_3 {name="": opr=NONE: arg=0: lw=-1: hi=1: };
       };
      };
      network=$.projects[0].networks[0]$;
      data=.projects[0].data.gp[1][4]$$;
      rmv_orphan_cols=1;
     };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="network";
      var_type=T_Object;
      object_type=Network;
      object_val=$.projects[0].networks[0]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network to get data from";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="epoch_mon_data";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][4]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data table to write the epoch data to";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="epoch_netmon";
      var_type=T_Object;
      object_type=NetMonitor;
      object_val=.projects[0].programs.gp[1][6].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="network monitor object that contains full specs for what to record and where to get it";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="epoch_timer";
      var_type=T_Object;
      object_type=TimeUsed;
      object_val=$.projects[0].networks[0].epoch_time$;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="pointer to the network's epoch-level timer, to record how long it took to process an epoch";
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=AssignExpr;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     AssignExpr @[0] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=.projects[0].programs.gp[1][6].vars[2]$$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[1] {
      desc="set data and network on NetMonitor object";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][6].vars[1]$$;
      method=NetMonitor::SetDataNetwork;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dt";
	required=1;
	def_val=;
	expr {
	 expr="epoch_mon_data";
	};
       };
       ProgArg @[1] {
	arg_type=Network_ptr;
	type="Network*";
	name="net";
	required=1;
	def_val=;
	expr {
	 expr="network";
	};
       };
      };
     };
     MethodCall @[2] {
      desc="check configuration and emit errors/warnings for problems";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=taBase::CheckConfig;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
      };
     };
     MethodCall @[3] {
      desc="update the monitor items and data schema based on current settings of NetMonitor";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=NetMonitor::UpdateMonitors;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=bool;
	type="bool";
	name="reset_first";
	required=0;
	def_val="false";
	expr {
	 expr="true";
	};
       };
      };
     };
    };
    prog_code {
     name=;
     el_typ=MethodCall;
     el_def=0;
     MethodCall @[0] {
      desc="add a new blank row to the data";
      flags=;
      result_var=NULL;
      obj=.projects[0].programs.gp[1][6].vars[0]$$;
      method=DataTable::AddBlankRow;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     MethodCall @[1] {
      desc="get the new monitor data and stor it into the data table -- this does the main job here";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[1]$;
      method=NetMonitor::GetMonVals;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
     AssignExpr @[2] {
      desc="get the epoch timer from current network";
      flags=;
      result_var=$.projects[0].programs.gp[1][6].vars[2]$;
      expr {
       expr="network.epoch_time";
      };
     };
     MethodCall @[3] {
      desc="set the total time to compute the epoch (epoch_time_tot -- wall clock time) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetTotSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_tot\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[4] {
      desc="set the user process time (cpu time for this process, epoch_time_usr) to time used data from network timer";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataTable::SetValColName;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=const_Variant_ref;
	type="const Variant&";
	name="val";
	required=1;
	def_val=;
	expr {
	 expr="epoch_timer.used.GetUsrSecs()";
	};
       };
       ProgArg @[1] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="col_name";
	required=1;
	def_val="\"\"";
	expr {
	 expr="\"epoch_time_usr\"";
	};
       };
       ProgArg @[2] {
	arg_type=int;
	type="int";
	name="row";
	required=1;
	def_val=;
	expr {
	 expr="-1";
	};
       };
       ProgArg @[3] {
	arg_type=bool;
	type="bool";
	name="quiet";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     MethodCall @[5] {
      desc="update after writing new data to monitor data table";
      flags=;
      result_var=NULL;
      obj=$.projects[0].programs.gp[1][6].vars[0]$;
      method=DataBlock::WriteClose;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
   Program @[7] {
    name="UniquePatStat";
    short_nm="nPStt";
    tags="Statistic, Unique Patterns";
    desc="compute number of unique patterns in source data table, generating a distance matrix";
    flags=NO_STOP_STEP;
    objs {
     name=;
     el_typ=DataTable;
     el_def=0;
     DataTable @[0] {
      name="dist_matrix";
      desc="distance matrix upon which computation is based";
      data {
       name="data";
       el_typ=String_Data;
       el_def=0;
       String_Data @[0] {
	name="Name";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[1] {
	name="V0";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[2] {
	name="V1";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[3] {
	name="V2";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[4] {
	name="V3";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[5] {
	name="V4";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[6] {
	name="H0";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[7] {
	name="H1";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[8] {
	name="H2";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[9] {
	name="H3";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
       float_Data @[10] {
	name="H4";
	col_flags=SAVE_ROWS|SAVE_DATA;
	is_matrix=0;
	cell_geom{ 1;	};
	calc_expr {
	 expr=;
	};
	dim_names {
	 name=;
		[0] 	};
       };
      };
      data_flags=AUTO_CALC;
      auto_load=NO_AUTO_LOAD;
      auto_load_file=;
      keygen 4 0=0;
     };
     Relation @[1] {name="cnt_eq_0": rel=EQUAL: val=0: use_var=0: var=NULL: };
    };
    types {
     name=;
     el_typ=ProgType;
     el_def=0;
    };
    args {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="data_src";
      var_type=T_Object;
      object_type=DataTable;
      object_val=$.projects[0].data.gp[1][3]$;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="data to process";
      init_from=NULL;
     };
     ProgVar @[1] {
      name="col_name";
      var_type=T_String;
      string_val="Hidden_act_eq";
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="name of column in data_src that has the data to process";
      init_from=NULL;
     };
    };
    vars {
     name=;
     el_typ=ProgVar;
     el_def=0;
     ProgVar @[0] {
      name="dist_matrix";
      var_type=T_Object;
      object_type=DataTable;
      object_val=.projects[0].programs.gp[1][7].objs[0]$$;
      objs_ptr=1;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[1] {
      name="dist_tol";
      var_type=T_Real;
      real_val=0.5;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc="distance tolerance for computing uniqueness of patterns";
      init_from=NULL;
     };
     ProgVar @[2] {
      name="uniq_pats";
      var_type=T_Int;
      int_val=10;
      objs_ptr=0;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[3] {
      name="n_zeros";
      var_type=T_Int;
      int_val=1;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[4] {
      name="i";
      var_type=T_Int;
      int_val=11;
      objs_ptr=0;
      flags=NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
     ProgVar @[5] {
      name="cnt_eq_0";
      var_type=T_Object;
      object_type=Relation;
      object_val=.projects[0].programs.gp[1][7].objs[1]$$;
      objs_ptr=1;
      flags=CTRL_PANEL|NULL_CHECK|USED|EDIT_VAL;
      reference=0;
      desc=;
      init_from=NULL;
     };
    };
    functions {
     name=;
     el_typ=Function;
     el_def=0;
    };
    load_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    init_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
    };
    prog_code {
     name=;
     el_typ=ProgEl;
     el_def=0;
     DataAnalCall @[0] {
      desc=;
      flags=;
      result_var=NULL;
      object_type=taDataAnal;
      method=taDataAnal::DistMatrixTable;
      meth_args {
       name=;
       el_typ=ProgArg;
       el_def=0;
       ProgArg @[0] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="dist_mat";
	required=1;
	def_val=;
	expr {
	 expr="dist_matrix";
	};
       };
       ProgArg @[1] {
	arg_type=bool;
	type="bool";
	name="view";
	required=1;
	def_val=;
	expr {
	 expr="false";
	};
       };
       ProgArg @[2] {
	arg_type=DataTable_ptr;
	type="DataTable*";
	name="src_data";
	required=1;
	def_val=;
	expr {
	 expr="data_src";
	};
       };
       ProgArg @[3] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="data_col_nm";
	required=1;
	def_val=;
	expr {
	 expr="col_name";
	};
       };
       ProgArg @[4] {
	arg_type=const_taString_ref;
	type="const taString&";
	name="name_col_nm";
	required=1;
	def_val=;
	expr {
	 expr="\"trial_name\"";
	};
       };
       ProgArg @[5] {
	arg_type=taMath::DistMetric;
	type="taMath::DistMetric";
	name="metric";
	required=1;
	def_val=;
	expr {
	 expr="taMath::SUM_SQUARES";
	};
       };
       ProgArg @[6] {
	arg_type=bool;
	type="bool";
	name="norm";
	required=0;
	def_val="false";
	expr {
	 expr="false";
	};
       };
       ProgArg @[7] {
	arg_type=float;
	type="float";
	name="tol";
	required=0;
	def_val="0.0f";
	expr {
	 expr="dist_tol";
	};
       };
       ProgArg @[8] {
	arg_type=bool;
	type="bool";
	name="incl_scalars";
	required=0;
	def_val="false";
	expr {
	 expr=;
	};
       };
      };
     };
     AssignExpr @[1] {
      desc=;
      flags=;
      result_var=.projects[0].programs.gp[1][7].vars[2]$$;
      expr {
       expr="0";
      };
     };
     ForLoop @[2] {
      desc=;
      flags=;
      loop_code {
       name=;
       el_typ=ProgEl;
       el_def=0;
       MathCall @[0] {
	desc=;
	flags=;
	result_var=.projects[0].programs.gp[1][7].vars[3]$$;
	object_type=taMath_float;
	method=taMath_float::vec_count;
	meth_args {
	 name=;
	 el_typ=ProgArg;
	 el_def=0;
	 ProgArg @[0] {
	  arg_type=const_float_Matrix_ptr;
	  type="const float_Matrix*";
	  name="vec";
	  required=1;
	  def_val=;
	  expr {
	   expr="dist_matrix.data[i].ar";
	  };
	 };
	 ProgArg @[1] {
	  arg_type=Relation_ref;
	  type="Relation&";
	  name="rel";
	  required=1;
	  def_val=;
	  expr {
	   expr="cnt_eq_0";
	  };
	 };
	};
       };
       If @[1] {
	desc="one zero in dist matrix means that it was identical only to itself -- more means not-unique";
	flags=;
	cond {
	 expr="n_zeros == 1";
	};
	true_code {
	 name=;
	 el_typ=ProgEl;
	 el_def=0;
	 VarIncr @[0] {
	  desc=;
	  flags=;
	  var=$.projects[0].programs.gp[1][7].vars[2]$;
	  expr {
	   expr="1";
	  };
	 };
	};
       };
      };
      init {
       expr="i = 1";
      };
      test {
       expr="i < dist_matrix.data.size";
      };
      iter {
       expr="i++";
      };
     };
    };
    step_prog=NULL;
    step_n=1;
   };
  };
 };
 viewers {
  name=;
  el_typ=TopLevelViewer;
  el_def=0;
  MainWindowViewer @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="view_win_lft";
     value 6 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[1] {
     name="view_win_top";
     value 6 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[2] {
     name="view_win_wd";
     value 6 0=1;
     val_type_fixed=0;
    };
    UserDataItem @[3] {
     name="view_win_ht";
     value 6 0=0.7996109127998352;
     val_type_fixed=0;
    };
    UserDataItem @[4] {
     name="view_win_iconified";
     value 1 0=0;
     val_type_fixed=0;
    };
    UserDataItem @[5] {
     name="view_splitter_state";
     value 9 0="AAAA/wAAAAAAAAADAAAAvgAAAnwAAAMWAQAAAAYBAAAAAQ==";
     val_type_fixed=0;
    };
   };
   name="Browser";
   m_data=.projects[0]$$;
   visible=1;
   m_is_root=0;
   m_is_viewer_xor_browser=0;
   m_is_proj_viewer=1;
   m_is_dialog=0;
   toolbars {
    name=;
    el_typ=ToolBar;
    el_def=0;
    ToolBar @[0] {
     UserDataItem_List @*(.user_data_) {
      name=;
      el_typ=UserDataItemBase;
      el_def=0;
      UserDataItem @[0] {
       name="view_win_visible";
       value 1 0=0;
       val_type_fixed=0;
      };
     };
     name="Application";
     m_data=NULL;
     visible=0;
     lft=0;
     top=0;
     o=Horizontal;
    };
   };
   frames {
    name=;
    el_typ=FrameViewer;
    el_def=0;
    tabBrowseViewer @[0] {
     name="Tree";
     m_data=NULL;
     visible=1;
     root_typ=LeabraProject;
     root_md=NULL;
     m_root=$.projects[0]$;
    };
    PanelViewer @[1] {
     name="Panels";
     m_data=NULL;
     visible=1;
    };
    T3DataViewer @[2] {
     name="T3Frames";
     m_data=NULL;
     visible=1;
     frames {
      name=;
      el_typ=T3DataViewFrame;
      el_def=0;
      T3DataViewFrame @[0] {
       name="Network";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 NetView @[0] {
	  name=;
	  m_data=$.projects[0].networks[0]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=1: y=0: z=0: rot=0.35: }: translate={x=0: y=0: z=0: }: };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=1: y=0: z=0: rot=0.35: }: translate={x=0: y=0: z=0: }: };
	  display=1;
	  lay_mv=0;
	  net_text=0;
	  net_text_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=0: y=-0.5: z=0: }: };
	  net_text_rot=0;
	  cur_unit_vals{ act;	  };
	  unit_src_path=".layers[1].units[13]";
	  hist_idx=0;
	  hist_save=1;
	  hist_max=100;
	  hist_ff=5;
	  unit_disp_mode=UDM_BLOCK;
	  unit_text_disp=UTD_NONE;
	  max_size {x=5: y=5: z=1.5: };
	  font_sizes {
	   net_name=0.05;
	   net_vals=0.05;
	   layer=0.04;
	   layer_min=0.01;
	   layer_vals=0.03;
	   prjn=0.01;
	   unit=0.02;
	   un_nm_len=3;
	  };
	  view_params {
	   xy_square=0;
	   unit_spacing=0.05;
	   prjn_disp=L_R_F;
	   prjn_name=0;
	   prjn_width=0.002;
	   prjn_trans=0.5;
	   lay_trans=0.5;
	   unit_trans=0.6;
	   laygp_width=1;
	   show_laygp=1;
	  };
	  wt_line_disp=0;
	  wt_line_width=4;
	  wt_line_thr=0.5;
	  wt_line_swt=0;
	  wt_prjn_k_un=4;
	  wt_prjn_k_gp=1;
	  wt_prjn_lay=NULL;
	  snap_bord_disp=0;
	  snap_bord_width=4;
	  scale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=.colorspecs[0]$$<ColorScaleSpec,C_ColdHot>;
	   auto_scale=0;
	  };
	  scale_ranges {
	   name=;
	   el_typ=ScaleRange;
	   el_def=0;
	   ScaleRange @[0] {
	    name="act";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	   ScaleRange @[1] {
	    name="r.wt";
	    auto_scale=0;
	    min=-1;
	    max=1;
	   };
	  };
	  lay_disp_modes{ Input=0;Hidden=0;	  };
	 };
	 GraphTableView @[1] {
	  name=;
	  m_data=$.projects[0].data.gp[1][1]$;
FloatTransform @*(.m_transform) {scale={x=0.745325: y=0.7453247: z=0.7453246: }: rotate={x=0.7141239: y=-0.69965: z=-0.02276706: rot=0.3636606: }: translate={x=0.6654732: y=1.229273: z=-0.1800281: }: };
	  children {
	   name=;
	   el_typ=GraphColView;
	   el_def=0;
	   GraphColView @[0] {
	    name="batch";
	    m_data=.projects[0].data.gp[1][1].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[1] {
	    name="epoch";
	    m_data=.projects[0].data.gp[1][1].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=16: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[2] {
	    name="avg_cycles";
	    m_data=.projects[0].data.gp[1][1].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=6.7: fix_max=0: max=9.9: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[3] {
	    name="Hidden_Fm_Input_r_wt";
	    m_data=.projects[0].data.gp[1][1].data[3]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	    data_range {min=0: max=0: };
	   };
	   GraphColView @[4] {
	    name="uniq_pats";
	    m_data=.projects[0].data.gp[1][1].data[4]$$;
	    m_transform=NULL;
	    visible=1;
	    fixed_range {fix_min=1: min=0: fix_max=1: max=10: };
	    data_range {min=0: max=0: };
	   };
	  };
	  main_xform {scale={x=0.745325: y=0.7453247: z=0.7453246: }: rotate={x=0.7141239: y=-0.69965: z=-0.02276706: rot=0.3636606: }: translate={x=0.6654732: y=1.229273: z=-0.1800281: }: };
	  view_rows=10000;
	  view_range {min=0: max=-1: };
	  display_on=1;
	  manip_ctrl_on=1;
	  graph_type=XY;
	  plot_style=LINE;
	  negative_draw=0;
	  negative_draw_z=1;
	  line_width=2;
	  point_size=MEDIUM;
	  point_spacing=1;
	  bar_space=0.2;
	  label_spacing=-1;
	  width=1;
	  depth=1;
	  axis_font_size=0.05;
	  label_font_size=0.04;
	  x_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=X;
	   col_name="epoch";
	   fixed_range {fix_min=0: min=0: fix_max=0: max=29: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=29: };
	   range {min=0: max=29: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  z_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=Z;
	   col_name="batch";
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=-6e-19: max=6e-19: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  plot_1 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=1;
	   axis=Y;
	   col_name="uniq_pats";
	   fixed_range {fix_min=1: min=0: fix_max=1: max=10: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=10: };
	   range {min=0: max=10: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  plot_2 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name="avg_cycles";
	   fixed_range {fix_min=0: min=6.7: fix_max=0: max=9.9: };
	   color {name="red": r=1: g=0: b=0: a=1: desc="": };
	   data_range {min=6.7: max=9.9: };
	   range {min=6.7: max=9.9: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=SQUARE;
	   alt_y=0;
	  };
	  plot_3 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="blue": r=0: g=0: b=1: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=DIAMOND;
	   alt_y=0;
	  };
	  plot_4 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="green": r=0: g=1: b=0: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=TRIANGLE;
	   alt_y=0;
	  };
	  plot_5 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=1: };
	   color {name="purple": r=0.627451: g=0.1254902: b=0.9411765: a=1: desc="": };
	   data_range {min=0: max=1: };
	   range {min=0: max=1: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=PLUS;
	   alt_y=0;
	  };
	  plot_6 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="orange": r=1: g=0.6470588: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CROSS;
	   alt_y=0;
	  };
	  plot_7 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="brown": r=0.6470588: g=0.1647059: b=0.1647059: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=STAR;
	   alt_y=0;
	  };
	  plot_8 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="chartreuse": r=0.4980392: g=1: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=MINUS;
	   alt_y=0;
	  };
	  alt_y_1=0;
	  alt_y_2=0;
	  alt_y_3=0;
	  alt_y_4=0;
	  alt_y_5=0;
	  err_1 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_2 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_3 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_4 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_5 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_6 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_7 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_8 {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   line_style=SOLID;
	   point_style=CIRCLE;
	   alt_y=0;
	  };
	  err_spacing=1;
	  err_bar_width=0.02;
	  color_mode=VALUE_COLOR;
	  color_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=0;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  raster_axis {
	   name=;
	   m_data=NULL;
	   m_transform=NULL;
	   on=0;
	   axis=Y;
	   col_name=;
	   fixed_range {fix_min=0: min=0: fix_max=0: max=0: };
	   color {name="black": r=0: g=0: b=0: a=1: desc="": };
	   data_range {min=0: max=0: };
	   range {min=0: max=0: };
	   n_ticks=10;
	   axis_length=1;
	   row_num=0;
	  };
	  thresh=0.5;
	  thr_line_len=0.48;
	  matrix_mode=SEP_GRAPHS;
	  mat_layout=BOT_ZERO;
	  mat_odd_vert=1;
	  two_d_font=0;
	  two_d_font_scale=350;
	 };
	 GridTableView @[2] {
	  name=;
	  m_data=$.projects[0].data.gp[1][1]$;
FloatTransform @*(.m_transform) {scale={x=0.821752: y=0.8217517: z=0.821752: }: rotate={x=0: y=1: z=0: rot=0.1739762: }: translate={x=-0.4541012: y=1.092062: z=0.0008038804: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="batch";
	    m_data=$.projects[0].data.gp[1][1].data[0]$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="epoch";
	    m_data=$.projects[0].data.gp[1][1].data[1]$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="avg_cycles";
	    m_data=$.projects[0].data.gp[1][1].data[2]$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[3] {
	    name="Hidden_Fm_Input_r_wt";
	    m_data=$.projects[0].data.gp[1][1].data[3]$;
	    m_transform=NULL;
	    visible=1;
	    text_width=5;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[4] {
	    name="uniq_pats";
	    m_data=$.projects[0].data.gp[1][1].data[4]$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=0.821752: y=0.8217517: z=0.821752: }: rotate={x=0: y=1: z=0: rot=0.1739762: }: translate={x=-0.4541012: y=1.092062: z=0.0008038804: }: };
	  view_rows=1;
	  view_range {min=0: max=-1: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=1;
	  col_range {min=3: max=3: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=0.5096891: y=0.9758379: z=2.62951: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=2.952573;
	};
	T3SavedView @[1] {
	 name="WtGrid";
	 view_saved=1;
	 pos {x=0.2067302: y=1.499838: z=1.156597: };
	 orient {x=0: y=1.000008: z=0: rot=0.1719987: };
	 focal_dist=1.50182;
	};
	T3SavedView @[2] {
	 name="Graph";
	 view_saved=1;
	 pos {x=0.7532836: y=1.5008: z=1.149646: };
	 orient {x=0.1111899: y=-0.9937448: z=0.01093163: rot=0.1972258: };
	 focal_dist=1.50182;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[1] {
       name="Lines_Input_Data";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=$.projects[0].data.gp[0][0]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="Name";
	    m_data=.projects[0].data.gp[0][0].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=12;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="Input";
	    m_data=.projects[0].data.gp[0][0].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=5;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=9: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=1: };
	  width=0.3;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	 GridTableView @[1] {
	  name=;
	  m_data=$.projects[0].data.gp[0][1]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1.470802: y=-0.001313807: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="Name";
	    m_data=.projects[0].data.gp[0][1].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=12;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="Input";
	    m_data=.projects[0].data.gp[0][1].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=5;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1.470802: y=-0.001313807: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=9: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=1: };
	  width=0.3;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.385401: y=0.5168431: z=1.467686: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.477686;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
      T3DataViewFrame @[2] {
       name="BatchOutputData";
       m_data=NULL;
       visible=1;
       root_view {
	name=;
	m_data=NULL;
	m_transform=NULL;
	children {
	 name=;
	 el_typ=T3DataView;
	 el_def=0;
	 GridTableView @[0] {
	  name=;
	  m_data=$.projects[0].data.gp[1][2]$;
FloatTransform @*(.m_transform) {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  children {
	   name=;
	   el_typ=GridColView;
	   el_def=0;
	   GridColView @[0] {
	    name="uniq_pats_last_mean";
	    m_data=.projects[0].data.gp[1][2].data[0]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[1] {
	    name="uniq_pats_last_min";
	    m_data=.projects[0].data.gp[1][2].data[1]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[2] {
	    name="uniq_pats_last_max";
	    m_data=.projects[0].data.gp[1][2].data[2]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	   GridColView @[3] {
	    name="uniq_pats_last_count";
	    m_data=.projects[0].data.gp[1][2].data[3]$$;
	    m_transform=NULL;
	    visible=1;
	    text_width=8;
	    scale_on=1;
	    mat_layout=BOT_ZERO;
	    mat_image=0;
	    mat_odd_vert=1;
	   };
	  };
	  main_xform {scale={x=1: y=1: z=1: }: rotate={x=0: y=0: z=1: rot=0: }: translate={x=1: y=0: z=0: }: };
	  view_rows=10;
	  view_range {min=0: max=0: };
	  display_on=1;
	  manip_ctrl_on=1;
	  col_n=5;
	  col_range {min=0: max=3: };
	  width=1;
	  grid_on=1;
	  header_on=1;
	  row_num_on=0;
	  two_d_font=0;
	  two_d_font_scale=350;
	  mat_val_text=0;
	  colorscale {
	   name="ColorScale";
	   chunks=133;
	   min=-1;
	   max=1;
	   range=1;
	   zero=0;
	   spec=$.colorspecs[0]$;
	   auto_scale=0;
	  };
	  grid_margin=0.01;
	  grid_line_size=0.005;
	  row_num_width=4;
	  mat_block_spc=0.1;
	  mat_block_height=0;
	  mat_rot=0;
	  mat_trans=0.6;
	  mat_size_range {min=4: max=16: };
	  text_size_range {min=0.02: max=0.05: };
	  click_vals=0;
	  lmb_val=1;
	  mmb_val=0;
	 };
	};
       };
       bg_color {r=0.8: g=0.8: b=0.8: a=1: };
       text_color {r=0: g=0: b=0: a=1: };
       headlight_on=1;
       stereo_view=STEREO_NONE;
       saved_views {
	name=;
	el_typ=T3SavedView;
	el_def=0;
	T3SavedView @[0] {
	 name="View 0";
	 view_saved=1;
	 pos {x=1.5325: y=0.5174999: z=1.443747: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=1.453747;
	};
	T3SavedView @[1] {
	 name="View 1";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[2] {
	 name="View 2";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[3] {
	 name="View 3";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[4] {
	 name="View 4";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
	T3SavedView @[5] {
	 name="View 5";
	 view_saved=0;
	 pos {x=0: y=0: z=0: };
	 orient {x=0: y=0: z=1: rot=0: };
	 focal_dist=0;
	};
       };
      };
     };
    };
   };
   docks {
    name=;
    el_typ=DockViewer;
    el_def=0;
    ToolBoxDockViewer @[0] {
     UserDataItem_List @*(.user_data_) {
      name=;
      el_typ=UserDataItemBase;
      el_def=0;
      UserDataItem @[0] {
       name="view_win_lft";
       value 6 0=0;
       val_type_fixed=0;
      };
      UserDataItem @[1] {
       name="view_win_top";
       value 6 0=-0.02140077762305737;
       val_type_fixed=0;
      };
      UserDataItem @[2] {
       name="view_win_wd";
       value 6 0=0.05958230793476105;
       val_type_fixed=0;
      };
      UserDataItem @[3] {
       name="view_win_ht";
       value 6 0=0.7587548494338989;
       val_type_fixed=0;
      };
      UserDataItem @[4] {
       name="view_win_iconified";
       value 1 0=0;
       val_type_fixed=0;
      };
      UserDataItem @[5] {
       name="view_visible";
       value 1 0=0;
       val_type_fixed=0;
      };
     };
     name="Tools";
     m_data=NULL;
     visible=0;
     dock_flags=DV_MOVABLE|DV_FLOATABLE;
     dock_area=1;
    };
   };
  };
 };
 last_change_desc=;
 networks {
  name=;
  el_typ=LeabraNetwork;
  el_def=0;
  LeabraNetwork @[0] {
   UserDataItem_List @*(.user_data_) {
    name=;
    el_typ=UserDataItemBase;
    el_def=0;
    UserDataItem @[0] {
     name="norm_err";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[1] {
     name="ext_rew";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[2] {
     name="maxda";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[3] {
     name="minus_output_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[4] {
     name="minus_cycles";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[5] {
     name="ct_cycle";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[6] {
     name="phase_no";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[7] {
     name="phase";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[8] {
     name="sse";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[9] {
     name="output_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[10] {
     name="trial_name";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[11] {
     name="group_name";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[12] {
     name="time";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[13] {
     name="cycle";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[14] {
     name="tick";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[15] {
     name="trial";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[16] {
     name="group";
     value 1 0=0;
     val_type_fixed=1;
    };
    UserDataItem @[17] {
     name="epoch";
     value 1 0=1;
     val_type_fixed=1;
    };
    UserDataItem @[18] {
     name="batch";
     value 1 0=1;
     val_type_fixed=1;
    };
   };
   name="SelfOrgNet";
   desc="self organizing network";
   specs {
    name=;
    el_typ=LeabraUnitSpec;
    el_def=0;
    LeabraUnitSpec @[0] {
     name="LeabraUnitSpec_0";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=LeabraUnitSpec;
      el_def=0;
     };
     act_range {min=0: max=1: range=1: scale=1: };
     bias_con_type=LeabraCon;
     bias_spec {type=LeabraBiasSpec: spec=.projects[0].networks[0].specs[4]$$: };
     sse_tol=0.5;
     act_fun=NOISY_XX1;
     act {gelin=0: thr=0.25: gain=600: nvar=0.005: avg_dt=0.005: avg_init=0.15: i_thr=STD: };
     spike {rise=0: decay=0.05: g_gain=5: window=3: eq_gain=10: eq_dt=0.02: };
     spike_misc {
      exp_slope=0.02;
      spk_thr=1.2;
      clamp_max_p=0.11;
      clamp_type=REGULAR;
      vm_r=0.3;
      vm_dend=0.3;
      vm_dend_dt=0.16;
      vm_dend_time=6.25;
     };
     opt_thresh {send=0.1: delta=0.005: phase_dif=0: };
     maxda {val=INET_DA: inet_scale=1: lay_avg_thr=0.01: };
     clamp_range {min=0: max=0.95: range=0.95: scale=1.052632: };
     vm_range {min=0: max=1: range=1: scale=1: };
     v_m_init {name="": type=UNIFORM: mean=0.15: var=0: par=1: };
     dt {integ=1: vm=0.2: net=0.7: midpoint=0: d_vm_max=0.025: vm_eq_cyc=0: vm_eq_dt=1: integ_time=1: vm_time=5: net_time=1.428571: };
     act_avg {l_gain=3: l_dt=0.005: ml_dt=0.4: m_dt=0.1: s_dt=0.2: ss_dt=1: use_nd=0: l_time=200: ml_time=2.5: m_time=10: s_time=5: ss_time=1: };
     g_bar {e=1: l=0.1: i=1: h=0.1: a=0.5: };
     e_rev {e=1: l=0.15: i=0.15: h=1: a=0: };
     hyst {on=0: b_inc_dt=0.01: b_dec_dt=0.05: a_thr=0.5: d_thr=0.1: g_dt=0.1: init=1: trl=0: };
     acc {on=0: b_inc_dt=0.01: b_dec_dt=0.01: a_thr=0.5: d_thr=0.1: g_dt=0.1: init=1: trl=0: };
     adapt {
      on=0;
      dt=0.007;
      vm_gain=0.04;
      spike_gain=0.00805;
      interval=10;
      dt_time=142.8571;
     };
     depress {on=0: rec=0.2: asymp_act=0.5: depl=0.2105263: interval=1: max_amp=2: };
     syn_delay {
      on=0;
      delay=4;
     };
     da_mod {on=0: mod=PLUS_CONT: gain=0.1: };
     noise_type=NO_NOISE;
     noise {name="": type=GAUSSIAN: mean=0: var=0.001: par=1: };
     noise_adapt {trial_fixed=1: k_pos_noise=0: mode=FIXED_NOISE: min_pct=0.5: min_pct_c=0.5: };
     noise_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=1;
      cur_val=0;
     };
    };
    LeabraConSpec @[1] {
     name="LeabraConSpec_0";
     desc=" ";
     unique{      };
     children {
      name=;
      el_typ=LeabraConSpec;
      el_def=0;
     };
     rnd {name="": type=UNIFORM: mean=0.25: var=0.2: par=1: };
     wt_limits {type=MIN_MAX: min=0: max=1: sym=1: };
     learn_rule=LEABRA_CHL;
     inhib=0;
     wt_scale {abs=1: rel=1: sem_extra=2: old=0: };
     wt_scale_init {init=0: abs=1: rel=1: };
     lrate=0.01;
     cur_lrate=0.01;
     lrs_value=EPOCH;
     lrate_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=0;
      cur_val=0;
     };
     wt_sig {gain=6: off=1.25: };
     lmix {hebb=1: err=0: err_sb=1: };
     xcal {s_mix=0.9: m_mix=0.1: thr_l_mix=0.01: thr_m_mix=0.99: d_rev=0.1: d_gain=1: d_thr=0.0001: d_rev_ratio=9: };
     savg_cor {cor=0.5: thresh=0.001: norm_con_n=1: };
     rel_net_adapt {
      on=0;
      trg_fm_input=0.85;
      trg_fm_output=0.15;
      trg_lateral=0;
      trg_sum=1;
      tol_lg=0.05;
      tol_sm=0.2;
      rel_lrate=0.1;
     };
    };
    LeabraLayerSpec @[2] {
     name="InputLayer";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=LeabraLayerSpec;
      el_def=0;
      LeabraLayerSpec @[0] {
       name="HiddenLayer";
       desc=;
       unique{ kwta;inhib;       };
       children {
	name=;
	el_typ=LeabraLayerSpec;
	el_def=0;
       };
       inhib_group=ENTIRE_LAYER;
       inhib {
	type=KWTA_AVG_INHIB;
	kwta_pt=0.7;
	min_i=0;
	fb_act_thr=0;
	ff_pct=0;
	fb_max_dt=0.1;
	comp_thr=0.5;
	comp_gain=2;
	gp_pt=0.2;
       };
       kwta {k_from=USE_K: k=2: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       gp_kwta {k_from=USE_PCT: k=12: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       tie_brk {on=0: k_thr=1: diff_thr=0.2: thr_gain=0.005: loser_gain=1: };
       i_netin_mod {on=0: max_mod=0.02: mod_gain=10: max_top_k=0.4: };
       adapt_i {type=NONE: tol=0.05: p_dt=0: mx_d=0.2: l=0.2: a_dt=0.005: };
       clamp {hard=1: gain=0.5: max_plus=0: plus=0.01: min_clamp=0.5: };
       decay {event=1: phase=1: phase2=0: clamp_phase2=0: };
       ct_inhib_mod {
	use_sin=0;
	burst_i=0.02;
	trough_i=0.02;
	use_fin=0;
	inhib_i=0;
       };
       abs_net_adapt {
	on=0;
	trg_net=0.5;
	tol=0.1;
	abs_lrate=0.1;
       };
      };
      LeabraLayerSpec @[1] {
       name="OneUnitActive";
       desc=;
       unique{ kwta;       };
       children {
	name=;
	el_typ=LeabraLayerSpec;
	el_def=0;
       };
       inhib_group=ENTIRE_LAYER;
       inhib {
	type=KWTA_AVG_INHIB;
	kwta_pt=0.7;
	min_i=0;
	fb_act_thr=0;
	ff_pct=0;
	fb_max_dt=0.1;
	comp_thr=0.5;
	comp_gain=2;
	gp_pt=0.2;
       };
       kwta {k_from=USE_K: k=1: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       gp_kwta {k_from=USE_PCT: k=12: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
       tie_brk {on=0: k_thr=1: diff_thr=0.2: thr_gain=0.005: loser_gain=1: };
       i_netin_mod {on=0: max_mod=0.02: mod_gain=10: max_top_k=0.4: };
       adapt_i {type=NONE: tol=0.05: p_dt=0: mx_d=0.2: l=0.2: a_dt=0.005: };
       clamp {hard=1: gain=0.5: max_plus=0: plus=0.01: min_clamp=0.5: };
       decay {event=1: phase=1: phase2=0: clamp_phase2=0: };
       ct_inhib_mod {
	use_sin=0;
	burst_i=0.02;
	trough_i=0.02;
	use_fin=0;
	inhib_i=0;
       };
       abs_net_adapt {
	on=0;
	trg_net=0.5;
	tol=0.1;
	abs_lrate=0.1;
       };
      };
     };
     inhib_group=ENTIRE_LAYER;
     inhib {
      type=KWTA_AVG_INHIB;
      kwta_pt=0.7;
      min_i=0;
      fb_act_thr=0;
      ff_pct=0;
      fb_max_dt=0.1;
      comp_thr=0.5;
      comp_gain=2;
      gp_pt=0.2;
     };
     kwta {k_from=USE_PAT_K: k=5: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
     gp_kwta {k_from=USE_PCT: k=12: pct=0.23: pat_q=0.5: diff_act_pct=0: act_pct=0.1: gp_i=0: gp_g=0.5: };
     tie_brk {on=0: k_thr=1: diff_thr=0.2: thr_gain=0.005: loser_gain=1: };
     i_netin_mod {on=0: max_mod=0.02: mod_gain=10: max_top_k=0.4: };
     adapt_i {type=NONE: tol=0.05: p_dt=0: mx_d=0.2: l=0.2: a_dt=0.005: };
     clamp {hard=1: gain=0.5: max_plus=0: plus=0.01: min_clamp=0.5: };
     decay {event=1: phase=1: phase2=0: clamp_phase2=0: };
     ct_inhib_mod {
      use_sin=0;
      burst_i=0.02;
      trough_i=0.02;
      use_fin=0;
      inhib_i=0;
     };
     abs_net_adapt {
      on=0;
      trg_net=0.5;
      tol=0.1;
      abs_lrate=0.1;
     };
    };
    FullPrjnSpec @[3] {
     name="FullPrjnSpec_0";
     desc=;
     unique{      };
     children {
      name=;
      el_typ=FullPrjnSpec;
      el_def=0;
     };
     self_con=0;
     init_wts=0;
     add_rnd_wts=0;
    };
    LeabraBiasSpec @[4] {
     name="LeabraBiasSpec_0";
     desc=;
     unique{ rnd;wt_limits;wt_scale;wt_scale_init;     };
     children {
      name=;
      el_typ=LeabraBiasSpec;
      el_def=0;
     };
     rnd {name="": type=UNIFORM: mean=0: var=0: par=1: };
     wt_limits {type=NONE: min=-1: max=5: sym=0: };
     learn_rule=LEABRA_CHL;
     inhib=0;
     wt_scale {abs=1: rel=0.02: sem_extra=2: old=0: };
     wt_scale_init {init=0: abs=1: rel=1: };
     lrate=0;
     cur_lrate=0;
     lrs_value=EPOCH;
     lrate_sched {
      name=;
      el_typ=SchedItem;
      el_def=0;
      last_ctr=-1;
      default_val=1;
      interpolate=0;
      cur_val=0;
     };
     wt_sig {gain=6: off=1.25: };
     lmix {hebb=0.01: err=0.99: err_sb=1: };
     xcal {s_mix=0.9: m_mix=0.1: thr_l_mix=0.01: thr_m_mix=0.99: d_rev=0.1: d_gain=1: d_thr=0.0001: d_rev_ratio=9: };
     savg_cor {cor=1: thresh=0.01: norm_con_n=0: };
     rel_net_adapt {
      on=0;
      trg_fm_input=0.85;
      trg_fm_output=0.15;
      trg_lateral=0;
      trg_sum=1;
      tol_lg=0.05;
      tol_sm=0.2;
      rel_lrate=0.1;
     };
     dwt_thresh=0.1;
    };
   };
   layers {
    name=;
    el_typ=LeabraLayer;
    el_def=0;
    pos {x=0: y=0: z=0: };
    max_size {x=5: y=5: z=2: };
    LeabraLayer @[0] {
     name="Input";
     desc=;
     flags=;
     layer_type=INPUT;
     pos {x=0: y=0: z=0: };
     disp_scale=1;
     un_geom {x=5: y=5: n_not_xy=0: n=25: };
     unit_groups=0;
     gp_geom {x=0: y=0: n_not_xy=0: n=0: };
     gp_spc {x=0: y=0: };
     act_geom {x=5: y=5: n_not_xy=0: n=25: };
     scaled_act_geom {x=5: y=5: n_not_xy=0: n=1: };
     projections {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
     };
     send_prjns {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
	    Projection_Group @. = [0] = LeabraPrjn .projects[0].networks[0].layers[1].projections[0];
     };
     units {
      name=;
      el_typ=LeabraUnit;
      el_def=0;
      pos {x=0: y=0: z=0: };
      unique_geom=0;
      geom {x=5: y=5: n_not_xy=0: n=25: };
      units_lesioned=0;
      output_name=;
     };
     unit_spec {type=LeabraUnitSpec: spec=.projects[0].networks[0].specs[0]$$: };
     ext_flag=;
     dmem_dist=DMEM_DIST_DEFAULT;
     dist {
      fm_input=-1;
      fm_output=-1;
     };
     output_name=;
     sse=0;
     icon_value=0;
     netin {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     netin_top_k {cmpt=1: avg=0: max=0: max_i=-1: };
     i_thrs {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts_p {cmpt=1: avg=0.19: max=0.95: max_i=20: };
     acts_m {cmpt=1: avg=0.19: max=0.95: max_i=20: };
     phase_dif_ratio=1;
     acts_p2 {cmpt=1: avg=0: max=0: max_i=-1: };
     acts_m2 {cmpt=1: avg=0: max=0: max_i=-1: };
     kwta {k=5: pct=0.2: pct_c=0.8: adth_k=2: k_ithr=0: k1_ithr=0: ithr_r=0: ithr_diff=0: tie_brk_gain=0: eff_loser_gain=1: tie_brk=0: };
     i_val {kwta=0: g_i=0: gp_g_i=0: g_i_orig=0: i_netin_mod=0: };
     un_g_i {cmpt=0: avg=0: max=-3.402823e+38: max_i=-1: };
     adapt_i {avg_avg=0.2: i_kwta_pt=0.7: g_bar_i=1: g_bar_l=0.1: };
     maxda=0;
     act_max_avg=0;
     spec {type=LeabraLayerSpec: spec=.projects[0].networks[0].specs[2]$$: };
     hard_clamped=0;
     avg_l_avg=8.32658e+35;
     dav=0;
     avg_netin {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_sum {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_n=0;
     norm_err=0;
     da_updt=0;
    };
    LeabraLayer @[1] {
     name="Hidden";
     desc=;
     flags=;
     layer_type=HIDDEN;
     pos {x=0: y=0: z=1: };
     disp_scale=1;
     un_geom {x=5: y=4: n_not_xy=0: n=20: };
     unit_groups=0;
     gp_geom {x=0: y=0: n_not_xy=0: n=0: };
     gp_spc {x=0: y=0: };
     act_geom {x=5: y=4: n_not_xy=0: n=20: };
     scaled_act_geom {x=5: y=4: n_not_xy=0: n=1: };
     projections {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
      LeabraPrjn @[0] {
       name="Fm_Input";
       from_type=CUSTOM;
       from=.projects[0].networks[0].layers[0]$$;
       spec {type=FullPrjnSpec: spec=.projects[0].networks[0].specs[3]$$: };
       con_type=LeabraCon;
       recvcons_type=LeabraRecvCons;
       sendcons_type=LeabraSendCons;
       con_spec {type=LeabraConSpec: spec=$.projects[0].networks[0].specs[1]$: };
       recv_idx=0;
       send_idx=0;
       recv_n=1;
       send_n=1;
       projected=1;
       direction=DIR_UNKNOWN;
       netin_avg=0;
       netin_rel=0;
       avg_netin_avg=0;
       avg_netin_avg_sum=0;
       avg_netin_rel=0;
       avg_netin_rel_sum=0;
       avg_netin_n=0;
       trg_netin_rel=-1;
      };
     };
     send_prjns {
      name=;
      el_typ=LeabraPrjn;
      el_def=0;
     };
     units {
      name=;
      el_typ=LeabraUnit;
      el_def=0;
      pos {x=0: y=0: z=0: };
      unique_geom=0;
      geom {x=5: y=4: n_not_xy=0: n=20: };
      units_lesioned=0;
      output_name=;
     };
     unit_spec {type=LeabraUnitSpec: spec=$.projects[0].networks[0].specs[0]$: };
     ext_flag=;
     dmem_dist=DMEM_DIST_DEFAULT;
     dist {
      fm_input=-1;
      fm_output=-1;
     };
     output_name=;
     sse=0;
     icon_value=0;
     netin {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     netin_top_k {cmpt=1: avg=0: max=0: max_i=-1: };
     i_thrs {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts {cmpt=1: avg=0: max=-3.402823e+38: max_i=-1: };
     acts_p {cmpt=1: avg=0.0942026: max=0.942026: max_i=1: };
     acts_m {cmpt=1: avg=0.0942026: max=0.942026: max_i=1: };
     phase_dif_ratio=1;
     acts_p2 {cmpt=1: avg=0: max=0: max_i=-1: };
     acts_m2 {cmpt=1: avg=0: max=0: max_i=-1: };
     kwta {k=2: pct=0.1: pct_c=0.9: adth_k=1: k_ithr=7.023442: k1_ithr=1.182464: ithr_r=1.781653: ithr_diff=0.8316404: tie_brk_gain=0: eff_loser_gain=1: tie_brk=0: };
     i_val {kwta=0: g_i=0: gp_g_i=0: g_i_orig=0: i_netin_mod=0: };
     un_g_i {cmpt=0: avg=0: max=-3.402823e+38: max_i=-1: };
     adapt_i {avg_avg=0.1: i_kwta_pt=0.7: g_bar_i=1: g_bar_l=0.1: };
     maxda=0;
     act_max_avg=0;
     spec {type=LeabraLayerSpec: spec=$.projects[0].networks[0].specs[2].children[0]$: };
     hard_clamped=0;
     avg_l_avg=1.666904e-33;
     dav=0;
     avg_netin {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_sum {cmpt=1: avg=0: max=0: max_i=-1: };
     avg_netin_n=0;
     norm_err=0;
     da_updt=0;
    };
   };
   view_objs {
    name=;
    el_typ=NetViewObj;
    el_def=0;
   };
   flags=;
   auto_build=AUTO_BUILD;
   train_mode=TRAIN;
   wt_update=ON_LINE;
   small_batch_n=10;
   batch=0;
   epoch=0;
   group=0;
   trial=0;
   tick=0;
   cycle=0;
   time=0;
   group_name=;
   trial_name=;
   output_name=;
   sse_unit_avg=0;
   sse_sqrt=0;
   sse=0;
   sum_sse=0;
   avg_sse=0;
   cnt_err_tol=0;
   cnt_err=0;
   pct_err=0;
   pct_cor=0;
   cur_sum_sse=0;
   avg_sse_n=0;
   cur_cnt_err=0;
   train_time {name="train_time": start={usr=1597: sys=418: tot=128203504863: }: end={usr=2144: sys=485: tot=128203505511: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   epoch_time {name="epoch_time": start={usr=2142: sys=484: tot=128203505508: }: end={usr=2142: sys=484: tot=128203505509: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   trial_time {name="trial_time": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   settle_time {name="settle_time": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   cycle_time {name="cycle_time": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   wt_sync_time {name="wt_sync_time": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   misc_time {name="misc_time": start={usr=0: sys=0: tot=0: }: end={usr=0: sys=0: tot=0: }: used={usr=0: sys=0: tot=0: }: s_used=0: n_used=0: };
   threads {
    run_time {name="": s_used=0: n_used=0: };
    sync_time {name="": s_used=0: n_used=0: };
    total_time {name="": s_used=0: n_used=0: };
    n_wake_in_sync=0;
    run_time_pct=0;
    sync_time_pct=0;
    wake_in_sync_pct=0;
    interleave=1;
    ignore_lay_sync=0;
   };
   dmem_sync_level=DMEM_SYNC_NETWORK;
   dmem_nprocs=1;
   usr1_save_fmt=FULL_NET;
   wt_save_fmt=TEXT;
   lay_layout=THREE_D;
   n_units=45;
   n_cons=500;
   max_size {x=5: y=5: z=2: };
   learn_rule=LEABRA_CHL;
   phase_order=PLUS_ONLY;
   no_plus_test=1;
   sequence_init=DO_NOTHING;
   phase=MINUS_PHASE;
   nothing_phase=0;
   phase_no=0;
   phase_max=1;
   ct_cycle=7;
   time_inc=1;
   cycle_max=60;
   mid_minus_cycle=-1;
   min_cycles=5;
   min_cycles_phase2=35;
   ct_time {
    minus=50;
    plus=20;
    inhib=1;
    n_avg_only_epcs=1;
    total_cycles=71;
    inhib_start=70;
   };
   ct_sravg {
    start=30;
    end=1;
    interval=1;
    plus_s_st=19;
    force_con=0;
   };
   ct_sin_i {
    start=30;
    duration=20;
    n_pi=2;
    burst_i=0.02;
    trough_i=0.02;
   };
   ct_fin_i {
    start=20;
    end=25;
    inhib_i=0;
   };
   sravg_vals {
    s_sum=0;
    s_nrm=0;
    m_sum=0;
    m_nrm=0;
    do_s=0;
   };
   ct_lrn_trig {
    plus_lrn_cyc=-1;
    davg_dt=0.1;
    davg_s_dt=0.05;
    davg_m_dt=0.03;
    davg_l_dt=0.0005;
    thr_min=0;
    thr_max=0.5;
    loc_max_cyc=8;
    loc_max_dec=0.01;
    lrn_delay=40;
    lrn_refract=100;
    davg_l_init=0;
    davg_max_init=0.001;
    davg_time=10;
    davg_s_time=20;
    davg_m_time=33.33334;
    davg_l_time=2000;
    lrn_delay_inc=0.025;
    lrn_refract_inc=0.01;
   };
   lrn_trig {
    davg=0;
    davg_s=0;
    davg_m=0;
    davg_smd=0;
    davg_l=0;
    davg_max=0.001;
    cyc_fm_inc=0;
    cyc_fm_dec=0;
    loc_max=0;
    lrn_max=0;
    lrn_trig=0;
    lrn=0;
    lrn_min=0;
    lrn_min_cyc=0;
    lrn_min_thr=0;
    lrn_min_sum=0;
    lrn_min_cyc_sum=0;
    lrn_min_thr_sum=0;
    lrn_plus=0;
    lrn_plus_cyc=0;
    lrn_plus_thr=0;
    lrn_plus_sum=0;
    lrn_plus_cyc_sum=0;
    lrn_plus_thr_sum=0;
    lrn_noth=0;
    lrn_noth_cyc=0;
    lrn_noth_thr=0;
    lrn_noth_sum=0;
    lrn_noth_cyc_sum=0;
    lrn_noth_thr_sum=0;
    lrn_stats_n=0;
   };
   minus_cycles=0;
   avg_cycles=0;
   avg_cycles_sum=0;
   avg_cycles_n=0;
   minus_output_name=;
   net_misc {
    cyc_syn_dep=0;
    syn_dep_int=20;
   };
   send_pct=0;
   send_pct_n=0;
   send_pct_tot=0;
   avg_send_pct=0;
   avg_send_pct_sum=0;
   avg_send_pct_n=0;
   maxda_stopcrit=0.005;
   maxda=0;
   trg_max_act_stopcrit=1;
   trg_max_act=0;
   ext_rew=0;
   ext_rew_avail=0;
   norew_val=0.5;
   avg_ext_rew=0;
   pvlv_pvi=0;
   pvlv_pvr=0;
   pvlv_lve=0;
   pvlv_lvi=0;
   pv_detected=0;
   avg_ext_rew_sum=0;
   avg_ext_rew_n=0;
   off_errs=1;
   on_errs=1;
   norm_err=0;
   avg_norm_err=1;
   avg_norm_err_sum=0;
   avg_norm_err_n=0;
  };
 };
};
